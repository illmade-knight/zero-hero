{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b5cd7b-bbea-4769-8512-e1c440795bf2",
   "metadata": {},
   "source": [
    "## larger corpus\n",
    "\n",
    "ok apply our network to a larger corpus and see what happens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e7065e-4b63-46d3-9c5c-bdc3ce1f2782",
   "metadata": {},
   "source": [
    "### standard setup\n",
    "\n",
    "but we're reading in alice in wonderland now\n",
    "\n",
    "for the moment we're going to use an input pattern to keep our vocab_size similar to the names file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d7eabc6c-08fb-4ae2-b7ab-26f664ad82d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4745ac40-30b7-4e76-b0ae-a72e5ea3d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../lib/bookreader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "33b59c17-863b-4377-ad06-16d8a2babbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowercase only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice = BookReader()\n",
    "\n",
    "alice.read(\"../resources/alice.txt\")\n",
    "\n",
    "vocab_size = len(alice.itos)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e6792ffb-5d03-4c00-845a-ce02682f5fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHAPTER I.\\nDown the Rabbit-Hole\\n\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into\\nthe book her sister was rea'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(alice.all_lines[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "32da8b1b-1beb-49ae-a277-cb562872f1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117467"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alice.batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1f659eb1-76e1-4d2a-a9b8-d1fe312c9a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  1, 26,  4, 10, 22,  1, 12, 23, 22,  1, 23,  4, 12],\n",
       "         [ 9,  1,  4, 22,  1, 11,  4, 21,  7,  1,  4, 22,  1, 22],\n",
       "         [18, 18, 14,  1, 17, 18,  1, 17, 18, 23, 12,  6,  8,  1],\n",
       "         [ 8,  1, 16, 28,  1, 10, 15, 18, 25,  8, 22,  1, 23, 11],\n",
       "         [ 1,  1, 26,  4, 22,  1, 23, 11,  8,  1, 14, 12, 17, 10]]),\n",
       " tensor([15, 11, 18, 12,  1]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = alice.sample_batch(5, 14)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e641ead5-bee6-48e6-a644-5bfacad7fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 25\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32455bf2-178f-4d5f-b0c2-34341d9baab7",
   "metadata": {},
   "source": [
    "### Neural net lib\n",
    "\n",
    "we've put our network in a python file so load it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "720fce12-d150-4f51-94ff-2f19726be1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../lib/simplebook.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "353e37de-81c6-4842-98b3-61debceae081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 100 5 6203\n"
     ]
    }
   ],
   "source": [
    "sn = SimpleBook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ed430cf0-7287-479c-a718-542eecee6964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 160 25 41260\n",
      "initial learning rate 0.2\n",
      "learning rate 0 [0.196]\n",
      "running loss tensor(2.5360)\n",
      "learning rate 10 [0.16014627014995916]\n",
      "running loss tensor(3.0162)\n",
      "learning rate 20 [0.13085116246399847]\n",
      "running loss tensor(2.7350)\n",
      "learning rate 30 [0.10691492659895763]\n",
      "running loss tensor(2.4980)\n",
      "learning rate 40 [0.08735727917438633]\n",
      "running loss tensor(2.3218)\n",
      "learning rate 50 [0.07137725729707488]\n",
      "running loss tensor(2.1827)\n",
      "learning rate 60 [0.058320415967655595]\n",
      "running loss tensor(2.0697)\n",
      "learning rate 70 [0.047652025973541665]\n",
      "running loss tensor(1.9731)\n",
      "learning rate 80 [0.03893517461607997]\n",
      "running loss tensor(1.8933)\n",
      "learning rate 90 [0.03181287241021722]\n",
      "running loss tensor(1.8195)\n",
      "learning rate 100 [0.025993432955371577]\n",
      "running loss tensor(1.7623)\n",
      "learning rate 110 [0.021238527225488715]\n",
      "running loss tensor(1.7165)\n",
      "learning rate 120 [0.017353423054287647]\n",
      "running loss tensor(1.6772)\n",
      "learning rate 130 [0.014179010084073873]\n",
      "running loss tensor(1.6500)\n",
      "learning rate 140 [0.011585283568281068]\n",
      "running loss tensor(1.6304)\n",
      "learning rate 150 [0.009466020163723585]\n",
      "running loss tensor(1.6140)\n",
      "learning rate 160 [0.007734427665227742]\n",
      "running loss tensor(1.6074)\n",
      "learning rate 170 [0.006319590522096326]\n",
      "running loss tensor(1.5946)\n",
      "learning rate 180 [0.005163565566269181]\n",
      "running loss tensor(1.5969)\n",
      "learning rate 190 [0.0042190090107794434]\n",
      "running loss tensor(1.5930)\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 80\n",
    "samples = 5000\n",
    "\n",
    "tr = TestRig(9, 160, context_length, vocab_size)\n",
    "# train(self, epochs, samples, batch_size, content_length, sampler):\n",
    "tr.train(epochs, samples, batch_size, alice)\n",
    "# tr.model.generate(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a4a1f3a0-53ef-4747-93f6-02fd09629c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "\n",
      "             a do! lowe keeped  aid shatice ras as in heand\n",
      "the inge edoneand the juser foumbontud  ind lanay! \n",
      "\n",
      "\n",
      "\n",
      " bot sen so   make   ith no cat dorang? \n",
      "\n",
      "\n",
      " imust of her the?  sret sole i ithe tupply inf itht eawelry\n",
      "the anit the quet in  shat gears thine d and tremaly   you?  as a kid hech   said   wattly\n",
      "\n",
      "worhe you nowlilline olice hom a vind a cuder   \n",
      "\n",
      "\n",
      "\n",
      " nowent yo   \n",
      " yur pisens lore peapduinat be qubbly\n",
      "litther?  alice \n",
      " i do had fech nokes he derer lase pratl trene sitner my tharle quee\n",
      "of thile   as  the pritlads \n",
      "\n",
      "\n",
      " hous   alice it  at fick the mand  \n",
      "thinuop  andy?pread reyen!der to  tilligh  \n",
      "\n",
      "\n",
      " whe take witsing on to hars alace wertared en the weroned en ad she gookige rom mour? she dourto    i ale ghe shink de the kidt saidrich  as a glithen\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(tr.model.generate(800, alice)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cc4d8d-4570-4f3b-bdc0-f94ae014dcfa",
   "metadata": {},
   "source": [
    "## OK it's not a masterpiece\n",
    "\n",
    "but we have structure - it's clearly more than random\n",
    "\n",
    "in the next section we'll add more [context](../context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
