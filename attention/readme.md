## All you need?

well, all you need for a gpt like base model

### The basic attention head

we look at the [query, key](attention_head.ipynb) lookup space and how this allows us to build
different heads which learn different contextual transformations of the inputs 