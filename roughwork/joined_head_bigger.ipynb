{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "965b36f1-1440-4a07-a843-80cba31c34e8",
   "metadata": {},
   "source": [
    "### Missing something again\n",
    "\n",
    "what's the difference between multi head and a bigger head?\n",
    "\n",
    "again the attention is linear unit - if we just make it wider isn't that the same as having mulitple smaller heads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d689a91-95ca-42cd-802e-ab97496243cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8919ad-3d6b-4421-94ce-553e3a506dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run bookreader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b6ef18-283c-41fd-9375-ef8d13ed5e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br = BookReader(False, r'[^\\d+a-zA-Z \\n?!:,]')\n",
    "br.read(\"tiny_shakespeare.txt\")\n",
    "vocab_size = br.vocab_size\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a713daf8-4a5f-430d-8f00-9c6db6743d22",
   "metadata": {},
   "source": [
    "### Get the batch with both x and y unseparated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91f9fe0b-25d9-4578-a105-4eb99138428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, batch_length=5, batch_size=5):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    ix = torch.randint(len(data) - batch_length, (batch_size,))\n",
    "    b = torch.stack([data[i:i+batch_length] for i in ix])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac12ed62-275e-43a8-b17e-9b0b6da58efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.tensor(br.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3b116f-f526-4958-bfed-07f665e89cba",
   "metadata": {},
   "source": [
    "### Create an attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf6cf111-bf37-49fe-8e92-de8a35f8e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, c, head_size, content_length):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(c, head_size, bias=False)\n",
    "        self.query = nn.Linear(c, head_size, bias=False)\n",
    "        self.value = nn.Linear(c, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(content_length, content_length)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   \n",
    "        q = self.query(x)\n",
    "        \n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 \n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        \n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7138eed8-721e-4752-bf9f-8ebca24882d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, fan_in, multiplier = 4):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = OrderedDict([\n",
    "            (\"l_in\", nn.Linear(fan_in, multiplier * fan_in)),\n",
    "            (\"relu\", nn.ReLU()),\n",
    "            (\"l_out\", nn.Linear(multiplier * fan_in, fan_in)),\n",
    "        ])\n",
    "        self.net = nn.Sequential(\n",
    "            layers\n",
    "        )\n",
    "\n",
    "        initial = layers['l_in']\n",
    "        nn.init.kaiming_normal_(initial.weight, nonlinearity=\"relu\")\n",
    "        layers['l_in'].weight.data = initial.weight.data * 3/5\n",
    "        if initial.bias is not None:\n",
    "            nn.init.constant_(initial.bias, 0)\n",
    "\n",
    "        final = layers['l_out']\n",
    "        layers['l_out'].weight.data = final.weight.data * .2\n",
    "        if final.bias is not None:\n",
    "            nn.init.constant_(final.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b77ec387-64c7-43b3-82a5-b24e22eb84a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "989f2ee4-1968-4bf6-8352-4e37ebaca633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiHead(nn.Module):\n",
    "\n",
    "#     def __init__(self, num_heads, head_size, embed_size, content_length):\n",
    "#         super().__init__()\n",
    "#         self.heads = nn.ModuleList([Head(embed_size, head_size, content_length) for _ in range(num_heads)])\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = torch.cat( [head(x) for head in self.heads], dim = -1 )\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c111acc3-cd35-46fe-bb16-413aeccbb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadJoin(nn.Module):\n",
    "    \n",
    "    def __init__(self, c, num_heads, head_size, content_length):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(c, head_size * num_heads, bias=False)\n",
    "        self.key = nn.Linear(c, head_size * num_heads, bias=False)\n",
    "        self.value = nn.Linear(c, head_size * num_heads, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(content_length, content_length)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   \n",
    "        q = self.query(x)\n",
    "        \n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 \n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        \n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dff586a7-6f05-4e2a-95f4-9a07c8e27203",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFMultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, content_length, num_heads, head_size, multiplier=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.positional_embed = nn.Embedding(content_length, embed_size)\n",
    "        self.mutli_attention = MultiHeadJoin(embed_size, num_heads, head_size, content_length)\n",
    "        self.lna = nn.LayerNorm(embed_size)\n",
    "        self.ff = FeedForward(embed_size, multiplier)\n",
    "        self.lnff = nn.LayerNorm(embed_size)\n",
    "        self.decode = nn.Linear(embed_size, vocab_size)\n",
    "        self.content_length = content_length\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        #idx B,T\n",
    "        B, T = idx.shape\n",
    "\n",
    "        idx_e = self.vocab_embed(idx)\n",
    "        # note tr is always the same - so the learning here is information passed back to the positional_embed from loss\n",
    "        tr = torch.arange(T)\n",
    "        pos_e = self.positional_embed(tr)\n",
    "\n",
    "        x = idx_e + pos_e\n",
    "        x = self.mutli_attention(x)\n",
    "        # print(\"multi ball out\", x.shape)\n",
    "        x = self.lna(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.lnff(x)\n",
    "        # print(\"feed forward out\", x.shape)\n",
    "        logits = self.decode(x)\n",
    "        # print(\"decode out\", x.shape)\n",
    "        # print(\"targets\", targets.shape)\n",
    "        # return None, None\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            targets = targets.reshape(B*T)\n",
    "            loss = F.cross_entropy(logits.view(B*T, -1), targets) #.resize(B*T)) # loss function\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -self.content_length:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16926363-2c95-4998-a0a9-8eee16e1abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_batch(data, batch_length=5, batch_size=5, i=0):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    if i == 0:\n",
    "        ix = torch.randint(len(data) - batch_length, (batch_size,))\n",
    "    else:\n",
    "        ix = torch.arange(1, 5) + 1 + i\n",
    "\n",
    "    b = torch.stack([data[i:i+batch_length] for i in ix])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f874381a-99eb-4bba-bde0-b10c9632e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "@torch.no_grad()\n",
    "def split_loss(split):\n",
    "    split_len = len(split)\n",
    "    total_loss = 0\n",
    "    batch_size = 50\n",
    "    num_batches = math.floor(split_len / batch_size)\n",
    "    print(\"num_batches\", split_len, num_batches)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        t_b = get_val_batch(split, context_length+1, batch_size, i*batch_size)\n",
    "        \n",
    "        x = t_b[:, 0: context_length]\n",
    "        y = t_b[:, context_length: context_length+1]\n",
    "        \n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, batch_loss = model(x, y)\n",
    "        \n",
    "        total_loss = total_loss + batch_loss\n",
    "    \n",
    "    print(\"total loss\", total_loss, total_loss / num_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c2d3c52-0c8a-4ab6-8121-7e8377d361d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "24475  parameters\n",
      "ep 0 tensor(2.6336, grad_fn=<DivBackward0>) [0.098]\n",
      "ep 5 tensor(1.8936, grad_fn=<DivBackward0>) [0.0885842380864]\n",
      "ep 10 tensor(1.8267, grad_fn=<DivBackward0>) [0.08007313507497958]\n",
      "ep 15 tensor(1.7958, grad_fn=<DivBackward0>) [0.07237977205924956]\n",
      "ep 20 tensor(1.7743, grad_fn=<DivBackward0>) [0.06542558123199924]\n",
      "ep 25 tensor(1.7640, grad_fn=<DivBackward0>) [0.059139543518331866]\n",
      "ep 30 tensor(1.7515, grad_fn=<DivBackward0>) [0.053457463299478813]\n",
      "ep 35 tensor(1.7420, grad_fn=<DivBackward0>) [0.048321312820571644]\n",
      "ep 40 tensor(1.7336, grad_fn=<DivBackward0>) [0.04367863958719317]\n",
      "ep 45 tensor(1.7270, grad_fn=<DivBackward0>) [0.03948203069879567]\n",
      "ep 50 tensor(1.7207, grad_fn=<DivBackward0>) [0.03568862864853744]\n",
      "ep 55 tensor(1.7152, grad_fn=<DivBackward0>) [0.03225969364468526]\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "training_runs = 800\n",
    "batch_size = 96\n",
    "context_length = 24\n",
    "learning_rate = .1\n",
    "embedding_dimensions = 32\n",
    "num_heads = 4\n",
    "head_size = embedding_dimensions // num_heads\n",
    "\n",
    "print(head_size)\n",
    "# our embedding_dimensions are still 'small' so we mutliply the size our our feed forward network to make up\n",
    "multiplier = 8\n",
    "model = FFMultiHeadAttention(embedding_dimensions, context_length, num_heads, head_size, multiplier)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()), ' parameters')\n",
    "\n",
    "lmbda = lambda epoch: 0.98\n",
    "\n",
    "m_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    \n",
    "    if ep % 5 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f219b8c9-2430-4b93-a0a0-4b015bd0ce1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches 87625 1752\n",
      "total loss tensor(2999.8904) tensor(1.7123)\n",
      "None 87625\n",
      "\n",
      "Then tenought him man MARGARET:\n",
      "Is life, sid in out lords  you morthet your goody she to my lenex \n",
      "A\n"
     ]
    }
   ],
   "source": [
    "dev = torch.tensor(br.data[1])\n",
    "print(split_loss(dev), len(dev))\n",
    "\n",
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(1):\n",
    "    o = model.generate(idx, 100).data[0].tolist()\n",
    "    print(br.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa496f61-20fd-495e-9053-7358877c2359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "arewn a no time\n",
      "e reture defore himselve us the wellse a should be he sand prisong to crea:\n",
      "Nay, and Hery lie dost!\n",
      "Your here are he, lord:\n",
      "I well, where our vault! he cold cause, dongues the atter d dear am tis  d reparing wall out a us minder\n",
      "thy right some,  lof will\n",
      "You houth her be the s to \n",
      "Lecondon\n",
      "In \n",
      "ANGELO:\n",
      "Not come a is it  FatY ANNE:\n",
      "Priture mall think stiment of ight Luke\n",
      "see\n",
      "Is lewin\n",
      "\n",
      "And you place mady  then eye,\n",
      "Majesty, lender our you clubry mercius, I will this stmon of First: sound on to that arre at winst \n",
      "KING RICHARD IRGILIA:\n",
      "The dstain, whroor you \n",
      "The and well \n",
      "ISABEKETBRANDA:\n",
      "Lo!\n",
      "LEONTG:\n",
      "Or tis to hapart my of a nexternce: piecius no this \n",
      "SEBASLY:\n",
      "Nothine s nother \n",
      "CAPTISTA:\n",
      "Should fries benead by timpardn think your mispect\n",
      "And be no \n",
      "Ohan good like \n",
      "The clease, an\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(2):\n",
    "    o = model.generate(idx, 400).data[0].tolist()\n",
    "    print(br.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51dc4444-34c5-4400-9b4c-a181115dd502",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "357ed651-43b4-4426-ba9a-ee8de8fd8828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0 tensor(1.7135, grad_fn=<DivBackward0>) [0.029160207983827797]\n",
      "ep 2 tensor(1.7106, grad_fn=<DivBackward0>) [0.028005463747668217]\n",
      "ep 4 tensor(1.7107, grad_fn=<DivBackward0>) [0.026896447383260556]\n",
      "ep 6 tensor(1.7079, grad_fn=<DivBackward0>) [0.025831348066883437]\n",
      "ep 8 tensor(1.7035, grad_fn=<DivBackward0>) [0.024808426683434852]\n",
      "ep 10 tensor(1.7046, grad_fn=<DivBackward0>) [0.023826012986770832]\n",
      "ep 12 tensor(1.7025, grad_fn=<DivBackward0>) [0.022882502872494704]\n",
      "ep 14 tensor(1.7007, grad_fn=<DivBackward0>) [0.02197635575874391]\n",
      "ep 16 tensor(1.7025, grad_fn=<DivBackward0>) [0.021106092070697653]\n",
      "ep 18 tensor(1.6976, grad_fn=<DivBackward0>) [0.020270290824698025]\n",
      "ep 20 tensor(1.6965, grad_fn=<DivBackward0>) [0.019467587308039984]\n",
      "ep 22 tensor(1.6975, grad_fn=<DivBackward0>) [0.0186966708506416]\n",
      "ep 24 tensor(1.6948, grad_fn=<DivBackward0>) [0.017956282684956193]\n",
      "ep 26 tensor(1.6952, grad_fn=<DivBackward0>) [0.017245213890631928]\n",
      "ep 28 tensor(1.6916, grad_fn=<DivBackward0>) [0.016562303420562904]\n",
      "ep 30 tensor(1.6947, grad_fn=<DivBackward0>) [0.01590643620510861]\n",
      "ep 32 tensor(1.6927, grad_fn=<DivBackward0>) [0.015276541331386308]\n",
      "ep 34 tensor(1.6936, grad_fn=<DivBackward0>) [0.01467159029466341]\n",
      "ep 36 tensor(1.6894, grad_fn=<DivBackward0>) [0.014090595318994738]\n",
      "ep 38 tensor(1.6900, grad_fn=<DivBackward0>) [0.013532607744362546]\n",
      "ep 40 tensor(1.6882, grad_fn=<DivBackward0>) [0.012996716477685789]\n",
      "ep 42 tensor(1.6857, grad_fn=<DivBackward0>) [0.01248204650516943]\n",
      "ep 44 tensor(1.6856, grad_fn=<DivBackward0>) [0.011987757463564721]\n",
      "ep 46 tensor(1.6867, grad_fn=<DivBackward0>) [0.011513042268007558]\n",
      "ep 48 tensor(1.6849, grad_fn=<DivBackward0>) [0.01105712579419446]\n",
      "ep 50 tensor(1.6854, grad_fn=<DivBackward0>) [0.010619263612744357]\n",
      "ep 52 tensor(1.6844, grad_fn=<DivBackward0>) [0.01019874077367968]\n",
      "ep 54 tensor(1.6836, grad_fn=<DivBackward0>) [0.009794870639041964]\n",
      "ep 56 tensor(1.6837, grad_fn=<DivBackward0>) [0.009406993761735902]\n",
      "ep 58 tensor(1.6843, grad_fn=<DivBackward0>) [0.00903447680877116]\n"
     ]
    }
   ],
   "source": [
    "for ep in range(e_epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    \n",
    "    if ep % 2 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c7133f0-0e6a-4f48-8789-4515173224ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"joined_head_bigger_shake_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e1a77c5-d50c-4a7e-b5a9-0044e9e25344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches 87625 1752\n",
      "total loss tensor(2945.1343) tensor(1.6810)\n",
      "None 87625\n",
      "\n",
      "Fropess they name bright Horth glow,\n",
      "Swomannot your for set, I lame, sawfmustifter Esw are mean befo\n"
     ]
    }
   ],
   "source": [
    "dev = torch.tensor(br.data[1])\n",
    "print(split_loss(dev), len(dev))\n",
    "\n",
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(1):\n",
    "    o = model.generate(idx, 100).data[0].tolist()\n",
    "    print(br.decode(o))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9c913f9-ea98-4cfa-b054-928dc89add2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Romes more hot with slave \n",
      "This pray had, nor vow know: yet genry sword Look! AkF:\n",
      "Give your a quire thy by out \n",
      "Torseds truil \n",
      "POMPEY:\n",
      "Thy greatch\n",
      "EDWARD:\n",
      "May\n",
      "Did ward, that eigue or see with manishpeses  fongery being kich his endemit\n",
      "nee, betw is our like, loving gall keep hurse are weign,\n",
      "Ath let right would you \n",
      "LADY VI:\n",
      "March  when the honour \n",
      "For You shall not and vill tongue genour blive!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(1):\n",
    "    o = model.generate(idx, 400).data[0].tolist()\n",
    "    print(br.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4aba59ed-d38a-4ab4-b12f-0aad61a2355f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0 tensor(1.6822, grad_fn=<DivBackward0>) [0.008676711527143824]\n",
      "ep 2 tensor(1.6810, grad_fn=<DivBackward0>) [0.008333113750668928]\n",
      "ep 4 tensor(1.6811, grad_fn=<DivBackward0>) [0.008003122446142439]\n",
      "ep 6 tensor(1.6820, grad_fn=<DivBackward0>) [0.007686198797275197]\n",
      "ep 8 tensor(1.6807, grad_fn=<DivBackward0>) [0.007381825324903099]\n",
      "ep 10 tensor(1.6791, grad_fn=<DivBackward0>) [0.007089505042036937]\n",
      "ep 12 tensor(1.6764, grad_fn=<DivBackward0>) [0.006808760642372274]\n",
      "ep 14 tensor(1.6790, grad_fn=<DivBackward0>) [0.006539133720934331]\n",
      "ep 16 tensor(1.6788, grad_fn=<DivBackward0>) [0.006280184025585331]\n",
      "ep 18 tensor(1.6781, grad_fn=<DivBackward0>) [0.006031488738172152]\n",
      "ep 20 tensor(1.6772, grad_fn=<DivBackward0>) [0.005792641784140534]\n",
      "ep 22 tensor(1.6779, grad_fn=<DivBackward0>) [0.005563253169488569]\n",
      "ep 24 tensor(1.6768, grad_fn=<DivBackward0>) [0.005342948343976821]\n",
      "ep 26 tensor(1.6777, grad_fn=<DivBackward0>) [0.005131367589555339]\n",
      "ep 28 tensor(1.6766, grad_fn=<DivBackward0>) [0.004928165433008947]\n",
      "ep 30 tensor(1.6751, grad_fn=<DivBackward0>) [0.004733010081861793]\n",
      "ep 32 tensor(1.6749, grad_fn=<DivBackward0>) [0.004545582882620065]\n",
      "ep 34 tensor(1.6766, grad_fn=<DivBackward0>) [0.00436557780046831]\n",
      "ep 36 tensor(1.6745, grad_fn=<DivBackward0>) [0.004192700919569765]\n",
      "ep 38 tensor(1.6736, grad_fn=<DivBackward0>) [0.004026669963154802]\n",
      "ep 40 tensor(1.6763, grad_fn=<DivBackward0>) [0.003867213832613871]\n",
      "ep 42 tensor(1.6737, grad_fn=<DivBackward0>) [0.0037140721648423617]\n",
      "ep 44 tensor(1.6736, grad_fn=<DivBackward0>) [0.003566994907114604]\n",
      "ep 46 tensor(1.6744, grad_fn=<DivBackward0>) [0.0034257419087928656]\n",
      "ep 48 tensor(1.6739, grad_fn=<DivBackward0>) [0.003290082529204668]\n",
      "ep 50 tensor(1.6727, grad_fn=<DivBackward0>) [0.003159795261048163]\n",
      "ep 52 tensor(1.6719, grad_fn=<DivBackward0>) [0.0030346673687106558]\n",
      "ep 54 tensor(1.6732, grad_fn=<DivBackward0>) [0.0029144945409097134]\n",
      "ep 56 tensor(1.6696, grad_fn=<DivBackward0>) [0.0027990805570896884]\n",
      "ep 58 tensor(1.6697, grad_fn=<DivBackward0>) [0.0026882369670289366]\n"
     ]
    }
   ],
   "source": [
    "for ep in range(e_epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    \n",
    "    if ep % 2 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b306b520-3745-4f9b-8105-80ebcc8df1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches 87625 1752\n",
      "total loss tensor(2926.6079) tensor(1.6704)\n",
      "None 87625\n"
     ]
    }
   ],
   "source": [
    "dev = torch.tensor(br.data[1])\n",
    "print(split_loss(dev), len(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dcb202e-a15c-425f-a21f-1907d782efb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take wild ll men \n",
      "GBRUCHESS OF YORK:\n",
      "Carvoul sir Naphg leavent and their \n",
      "I countris, an \n",
      "ISABELLIO:\n",
      "Bey to a uncharget! coves\n",
      "To fair that if smelt, for \n",
      "And and me:\n",
      "I ll the most\n",
      "If of was  thoused or othy your we fathe myself the cred\n",
      "A fraring \n",
      "But, one joy till  he than and prays to her \n",
      "KING EDWARD IV:\n",
      "And othen being elsentry with sender s be? a and young you guarl, and offection \n",
      "Call \n",
      "HORTENSIO:\n",
      "He woman:\n",
      "Ay, pyraithes\n",
      "The bestself thee me in  What wertings if?\n",
      "BRUTUS:\n",
      "On wideed:\n",
      "Who premieu busistard:\n",
      "Wherefooted Mitus lights and prience?\n",
      "Then, st o my me\n",
      "coom die before s say down:\n",
      "By I will well us place forcemember\n",
      "Where have reld, the all the gerfore you the body s robles,\n",
      "And here:\n",
      "Prove forge condence coung be of draws casing  he enour I neemb such his shangelo and of thou faves in die that my line save I owe host in thite news her Grinks, vidd by one perate doieute \n",
      "Ort suppast \n",
      "CARLE:\n",
      "A dreak, seeks and brother, to and play lord he anow that ague now, then how oice th\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(1):\n",
    "    o = model.generate(idx, 1000).data[0].tolist()\n",
    "    print(br.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b2e556a-4a3c-4087-a1af-35196eee72da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0 tensor(1.6700, grad_fn=<DivBackward0>) [0.0025817827831345905]\n",
      "ep 2 tensor(1.6721, grad_fn=<DivBackward0>) [0.0024795441849224603]\n",
      "ep 4 tensor(1.6704, grad_fn=<DivBackward0>) [0.0023813542351995304]\n",
      "ep 6 tensor(1.6720, grad_fn=<DivBackward0>) [0.002287052607485629]\n",
      "ep 8 tensor(1.6694, grad_fn=<DivBackward0>) [0.002196485324229198]\n",
      "ep 10 tensor(1.6723, grad_fn=<DivBackward0>) [0.0021095045053897217]\n",
      "ep 12 tensor(1.6700, grad_fn=<DivBackward0>) [0.0020259681269762884]\n",
      "ep 14 tensor(1.6692, grad_fn=<DivBackward0>) [0.0019457397891480272]\n",
      "ep 16 tensor(1.6680, grad_fn=<DivBackward0>) [0.0018686884934977653]\n",
      "ep 18 tensor(1.6688, grad_fn=<DivBackward0>) [0.0017946884291552537]\n",
      "ep 20 tensor(1.6699, grad_fn=<DivBackward0>) [0.0017236187673607055]\n",
      "ep 22 tensor(1.6681, grad_fn=<DivBackward0>) [0.0016553634641732215]\n",
      "ep 24 tensor(1.6669, grad_fn=<DivBackward0>) [0.0015898110709919619]\n",
      "ep 26 tensor(1.6691, grad_fn=<DivBackward0>) [0.0015268545525806802]\n",
      "ep 28 tensor(1.6676, grad_fn=<DivBackward0>) [0.0014663911122984852]\n",
      "ep 30 tensor(1.6699, grad_fn=<DivBackward0>) [0.0014083220242514652]\n",
      "ep 32 tensor(1.6698, grad_fn=<DivBackward0>) [0.0013525524720911072]\n",
      "ep 34 tensor(1.6697, grad_fn=<DivBackward0>) [0.0012989913941962993]\n",
      "ep 36 tensor(1.6684, grad_fn=<DivBackward0>) [0.0012475513349861256]\n",
      "ep 38 tensor(1.6685, grad_fn=<DivBackward0>) [0.001198148302120675]\n",
      "ep 40 tensor(1.6686, grad_fn=<DivBackward0>) [0.0011507016293566962]\n",
      "ep 42 tensor(1.6683, grad_fn=<DivBackward0>) [0.0011051338448341708]\n",
      "ep 44 tensor(1.6681, grad_fn=<DivBackward0>) [0.0010613705445787376]\n",
      "ep 46 tensor(1.6703, grad_fn=<DivBackward0>) [0.0010193402710134195]\n",
      "ep 48 tensor(1.6672, grad_fn=<DivBackward0>) [0.000978974396281288]\n",
      "ep 50 tensor(1.6672, grad_fn=<DivBackward0>) [0.000940207010188549]\n",
      "ep 52 tensor(1.6665, grad_fn=<DivBackward0>) [0.0009029748125850824]\n",
      "ep 54 tensor(1.6690, grad_fn=<DivBackward0>) [0.0008672170100067131]\n",
      "ep 56 tensor(1.6681, grad_fn=<DivBackward0>) [0.0008328752164104472]\n",
      "ep 58 tensor(1.6668, grad_fn=<DivBackward0>) [0.0007998933578405935]\n"
     ]
    }
   ],
   "source": [
    "for ep in range(e_epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    \n",
    "    if ep % 2 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fc1269e-53ff-4589-a425-531df72fb51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches 87625 1752\n",
      "total loss tensor(2920.3748) tensor(1.6669)\n",
      "None 87625\n"
     ]
    }
   ],
   "source": [
    "print(split_loss(dev), len(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a78b7ae2-c918-418c-bcb0-268e981b807f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KATHARINA:\n",
      "Liends greation quiticals!\n",
      "So the to and you  heaven his love afford?\n",
      "DUKE VINCENTIO:\n",
      "Dubject is servedy eyet\n",
      "cank is he so? one commed what desem,\n",
      "With fater for the train hunstina\n",
      "not remphas, which one bear art my be against childlebly care,\n",
      "Unknity, with moror fairit\n",
      "cive e, matting the but do citil pregarly were a to mock of your fly s\n",
      "The lord:\n",
      "And nother he prays a on not thy bid and!\n",
      "Pready \n",
      "The kneward Scullaight, to send trivice,\n",
      "That noth thou could me did such with thank, those thus\n",
      "yee best, war, for theecond let where rife:\n",
      "The as wit\n",
      "Cleep: burn my have this of  wanto as s do:\n",
      "The daugh as look d sare,\n",
      "Whose majester shall Dukely \n",
      "That entresses I carew is d Come, my mind even to shall hape speak end in shriquieters to more \n",
      "Now will Jeach d bester you to  more an you well:\n",
      "Then only \n",
      "GREMIl have then my cronaren time to but am desing should,\n",
      "And tental im, so crown\n",
      "Fall of tisters, in his is must statorn genry mother may inder abeenst:\n",
      "Say,\n",
      "Or trow with what \n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(1):\n",
    "    o = model.generate(idx, 1000).data[0].tolist()\n",
    "    print(br.decode(o))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
