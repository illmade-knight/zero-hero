{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "965b36f1-1440-4a07-a843-80cba31c34e8",
   "metadata": {},
   "source": [
    "### Add an attention head to our sequence\n",
    "\n",
    "with what we've learnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d689a91-95ca-42cd-802e-ab97496243cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8919ad-3d6b-4421-94ce-553e3a506dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run bookreader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b6ef18-283c-41fd-9375-ef8d13ed5e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = BookReader(\"names.txt\")\n",
    "vocab_size = names.vocab_size\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a713daf8-4a5f-430d-8f00-9c6db6743d22",
   "metadata": {},
   "source": [
    "### Get the batch with both x and y unseparated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f9fe0b-25d9-4578-a105-4eb99138428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, batch_length=5, batch_size=5):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    ix = torch.randint(len(data) - batch_length, (batch_size,))\n",
    "    b = torch.stack([data[i:i+batch_length] for i in ix])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3b116f-f526-4958-bfed-07f665e89cba",
   "metadata": {},
   "source": [
    "### Create an attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56041610-5973-4c4e-9e3c-969def35525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_size = 7\n",
    "channels = 3\n",
    "context_length = 8\n",
    "\n",
    "tril = torch.tril(torch.ones(context_length, context_length))\n",
    "\n",
    "key = nn.Linear(channels, head_size, bias=False)\n",
    "query = nn.Linear(channels, head_size, bias=False)\n",
    "## add in \n",
    "value = nn.Linear(channels, head_size, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82198220-b1ad-4c51-8544-849bdbd6e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "x = torch.randn(batch_size, context_length, channels)\n",
    "\n",
    "k = key(x)\n",
    "# k = B, T, head_size  - 4, 8, 7\n",
    "q = query(x)\n",
    "# k = B, T, head_size\n",
    "\n",
    "#the dot product tells us how much our query matches our key\n",
    "kq_match = k @ q.transpose(-2,-1) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28e47b2b-5cfb-4ade-ad0d-3f1b3b11e132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1143, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0508, 0.1228, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1237, 0.1388, 0.1592, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1940, 0.1616, 0.1235, 0.1688, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1224, 0.1298, 0.1263, 0.2108, 0.2603, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0857, 0.1490, 0.2276, 0.2128, 0.2024, 0.3855, 0.0000, 0.0000],\n",
      "        [0.0624, 0.1271, 0.2544, 0.2526, 0.1743, 0.4549, 0.7471, 0.0000],\n",
      "        [0.2466, 0.1708, 0.1090, 0.1550, 0.3630, 0.1596, 0.2529, 1.0000]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0620, -0.1640,  0.0303,  0.1762, -0.0439, -0.0426, -0.1908],\n",
       "         [-0.1111, -0.1128,  0.1580,  0.0957, -0.1416, -0.0184, -0.0864],\n",
       "         [-0.1647, -0.1870,  0.2002,  0.2375, -0.2416, -0.0529, -0.2055],\n",
       "         [-0.1197, -0.2294,  0.0875,  0.2996, -0.1501, -0.0720, -0.2907],\n",
       "         [-0.0813, -0.2819, -0.0177,  0.3719, -0.0662, -0.0935, -0.3861],\n",
       "         [-0.0538,  0.1168,  0.1120,  0.0348, -0.2339, -0.0070,  0.0639],\n",
       "         [-0.3949,  0.4814,  0.8636, -0.0927, -1.1537,  0.0452,  0.4958],\n",
       "         [ 0.4675,  0.1928, -0.9063,  0.1883,  0.5611, -0.0801, -0.2070]],\n",
       "        grad_fn=<SelectBackward0>),\n",
       " torch.Size([4, 8, 7]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_affin = kq_match.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(masked_affin, 1)\n",
    "\n",
    "print(wei[0])\n",
    "\n",
    "wei[0]\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "out[0], out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf6cf111-bf37-49fe-8e92-de8a35f8e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, c, head_size, content_length):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(c, head_size, bias=False)\n",
    "        self.query = nn.Linear(c, head_size, bias=False)\n",
    "        self.value = nn.Linear(c, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(content_length, content_length)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   \n",
    "        q = self.query(x)\n",
    "        \n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 \n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        \n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d5d2c4-7f1a-4f79-9703-ab2d66f2b123",
   "metadata": {},
   "source": [
    "### For a start we're going to feed a sequential model\n",
    "\n",
    "ignore the positional encoding for a start so we can see what impact it has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b47ce7b-24d3-4876-a3d5-c25cf2e6a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.tensor(names.data[0])\n",
    "\n",
    "def get_batch(data, batch_length=5, batch_size=5):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    ix = torch.randint(len(data) - batch_length, (batch_size,))\n",
    "    b = torch.stack([data[i:i+batch_length] for i in ix])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "948635f1-7d0d-4a4f-9a83-5d91f2fa2fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "nonlin = 'relu'\n",
    "\n",
    "def create_model(embed_size, content_length):\n",
    "\n",
    "    seq = OrderedDict([\n",
    "        ('embed', nn.Embedding(vocab_size, embed_size)),\n",
    "        ('attention', Head(embed_size, head_size)),\n",
    "        ('decode', nn.Linear(head_size, vocab_size)),\n",
    "    ])\n",
    "\n",
    "    md = nn.Sequential(seq)\n",
    "    \n",
    "    return md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c18e25-c38c-4924-9ed0-eac5b544e34c",
   "metadata": {},
   "source": [
    "### First run through sequence\n",
    "\n",
    "just like we had it before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3181315-70c2-4f1b-9314-6e54ddf0e9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7617, grad_fn=<DivBackward0>)\n",
      "tensor(2.5831, grad_fn=<DivBackward0>)\n",
      "tensor(2.5330, grad_fn=<DivBackward0>)\n",
      "tensor(2.5134, grad_fn=<DivBackward0>)\n",
      "tensor(2.5002, grad_fn=<DivBackward0>)\n",
      "tensor(2.4917, grad_fn=<DivBackward0>)\n",
      "tensor(2.4869, grad_fn=<DivBackward0>)\n",
      "tensor(2.4772, grad_fn=<DivBackward0>)\n",
      "tensor(2.4701, grad_fn=<DivBackward0>)\n",
      "tensor(2.4711, grad_fn=<DivBackward0>)\n",
      "tensor(2.4674, grad_fn=<DivBackward0>)\n",
      "tensor(2.4644, grad_fn=<DivBackward0>)\n",
      "tensor(2.4624, grad_fn=<DivBackward0>)\n",
      "tensor(2.4635, grad_fn=<DivBackward0>)\n",
      "tensor(2.4667, grad_fn=<DivBackward0>)\n",
      "tensor(2.4567, grad_fn=<DivBackward0>)\n",
      "tensor(2.4563, grad_fn=<DivBackward0>)\n",
      "tensor(2.4610, grad_fn=<DivBackward0>)\n",
      "tensor(2.4535, grad_fn=<DivBackward0>)\n",
      "tensor(2.4544, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "training_runs = 1000\n",
    "batch_size = 24\n",
    "context_length = 4\n",
    "learning_rate = .1\n",
    "embedding_dimensions = 9\n",
    "\n",
    "model = create_model(embedding_dimensions, context_length)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # , weight_decay=args.weight_decay, betas=(0.9, 0.99), eps=1e-8)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits = model.forward(x)\n",
    "        \n",
    "        Y = y.reshape(-1)\n",
    "        loss = F.cross_entropy(logits.view(-1, vocab_size), Y) # loss function\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(epoch_loss/training_runs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53043ea-423c-4fe2-a93d-9a68721d7678",
   "metadata": {},
   "source": [
    "## OK it's doing something, what?\n",
    "\n",
    "now we've got loss that looks similar to our bigram model \n",
    "\n",
    "and a thing to note is that the model at the moment is linear - just a big ole linear model\n",
    "\n",
    "we're going to add in the position embedding now but the model will still be a linear one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49f76262-bf4d-40b1-bd5e-250a7da35102",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, content_length):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.positional_embed = nn.Embedding(content_length, embed_size)\n",
    "        self.attention = Head(embed_size, head_size, content_length)\n",
    "        self.decode = nn.Linear(head_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets):\n",
    "        #idx B,T\n",
    "        B, T = idx.shape\n",
    "\n",
    "        idx_e = self.vocab_embed(idx)\n",
    "        # note tr is always the same - so the learning here is information passed back to the positional_embed from loss\n",
    "        tr = torch.arange(T)\n",
    "        pos_e = self.positional_embed(tr)\n",
    "\n",
    "        x = idx_e + pos_e\n",
    "        x = self.attention(x)\n",
    "        logits = self.decode(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits.view(B*T, -1), targets.resize(B*T)) # loss function\n",
    "\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cc9c4987-ff27-4347-a610-87edfd6b3501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7402, grad_fn=<DivBackward0>)\n",
      "tensor(2.5816, grad_fn=<DivBackward0>)\n",
      "tensor(2.5323, grad_fn=<DivBackward0>)\n",
      "tensor(2.5098, grad_fn=<DivBackward0>)\n",
      "tensor(2.5020, grad_fn=<DivBackward0>)\n",
      "tensor(2.4873, grad_fn=<DivBackward0>)\n",
      "tensor(2.4857, grad_fn=<DivBackward0>)\n",
      "tensor(2.4797, grad_fn=<DivBackward0>)\n",
      "tensor(2.4760, grad_fn=<DivBackward0>)\n",
      "tensor(2.4748, grad_fn=<DivBackward0>)\n",
      "tensor(2.4680, grad_fn=<DivBackward0>)\n",
      "tensor(2.4647, grad_fn=<DivBackward0>)\n",
      "tensor(2.4637, grad_fn=<DivBackward0>)\n",
      "tensor(2.4602, grad_fn=<DivBackward0>)\n",
      "tensor(2.4598, grad_fn=<DivBackward0>)\n",
      "tensor(2.4551, grad_fn=<DivBackward0>)\n",
      "tensor(2.4603, grad_fn=<DivBackward0>)\n",
      "tensor(2.4542, grad_fn=<DivBackward0>)\n",
      "tensor(2.4511, grad_fn=<DivBackward0>)\n",
      "tensor(2.4558, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "training_runs = 1000\n",
    "batch_size = 24\n",
    "context_length = 4\n",
    "learning_rate = .1\n",
    "embedding_dimensions = 9\n",
    "\n",
    "model = Attention(embedding_dimensions, context_length)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # , weight_decay=args.weight_decay, betas=(0.9, 0.99), eps=1e-8)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(epoch_loss/training_runs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa6621d-79e1-4ece-8034-6b3d5159ce3e",
   "metadata": {},
   "source": [
    "### Hum we'll need something more...\n",
    "\n",
    "we're still just learning a linear approximation of names - and the positional_encoding hasn't helped\n",
    "\n",
    "attention has created a kind of lookup table but that's all\n",
    "\n",
    "(lets come back and see if we can analyse *what* it's looking up later)\n",
    "\n",
    "for a start lets add some non-linearity to all this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7138eed8-721e-4752-bf9f-8ebca24882d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, fan_in, multiplier = 4):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = OrderedDict([\n",
    "            (\"l_in\", nn.Linear(fan_in, multiplier * fan_in)),\n",
    "            (\"relu\", nn.ReLU()),\n",
    "            (\"l_out\", nn.Linear(multiplier * fan_in, fan_in)),\n",
    "        ])\n",
    "        self.net = nn.Sequential(\n",
    "            layers\n",
    "        )\n",
    "\n",
    "        initial = layers['l_in']\n",
    "        nn.init.kaiming_normal_(initial.weight, nonlinearity=\"relu\")\n",
    "        layers['l_in'].weight.data = initial.weight.data * 3/5\n",
    "        if initial.bias is not None:\n",
    "            nn.init.constant_(initial.bias, 0)\n",
    "\n",
    "        final = layers['l_out']\n",
    "        layers['l_out'].weight.data = final.weight.data * .2\n",
    "        if final.bias is not None:\n",
    "            nn.init.constant_(final.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "cee0cbcc-380d-4da9-a9e2-626359763ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention out torch.Size([48, 4, 8])\n",
      "feed forward out torch.Size([48, 4, 8])\n",
      "logits out torch.Size([48, 4, 8])\n",
      "targets torch.Size([48, 4])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[239], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m t_b[:, \u001b[38;5;241m0\u001b[39m:context_length]\n\u001b[0;32m     18\u001b[0m y \u001b[38;5;241m=\u001b[39m t_b[:, \u001b[38;5;241m1\u001b[39m:context_length\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 20\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m model(x, y)\n\u001b[0;32m     22\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "training_runs = 1000\n",
    "batch_size = 48\n",
    "context_length = 4\n",
    "learning_rate = .2\n",
    "head_size = 8\n",
    "embedding_dimensions = 9\n",
    "\n",
    "model = FFAttention(embedding_dimensions, head_size, context_length)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # , weight_decay=args.weight_decay, betas=(0.9, 0.99), eps=1e-8)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(epoch_loss/training_runs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c5ab893-cdb8-4702-9459-99a717f81b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, head_size, content_length):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.positional_embed = nn.Embedding(content_length, embed_size)\n",
    "        self.attention = Head(embed_size, head_size, content_length)\n",
    "        self.ff = FeedForward(head_size)\n",
    "        self.decode = nn.Linear(head_size, vocab_size)\n",
    "        self.content_length = content_length\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        #idx B,T\n",
    "        B, T = idx.shape\n",
    "\n",
    "        idx_e = self.vocab_embed(idx)\n",
    "        # note tr is always the same - so the learning here is information passed back to the positional_embed from loss\n",
    "        tr = torch.arange(T)\n",
    "        pos_e = self.positional_embed(tr)\n",
    "\n",
    "        x = idx_e + pos_e\n",
    "        x = self.attention(x)\n",
    "        x = self.ff(x)\n",
    "        logits = self.decode(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits.view(B*T, -1), targets.resize(B*T)) # loss function\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -self.content_length:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b7e8592a-4c97-467d-9373-c2a4ba054d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6730, grad_fn=<DivBackward0>)\n",
      "tensor(2.4969, grad_fn=<DivBackward0>)\n",
      "tensor(2.4687, grad_fn=<DivBackward0>)\n",
      "tensor(2.4532, grad_fn=<DivBackward0>)\n",
      "tensor(2.4413, grad_fn=<DivBackward0>)\n",
      "tensor(2.4375, grad_fn=<DivBackward0>)\n",
      "tensor(2.4308, grad_fn=<DivBackward0>)\n",
      "tensor(2.4313, grad_fn=<DivBackward0>)\n",
      "tensor(2.4242, grad_fn=<DivBackward0>)\n",
      "tensor(2.4196, grad_fn=<DivBackward0>)\n",
      "tensor(2.4154, grad_fn=<DivBackward0>)\n",
      "tensor(2.4107, grad_fn=<DivBackward0>)\n",
      "tensor(2.4114, grad_fn=<DivBackward0>)\n",
      "tensor(2.4085, grad_fn=<DivBackward0>)\n",
      "tensor(2.4060, grad_fn=<DivBackward0>)\n",
      "tensor(2.4025, grad_fn=<DivBackward0>)\n",
      "tensor(2.4023, grad_fn=<DivBackward0>)\n",
      "tensor(2.3965, grad_fn=<DivBackward0>)\n",
      "tensor(2.3984, grad_fn=<DivBackward0>)\n",
      "tensor(2.3961, grad_fn=<DivBackward0>)\n",
      "tensor(2.3971, grad_fn=<DivBackward0>)\n",
      "tensor(2.3921, grad_fn=<DivBackward0>)\n",
      "tensor(2.3880, grad_fn=<DivBackward0>)\n",
      "tensor(2.3906, grad_fn=<DivBackward0>)\n",
      "tensor(2.3877, grad_fn=<DivBackward0>)\n",
      "tensor(2.3841, grad_fn=<DivBackward0>)\n",
      "tensor(2.3857, grad_fn=<DivBackward0>)\n",
      "tensor(2.3842, grad_fn=<DivBackward0>)\n",
      "tensor(2.3883, grad_fn=<DivBackward0>)\n",
      "tensor(2.3887, grad_fn=<DivBackward0>)\n",
      "tensor(2.3793, grad_fn=<DivBackward0>)\n",
      "tensor(2.3852, grad_fn=<DivBackward0>)\n",
      "tensor(2.3827, grad_fn=<DivBackward0>)\n",
      "tensor(2.3838, grad_fn=<DivBackward0>)\n",
      "tensor(2.3839, grad_fn=<DivBackward0>)\n",
      "tensor(2.3813, grad_fn=<DivBackward0>)\n",
      "tensor(2.3789, grad_fn=<DivBackward0>)\n",
      "tensor(2.3814, grad_fn=<DivBackward0>)\n",
      "tensor(2.3776, grad_fn=<DivBackward0>)\n",
      "tensor(2.3787, grad_fn=<DivBackward0>)\n",
      "tensor(2.3799, grad_fn=<DivBackward0>)\n",
      "tensor(2.3782, grad_fn=<DivBackward0>)\n",
      "tensor(2.3819, grad_fn=<DivBackward0>)\n",
      "tensor(2.3797, grad_fn=<DivBackward0>)\n",
      "tensor(2.3775, grad_fn=<DivBackward0>)\n",
      "tensor(2.3755, grad_fn=<DivBackward0>)\n",
      "tensor(2.3754, grad_fn=<DivBackward0>)\n",
      "tensor(2.3803, grad_fn=<DivBackward0>)\n",
      "tensor(2.3770, grad_fn=<DivBackward0>)\n",
      "tensor(2.3805, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "training_runs = 1000\n",
    "batch_size = 48\n",
    "context_length = 4\n",
    "learning_rate = .2\n",
    "embedding_dimensions = 9\n",
    "\n",
    "model = FFAttention(embedding_dimensions, head_size, context_length)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # , weight_decay=args.weight_decay, betas=(0.9, 0.99), eps=1e-8)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(epoch_loss/training_runs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8ab9a64a-4bde-4758-8aa1-aa08c9844e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "maizzylin\n",
      "kari\n",
      "kendowero\n",
      "denli\n",
      "drala\n",
      "kelyn\n",
      "ali\n",
      "lajyde\n",
      "adce\n",
      "alyarieztyna\n",
      "trash\n",
      "trabrannge\n",
      "lakidyanty\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(1):\n",
    "    o = model.generate(idx, 100).data[0].tolist()\n",
    "    print(names.decode(o))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25343b3-9818-4b4e-86b1-06e053f6f4f0",
   "metadata": {},
   "source": [
    "## OK we're back to 'learning'\n",
    "\n",
    "rather than remembering\n",
    "\n",
    "lets add more heads and look at things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c7ae8761-3bfa-412b-9fd8-33b1406f436f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4, 16])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 8])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, t, hs = 5, 4, 8\n",
    "num_heads = 2\n",
    "h1 = torch.zeros(b, t, hs)\n",
    "h2 = torch.ones(b, t, hs)\n",
    "cat_out = torch.cat([h1, h2], dim=-1)\n",
    "print(cat_out.shape)\n",
    "print(cat_out[0])\n",
    "prog = torch.randn(16, 8)\n",
    "prog_out = cat_out @ prog\n",
    "prog_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "989f2ee4-1968-4bf6-8352-4e37ebaca633",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHead(nn.Module):\n",
    "\n",
    "    def __init__(self, num_heads, head_size, embed_size, content_length):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(embed_size, head_size, content_length) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat( [head(x) for head in self.heads], dim = -1 )\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dff586a7-6f05-4e2a-95f4-9a07c8e27203",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFMultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, content_length, num_heads, head_size, multiplier=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.positional_embed = nn.Embedding(content_length, embed_size)\n",
    "        self.mutli_attention = MultiHead(num_heads, head_size, embed_size, content_length)\n",
    "        self.lna = nn.LayerNorm(embed_size)\n",
    "        self.ff = FeedForward(embed_size, multiplier)\n",
    "        self.lnff = nn.LayerNorm(embed_size)\n",
    "        self.decode = nn.Linear(embed_size, vocab_size)\n",
    "        self.content_length = content_length\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        #idx B,T\n",
    "        B, T = idx.shape\n",
    "\n",
    "        idx_e = self.vocab_embed(idx)\n",
    "        # note tr is always the same - so the learning here is information passed back to the positional_embed from loss\n",
    "        tr = torch.arange(T)\n",
    "        pos_e = self.positional_embed(tr)\n",
    "\n",
    "        x = idx_e + pos_e\n",
    "        x = self.mutli_attention(x)\n",
    "        # print(\"multi ball out\", x.shape)\n",
    "        x = self.lna(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.lnff(x)\n",
    "        # print(\"feed forward out\", x.shape)\n",
    "        logits = self.decode(x)\n",
    "        # print(\"decode out\", x.shape)\n",
    "        # print(\"targets\", targets.shape)\n",
    "        # return None, None\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            targets = targets.reshape(B*T)\n",
    "            loss = F.cross_entropy(logits.view(B*T, -1), targets) #.resize(B*T)) # loss function\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    # we're restorspectively adding generate because we're getting genuinely better results here\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -self.content_length:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b77ec387-64c7-43b3-82a5-b24e22eb84a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "22355b0d-b5c2-4958-8d62-02e6c9dd476a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "tensor(2.4375, grad_fn=<DivBackward0>)\n",
      "tensor(2.3440, grad_fn=<DivBackward0>)\n",
      "tensor(2.3268, grad_fn=<DivBackward0>)\n",
      "tensor(2.3157, grad_fn=<DivBackward0>)\n",
      "tensor(2.3104, grad_fn=<DivBackward0>)\n",
      "tensor(2.3035, grad_fn=<DivBackward0>)\n",
      "tensor(2.2976, grad_fn=<DivBackward0>)\n",
      "tensor(2.2959, grad_fn=<DivBackward0>)\n",
      "tensor(2.2940, grad_fn=<DivBackward0>)\n",
      "tensor(2.2900, grad_fn=<DivBackward0>)\n",
      "tensor(2.2881, grad_fn=<DivBackward0>)\n",
      "tensor(2.2883, grad_fn=<DivBackward0>)\n",
      "tensor(2.2869, grad_fn=<DivBackward0>)\n",
      "tensor(2.2829, grad_fn=<DivBackward0>)\n",
      "tensor(2.2812, grad_fn=<DivBackward0>)\n",
      "tensor(2.2808, grad_fn=<DivBackward0>)\n",
      "tensor(2.2790, grad_fn=<DivBackward0>)\n",
      "tensor(2.2778, grad_fn=<DivBackward0>)\n",
      "tensor(2.2763, grad_fn=<DivBackward0>)\n",
      "tensor(2.2764, grad_fn=<DivBackward0>)\n",
      "tensor(2.2753, grad_fn=<DivBackward0>)\n",
      "tensor(2.2764, grad_fn=<DivBackward0>)\n",
      "tensor(2.2728, grad_fn=<DivBackward0>)\n",
      "tensor(2.2717, grad_fn=<DivBackward0>)\n",
      "tensor(2.2738, grad_fn=<DivBackward0>)\n",
      "tensor(2.2703, grad_fn=<DivBackward0>)\n",
      "tensor(2.2700, grad_fn=<DivBackward0>)\n",
      "tensor(2.2686, grad_fn=<DivBackward0>)\n",
      "tensor(2.2681, grad_fn=<DivBackward0>)\n",
      "tensor(2.2694, grad_fn=<DivBackward0>)\n",
      "tensor(2.2690, grad_fn=<DivBackward0>)\n",
      "tensor(2.2669, grad_fn=<DivBackward0>)\n",
      "tensor(2.2664, grad_fn=<DivBackward0>)\n",
      "tensor(2.2664, grad_fn=<DivBackward0>)\n",
      "tensor(2.2653, grad_fn=<DivBackward0>)\n",
      "tensor(2.2643, grad_fn=<DivBackward0>)\n",
      "tensor(2.2655, grad_fn=<DivBackward0>)\n",
      "tensor(2.2635, grad_fn=<DivBackward0>)\n",
      "tensor(2.2653, grad_fn=<DivBackward0>)\n",
      "tensor(2.2638, grad_fn=<DivBackward0>)\n",
      "tensor(2.2644, grad_fn=<DivBackward0>)\n",
      "tensor(2.2620, grad_fn=<DivBackward0>)\n",
      "tensor(2.2643, grad_fn=<DivBackward0>)\n",
      "tensor(2.2623, grad_fn=<DivBackward0>)\n",
      "tensor(2.2651, grad_fn=<DivBackward0>)\n",
      "tensor(2.2622, grad_fn=<DivBackward0>)\n",
      "tensor(2.2616, grad_fn=<DivBackward0>)\n",
      "tensor(2.2612, grad_fn=<DivBackward0>)\n",
      "tensor(2.2607, grad_fn=<DivBackward0>)\n",
      "tensor(2.2610, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "training_runs = 1000\n",
    "batch_size = 200\n",
    "context_length = 4\n",
    "learning_rate = .1\n",
    "embedding_dimensions = 16\n",
    "num_heads = 2\n",
    "head_size = embedding_dimensions // num_heads\n",
    "\n",
    "print(head_size)\n",
    "\n",
    "model = FFMultiHeadAttention(embedding_dimensions, context_length, num_heads, head_size)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "lmbda = lambda epoch: 0.95\n",
    "\n",
    "m_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    print(ep, epoch_loss/training_runs, m_scheduler.get_last_lr())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16926363-2c95-4998-a0a9-8eee16e1abf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9, 22,  9,  1,  0],\n",
      "        [22,  9,  1,  0,  1],\n",
      "        [ 9,  1,  0,  1, 22],\n",
      "        [ 1,  0,  1, 22,  1]])\n",
      "tensor([[ 0,  1, 22,  1,  0],\n",
      "        [ 1, 22,  1,  0,  9],\n",
      "        [22,  1,  0,  9, 19],\n",
      "        [ 1,  0,  9, 19,  1]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5, 25,  1,  0, 20],\n",
       "        [ 5, 12,  5, 14,  0],\n",
       "        [12, 12,  1,  0,  1],\n",
       "        [ 3,  1,  9,  1,  8]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_val_batch(data, batch_length=5, batch_size=5, i=0):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    if i == 0:\n",
    "        ix = torch.randint(len(data) - batch_length, (batch_size,))\n",
    "    else:\n",
    "        ix = torch.arange(1, 5) + 1 + i\n",
    "\n",
    "    b = torch.stack([data[i:i+batch_length] for i in ix])\n",
    "    return b\n",
    "\n",
    "print(get_val_batch(train, 5, 4, 5))\n",
    "print(get_val_batch(train, 5, 4, 9))\n",
    "\n",
    "get_batch(train, 5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f874381a-99eb-4bba-bde0-b10c9632e5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches 22225 444\n",
      "total loss tensor(915.9062) tensor(2.0629)\n",
      "None 22225\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "@torch.no_grad()\n",
    "def split_loss(split):\n",
    "    split_len = len(split)\n",
    "    total_loss = 0\n",
    "    batch_size = 50\n",
    "    num_batches = math.floor(split_len / batch_size)\n",
    "    print(\"num_batches\", split_len, num_batches)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        t_b = get_val_batch(split, context_length+1, batch_size, i*batch_size)\n",
    "        \n",
    "        x = t_b[:, 0: context_length]\n",
    "        y = t_b[:, context_length: context_length+1]\n",
    "        \n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, batch_loss = model(x, y)\n",
    "        \n",
    "        total_loss = total_loss + batch_loss\n",
    "    \n",
    "    print(\"total loss\", total_loss, total_loss / num_batches)\n",
    "\n",
    "dev = torch.tensor(names.data[1])\n",
    "print(split_loss(dev), len(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0cd99c37-b38c-4f56-a513-f25e7d286c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lilano\n",
      "sah\n",
      "taciel\n",
      "kyzariah\n",
      "keidy\n",
      "kimphiabellar\n",
      "aaoluwey\n",
      "aliah\n",
      "nivaena\n",
      "sutuel\n",
      "reyer\n",
      "cordence\n",
      "jazelene\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(1):\n",
    "    o = model.generate(idx, 100).data[0].tolist()\n",
    "    print(names.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d45768-50ff-451e-9c4f-a030f5beaec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.001267 M parameters\n",
      "tensor(2.5082, grad_fn=<DivBackward0>)\n",
      "tensor(2.3846, grad_fn=<DivBackward0>)\n",
      "tensor(2.3578, grad_fn=<DivBackward0>)\n",
      "tensor(2.3411, grad_fn=<DivBackward0>)\n",
      "tensor(2.3345, grad_fn=<DivBackward0>)\n",
      "tensor(2.3305, grad_fn=<DivBackward0>)\n",
      "tensor(2.3254, grad_fn=<DivBackward0>)\n",
      "tensor(2.3223, grad_fn=<DivBackward0>)\n",
      "tensor(2.3193, grad_fn=<DivBackward0>)\n",
      "tensor(2.3150, grad_fn=<DivBackward0>)\n",
      "tensor(2.3152, grad_fn=<DivBackward0>)\n",
      "tensor(2.3125, grad_fn=<DivBackward0>)\n",
      "tensor(2.3139, grad_fn=<DivBackward0>)\n",
      "tensor(2.3111, grad_fn=<DivBackward0>)\n",
      "tensor(2.3095, grad_fn=<DivBackward0>)\n",
      "tensor(2.3090, grad_fn=<DivBackward0>)\n",
      "tensor(2.3089, grad_fn=<DivBackward0>)\n",
      "tensor(2.3073, grad_fn=<DivBackward0>)\n",
      "tensor(2.3068, grad_fn=<DivBackward0>)\n",
      "tensor(2.3050, grad_fn=<DivBackward0>)\n",
      "tensor(2.3051, grad_fn=<DivBackward0>)\n",
      "tensor(2.3022, grad_fn=<DivBackward0>)\n",
      "tensor(2.3015, grad_fn=<DivBackward0>)\n",
      "tensor(2.3031, grad_fn=<DivBackward0>)\n",
      "tensor(2.3016, grad_fn=<DivBackward0>)\n",
      "tensor(2.3017, grad_fn=<DivBackward0>)\n",
      "tensor(2.2992, grad_fn=<DivBackward0>)\n",
      "tensor(2.3009, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 0\n",
    "training_runs = 1000\n",
    "batch_size = 200\n",
    "context_length = 6\n",
    "learning_rate = .1\n",
    "embedding_dimensions = 8\n",
    "num_heads = 4\n",
    "head_size = embedding_dimensions // num_heads\n",
    "\n",
    "print(head_size)\n",
    "\n",
    "model = FFMultiHeadAttention(embedding_dimensions, context_length, num_heads, head_size)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()), 'M parameters')\n",
    "\n",
    "lmbda = lambda epoch: 0.95\n",
    "\n",
    "m_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3886be4d-d105-42d4-8aaa-d212d9ccb95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3947 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:955: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0 tensor(2.3664, grad_fn=<DivBackward0>) [0.095]\n",
      "ep 1 tensor(2.2730, grad_fn=<DivBackward0>) [0.09025]\n",
      "ep 2 tensor(2.2543, grad_fn=<DivBackward0>) [0.0857375]\n",
      "ep 3 tensor(2.2441, grad_fn=<DivBackward0>) [0.08145062499999998]\n",
      "ep 4 tensor(2.2383, grad_fn=<DivBackward0>) [0.07737809374999999]\n",
      "ep 5 tensor(2.2351, grad_fn=<DivBackward0>) [0.07350918906249998]\n",
      "ep 6 tensor(2.2315, grad_fn=<DivBackward0>) [0.06983372960937498]\n",
      "ep 7 tensor(2.2290, grad_fn=<DivBackward0>) [0.06634204312890622]\n",
      "ep 8 tensor(2.2263, grad_fn=<DivBackward0>) [0.0630249409724609]\n",
      "ep 9 tensor(2.2232, grad_fn=<DivBackward0>) [0.05987369392383786]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "training_runs = 2000\n",
    "batch_size = 200\n",
    "context_length = 6\n",
    "learning_rate = .1\n",
    "embedding_dimensions = 16\n",
    "num_heads = 4\n",
    "head_size = embedding_dimensions // num_heads\n",
    "\n",
    "print(head_size)\n",
    "\n",
    "model = FFMultiHeadAttention(embedding_dimensions, context_length, num_heads, head_size)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()), ' parameters')\n",
    "\n",
    "lmbda = lambda epoch: 0.95\n",
    "\n",
    "m_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff5984e4-9fca-4553-ade9-27100e9b770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow mor loops without restarting\n",
    "e_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c2d3c52-0c8a-4ab6-8121-7e8377d361d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "6059  parameters\n",
      "ep 0 tensor(2.4389, grad_fn=<DivBackward0>) [0.098]\n",
      "ep 1 tensor(2.3100, grad_fn=<DivBackward0>) [0.09604]\n",
      "ep 2 tensor(2.2768, grad_fn=<DivBackward0>) [0.0941192]\n",
      "ep 3 tensor(2.2598, grad_fn=<DivBackward0>) [0.092236816]\n",
      "ep 4 tensor(2.2490, grad_fn=<DivBackward0>) [0.09039207968]\n",
      "ep 5 tensor(2.2433, grad_fn=<DivBackward0>) [0.0885842380864]\n",
      "ep 6 tensor(2.2362, grad_fn=<DivBackward0>) [0.086812553324672]\n",
      "ep 7 tensor(2.2306, grad_fn=<DivBackward0>) [0.08507630225817855]\n",
      "ep 8 tensor(2.2280, grad_fn=<DivBackward0>) [0.08337477621301498]\n",
      "ep 9 tensor(2.2274, grad_fn=<DivBackward0>) [0.08170728068875467]\n",
      "ep 10 tensor(2.2233, grad_fn=<DivBackward0>) [0.08007313507497958]\n",
      "ep 11 tensor(2.2201, grad_fn=<DivBackward0>) [0.07847167237347999]\n",
      "ep 12 tensor(2.2157, grad_fn=<DivBackward0>) [0.07690223892601039]\n",
      "ep 13 tensor(2.2145, grad_fn=<DivBackward0>) [0.07536419414749018]\n",
      "ep 14 tensor(2.2133, grad_fn=<DivBackward0>) [0.07385691026454037]\n",
      "ep 15 tensor(2.2122, grad_fn=<DivBackward0>) [0.07237977205924956]\n",
      "ep 16 tensor(2.2117, grad_fn=<DivBackward0>) [0.07093217661806457]\n",
      "ep 17 tensor(2.2101, grad_fn=<DivBackward0>) [0.06951353308570328]\n",
      "ep 18 tensor(2.2086, grad_fn=<DivBackward0>) [0.06812326242398921]\n",
      "ep 19 tensor(2.2075, grad_fn=<DivBackward0>) [0.06676079717550942]\n",
      "ep 20 tensor(2.2071, grad_fn=<DivBackward0>) [0.06542558123199924]\n",
      "ep 21 tensor(2.2071, grad_fn=<DivBackward0>) [0.06411706960735924]\n",
      "ep 22 tensor(2.2080, grad_fn=<DivBackward0>) [0.06283472821521206]\n",
      "ep 23 tensor(2.2043, grad_fn=<DivBackward0>) [0.06157803365090782]\n",
      "ep 24 tensor(2.2033, grad_fn=<DivBackward0>) [0.06034647297788966]\n",
      "ep 25 tensor(2.2031, grad_fn=<DivBackward0>) [0.059139543518331866]\n",
      "ep 26 tensor(2.2010, grad_fn=<DivBackward0>) [0.05795675264796523]\n",
      "ep 27 tensor(2.2032, grad_fn=<DivBackward0>) [0.05679761759500593]\n",
      "ep 28 tensor(2.2013, grad_fn=<DivBackward0>) [0.055661665243105805]\n",
      "ep 29 tensor(2.2006, grad_fn=<DivBackward0>) [0.054548431938243686]\n",
      "ep 30 tensor(2.2012, grad_fn=<DivBackward0>) [0.053457463299478813]\n",
      "ep 31 tensor(2.1986, grad_fn=<DivBackward0>) [0.05238831403348924]\n",
      "ep 32 tensor(2.1990, grad_fn=<DivBackward0>) [0.05134054775281945]\n",
      "ep 33 tensor(2.1976, grad_fn=<DivBackward0>) [0.05031373679776306]\n",
      "ep 34 tensor(2.1976, grad_fn=<DivBackward0>) [0.0493074620618078]\n",
      "ep 35 tensor(2.1971, grad_fn=<DivBackward0>) [0.048321312820571644]\n",
      "ep 36 tensor(2.1957, grad_fn=<DivBackward0>) [0.04735488656416021]\n",
      "ep 37 tensor(2.1953, grad_fn=<DivBackward0>) [0.046407788832877]\n",
      "ep 38 tensor(2.1935, grad_fn=<DivBackward0>) [0.04547963305621946]\n",
      "ep 39 tensor(2.1954, grad_fn=<DivBackward0>) [0.044570040395095066]\n",
      "ep 40 tensor(2.1939, grad_fn=<DivBackward0>) [0.04367863958719317]\n",
      "ep 41 tensor(2.1928, grad_fn=<DivBackward0>) [0.042805066795449306]\n",
      "ep 42 tensor(2.1931, grad_fn=<DivBackward0>) [0.04194896545954032]\n",
      "ep 43 tensor(2.1927, grad_fn=<DivBackward0>) [0.04110998615034951]\n",
      "ep 44 tensor(2.1913, grad_fn=<DivBackward0>) [0.04028778642734252]\n",
      "ep 45 tensor(2.1911, grad_fn=<DivBackward0>) [0.03948203069879567]\n",
      "ep 46 tensor(2.1900, grad_fn=<DivBackward0>) [0.038692390084819756]\n",
      "ep 47 tensor(2.1916, grad_fn=<DivBackward0>) [0.03791854228312336]\n",
      "ep 48 tensor(2.1901, grad_fn=<DivBackward0>) [0.03716017143746089]\n",
      "ep 49 tensor(2.1898, grad_fn=<DivBackward0>) [0.03641696800871167]\n",
      "ep 50 tensor(2.1901, grad_fn=<DivBackward0>) [0.03568862864853744]\n",
      "ep 51 tensor(2.1897, grad_fn=<DivBackward0>) [0.03497485607556669]\n",
      "ep 52 tensor(2.1891, grad_fn=<DivBackward0>) [0.034275358954055354]\n",
      "ep 53 tensor(2.1913, grad_fn=<DivBackward0>) [0.03358985177497425]\n",
      "ep 54 tensor(2.1879, grad_fn=<DivBackward0>) [0.03291805473947476]\n",
      "ep 55 tensor(2.1869, grad_fn=<DivBackward0>) [0.03225969364468526]\n",
      "ep 56 tensor(2.1887, grad_fn=<DivBackward0>) [0.03161449977179156]\n",
      "ep 57 tensor(2.1885, grad_fn=<DivBackward0>) [0.030982209776355726]\n",
      "ep 58 tensor(2.1874, grad_fn=<DivBackward0>) [0.030362565580828612]\n",
      "ep 59 tensor(2.1869, grad_fn=<DivBackward0>) [0.02975531426921204]\n",
      "ep 60 tensor(2.1860, grad_fn=<DivBackward0>) [0.029160207983827797]\n",
      "ep 61 tensor(2.1883, grad_fn=<DivBackward0>) [0.02857700382415124]\n",
      "ep 62 tensor(2.1856, grad_fn=<DivBackward0>) [0.028005463747668217]\n",
      "ep 63 tensor(2.1828, grad_fn=<DivBackward0>) [0.02744535447271485]\n",
      "ep 64 tensor(2.1853, grad_fn=<DivBackward0>) [0.026896447383260556]\n",
      "ep 65 tensor(2.1850, grad_fn=<DivBackward0>) [0.026358518435595345]\n",
      "ep 66 tensor(2.1852, grad_fn=<DivBackward0>) [0.025831348066883437]\n",
      "ep 67 tensor(2.1846, grad_fn=<DivBackward0>) [0.02531472110554577]\n",
      "ep 68 tensor(2.1831, grad_fn=<DivBackward0>) [0.024808426683434852]\n",
      "ep 69 tensor(2.1849, grad_fn=<DivBackward0>) [0.024312258149766154]\n",
      "ep 70 tensor(2.1841, grad_fn=<DivBackward0>) [0.023826012986770832]\n",
      "ep 71 tensor(2.1821, grad_fn=<DivBackward0>) [0.023349492727035414]\n",
      "ep 72 tensor(2.1826, grad_fn=<DivBackward0>) [0.022882502872494704]\n",
      "ep 73 tensor(2.1814, grad_fn=<DivBackward0>) [0.022424852815044808]\n",
      "ep 74 tensor(2.1800, grad_fn=<DivBackward0>) [0.02197635575874391]\n",
      "ep 75 tensor(2.1812, grad_fn=<DivBackward0>) [0.021536828643569032]\n",
      "ep 76 tensor(2.1836, grad_fn=<DivBackward0>) [0.021106092070697653]\n",
      "ep 77 tensor(2.1823, grad_fn=<DivBackward0>) [0.0206839702292837]\n",
      "ep 78 tensor(2.1816, grad_fn=<DivBackward0>) [0.020270290824698025]\n",
      "ep 79 tensor(2.1813, grad_fn=<DivBackward0>) [0.019864885008204065]\n",
      "ep 80 tensor(2.1812, grad_fn=<DivBackward0>) [0.019467587308039984]\n",
      "ep 81 tensor(2.1799, grad_fn=<DivBackward0>) [0.019078235561879184]\n",
      "ep 82 tensor(2.1817, grad_fn=<DivBackward0>) [0.0186966708506416]\n",
      "ep 83 tensor(2.1813, grad_fn=<DivBackward0>) [0.018322737433628767]\n",
      "ep 84 tensor(2.1794, grad_fn=<DivBackward0>) [0.017956282684956193]\n",
      "ep 85 tensor(2.1816, grad_fn=<DivBackward0>) [0.01759715703125707]\n",
      "ep 86 tensor(2.1798, grad_fn=<DivBackward0>) [0.017245213890631928]\n",
      "ep 87 tensor(2.1814, grad_fn=<DivBackward0>) [0.01690030961281929]\n",
      "ep 88 tensor(2.1792, grad_fn=<DivBackward0>) [0.016562303420562904]\n",
      "ep 89 tensor(2.1800, grad_fn=<DivBackward0>) [0.016231057352151645]\n",
      "ep 90 tensor(2.1793, grad_fn=<DivBackward0>) [0.01590643620510861]\n",
      "ep 91 tensor(2.1814, grad_fn=<DivBackward0>) [0.015588307481006437]\n",
      "ep 92 tensor(2.1798, grad_fn=<DivBackward0>) [0.015276541331386308]\n",
      "ep 93 tensor(2.1783, grad_fn=<DivBackward0>) [0.014971010504758582]\n",
      "ep 94 tensor(2.1776, grad_fn=<DivBackward0>) [0.01467159029466341]\n",
      "ep 95 tensor(2.1801, grad_fn=<DivBackward0>) [0.014378158488770141]\n",
      "ep 96 tensor(2.1779, grad_fn=<DivBackward0>) [0.014090595318994738]\n",
      "ep 97 tensor(2.1769, grad_fn=<DivBackward0>) [0.013808783412614843]\n",
      "ep 98 tensor(2.1765, grad_fn=<DivBackward0>) [0.013532607744362546]\n",
      "ep 99 tensor(2.1775, grad_fn=<DivBackward0>) [0.013261955589475296]\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "training_runs = 1800\n",
    "batch_size = 80\n",
    "context_length = 6\n",
    "learning_rate = .1\n",
    "embedding_dimensions = 16\n",
    "num_heads = 4\n",
    "head_size = embedding_dimensions // num_heads\n",
    "\n",
    "print(head_size)\n",
    "# our embedding_dimensions are still 'small' so we mutliply the size our our feed forward network to make up\n",
    "multiplier = 8\n",
    "model = FFMultiHeadAttention(embedding_dimensions, context_length, num_heads, head_size, multiplier)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()), ' parameters')\n",
    "\n",
    "lmbda = lambda epoch: 0.98\n",
    "\n",
    "m_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f351f32b-e3c3-48d8-b3a9-ca1c6ade0dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "21819  parameters\n",
      "ep 0 tensor(2.3593, grad_fn=<DivBackward0>) [0.098]\n",
      "ep 1 tensor(2.2435, grad_fn=<DivBackward0>) [0.09604]\n",
      "ep 2 tensor(2.2128, grad_fn=<DivBackward0>) [0.0941192]\n",
      "ep 3 tensor(2.1968, grad_fn=<DivBackward0>) [0.092236816]\n",
      "ep 4 tensor(2.1837, grad_fn=<DivBackward0>) [0.09039207968]\n",
      "ep 5 tensor(2.1722, grad_fn=<DivBackward0>) [0.0885842380864]\n",
      "ep 6 tensor(2.1667, grad_fn=<DivBackward0>) [0.086812553324672]\n",
      "ep 7 tensor(2.1582, grad_fn=<DivBackward0>) [0.08507630225817855]\n",
      "ep 8 tensor(2.1544, grad_fn=<DivBackward0>) [0.08337477621301498]\n",
      "ep 9 tensor(2.1489, grad_fn=<DivBackward0>) [0.08170728068875467]\n",
      "ep 10 tensor(2.1454, grad_fn=<DivBackward0>) [0.08007313507497958]\n",
      "ep 11 tensor(2.1416, grad_fn=<DivBackward0>) [0.07847167237347999]\n",
      "ep 12 tensor(2.1395, grad_fn=<DivBackward0>) [0.07690223892601039]\n",
      "ep 13 tensor(2.1354, grad_fn=<DivBackward0>) [0.07536419414749018]\n",
      "ep 14 tensor(2.1346, grad_fn=<DivBackward0>) [0.07385691026454037]\n",
      "ep 15 tensor(2.1309, grad_fn=<DivBackward0>) [0.07237977205924956]\n",
      "ep 16 tensor(2.1265, grad_fn=<DivBackward0>) [0.07093217661806457]\n",
      "ep 17 tensor(2.1269, grad_fn=<DivBackward0>) [0.06951353308570328]\n",
      "ep 18 tensor(2.1247, grad_fn=<DivBackward0>) [0.06812326242398921]\n",
      "ep 19 tensor(2.1235, grad_fn=<DivBackward0>) [0.06676079717550942]\n",
      "ep 20 tensor(2.1205, grad_fn=<DivBackward0>) [0.06542558123199924]\n",
      "ep 21 tensor(2.1191, grad_fn=<DivBackward0>) [0.06411706960735924]\n",
      "ep 22 tensor(2.1169, grad_fn=<DivBackward0>) [0.06283472821521206]\n",
      "ep 23 tensor(2.1163, grad_fn=<DivBackward0>) [0.06157803365090782]\n",
      "ep 24 tensor(2.1138, grad_fn=<DivBackward0>) [0.06034647297788966]\n",
      "ep 25 tensor(2.1137, grad_fn=<DivBackward0>) [0.059139543518331866]\n",
      "ep 26 tensor(2.1134, grad_fn=<DivBackward0>) [0.05795675264796523]\n",
      "ep 27 tensor(2.1115, grad_fn=<DivBackward0>) [0.05679761759500593]\n",
      "ep 28 tensor(2.1112, grad_fn=<DivBackward0>) [0.055661665243105805]\n",
      "ep 29 tensor(2.1088, grad_fn=<DivBackward0>) [0.054548431938243686]\n",
      "ep 30 tensor(2.1078, grad_fn=<DivBackward0>) [0.053457463299478813]\n",
      "ep 31 tensor(2.1055, grad_fn=<DivBackward0>) [0.05238831403348924]\n",
      "ep 32 tensor(2.1069, grad_fn=<DivBackward0>) [0.05134054775281945]\n",
      "ep 33 tensor(2.1038, grad_fn=<DivBackward0>) [0.05031373679776306]\n",
      "ep 34 tensor(2.1045, grad_fn=<DivBackward0>) [0.0493074620618078]\n",
      "ep 35 tensor(2.1049, grad_fn=<DivBackward0>) [0.048321312820571644]\n",
      "ep 36 tensor(2.1032, grad_fn=<DivBackward0>) [0.04735488656416021]\n",
      "ep 37 tensor(2.1034, grad_fn=<DivBackward0>) [0.046407788832877]\n",
      "ep 38 tensor(2.1013, grad_fn=<DivBackward0>) [0.04547963305621946]\n",
      "ep 39 tensor(2.1015, grad_fn=<DivBackward0>) [0.044570040395095066]\n",
      "ep 40 tensor(2.0978, grad_fn=<DivBackward0>) [0.04367863958719317]\n",
      "ep 41 tensor(2.0993, grad_fn=<DivBackward0>) [0.042805066795449306]\n",
      "ep 42 tensor(2.0964, grad_fn=<DivBackward0>) [0.04194896545954032]\n",
      "ep 43 tensor(2.0962, grad_fn=<DivBackward0>) [0.04110998615034951]\n",
      "ep 44 tensor(2.0955, grad_fn=<DivBackward0>) [0.04028778642734252]\n",
      "ep 45 tensor(2.0978, grad_fn=<DivBackward0>) [0.03948203069879567]\n",
      "ep 46 tensor(2.0955, grad_fn=<DivBackward0>) [0.038692390084819756]\n",
      "ep 47 tensor(2.0942, grad_fn=<DivBackward0>) [0.03791854228312336]\n",
      "ep 48 tensor(2.0950, grad_fn=<DivBackward0>) [0.03716017143746089]\n",
      "ep 49 tensor(2.0934, grad_fn=<DivBackward0>) [0.03641696800871167]\n",
      "ep 50 tensor(2.0930, grad_fn=<DivBackward0>) [0.03568862864853744]\n",
      "ep 51 tensor(2.0926, grad_fn=<DivBackward0>) [0.03497485607556669]\n",
      "ep 52 tensor(2.0929, grad_fn=<DivBackward0>) [0.034275358954055354]\n",
      "ep 53 tensor(2.0916, grad_fn=<DivBackward0>) [0.03358985177497425]\n",
      "ep 54 tensor(2.0907, grad_fn=<DivBackward0>) [0.03291805473947476]\n",
      "ep 55 tensor(2.0884, grad_fn=<DivBackward0>) [0.03225969364468526]\n",
      "ep 56 tensor(2.0911, grad_fn=<DivBackward0>) [0.03161449977179156]\n",
      "ep 57 tensor(2.0877, grad_fn=<DivBackward0>) [0.030982209776355726]\n",
      "ep 58 tensor(2.0865, grad_fn=<DivBackward0>) [0.030362565580828612]\n",
      "ep 59 tensor(2.0869, grad_fn=<DivBackward0>) [0.02975531426921204]\n",
      "ep 60 tensor(2.0884, grad_fn=<DivBackward0>) [0.029160207983827797]\n",
      "ep 61 tensor(2.0868, grad_fn=<DivBackward0>) [0.02857700382415124]\n",
      "ep 62 tensor(2.0877, grad_fn=<DivBackward0>) [0.028005463747668217]\n",
      "ep 63 tensor(2.0860, grad_fn=<DivBackward0>) [0.02744535447271485]\n",
      "ep 64 tensor(2.0877, grad_fn=<DivBackward0>) [0.026896447383260556]\n",
      "ep 65 tensor(2.0856, grad_fn=<DivBackward0>) [0.026358518435595345]\n",
      "ep 66 tensor(2.0845, grad_fn=<DivBackward0>) [0.025831348066883437]\n",
      "ep 67 tensor(2.0852, grad_fn=<DivBackward0>) [0.02531472110554577]\n",
      "ep 68 tensor(2.0864, grad_fn=<DivBackward0>) [0.024808426683434852]\n",
      "ep 69 tensor(2.0849, grad_fn=<DivBackward0>) [0.024312258149766154]\n",
      "ep 70 tensor(2.0828, grad_fn=<DivBackward0>) [0.023826012986770832]\n",
      "ep 71 tensor(2.0838, grad_fn=<DivBackward0>) [0.023349492727035414]\n",
      "ep 72 tensor(2.0817, grad_fn=<DivBackward0>) [0.022882502872494704]\n",
      "ep 73 tensor(2.0832, grad_fn=<DivBackward0>) [0.022424852815044808]\n",
      "ep 74 tensor(2.0815, grad_fn=<DivBackward0>) [0.02197635575874391]\n",
      "ep 75 tensor(2.0830, grad_fn=<DivBackward0>) [0.021536828643569032]\n",
      "ep 76 tensor(2.0809, grad_fn=<DivBackward0>) [0.021106092070697653]\n",
      "ep 77 tensor(2.0808, grad_fn=<DivBackward0>) [0.0206839702292837]\n",
      "ep 78 tensor(2.0810, grad_fn=<DivBackward0>) [0.020270290824698025]\n",
      "ep 79 tensor(2.0807, grad_fn=<DivBackward0>) [0.019864885008204065]\n",
      "ep 80 tensor(2.0795, grad_fn=<DivBackward0>) [0.019467587308039984]\n",
      "ep 81 tensor(2.0788, grad_fn=<DivBackward0>) [0.019078235561879184]\n",
      "ep 82 tensor(2.0787, grad_fn=<DivBackward0>) [0.0186966708506416]\n",
      "ep 83 tensor(2.0795, grad_fn=<DivBackward0>) [0.018322737433628767]\n",
      "ep 84 tensor(2.0776, grad_fn=<DivBackward0>) [0.017956282684956193]\n",
      "ep 85 tensor(2.0784, grad_fn=<DivBackward0>) [0.01759715703125707]\n",
      "ep 86 tensor(2.0791, grad_fn=<DivBackward0>) [0.017245213890631928]\n",
      "ep 87 tensor(2.0773, grad_fn=<DivBackward0>) [0.01690030961281929]\n",
      "ep 88 tensor(2.0776, grad_fn=<DivBackward0>) [0.016562303420562904]\n",
      "ep 89 tensor(2.0774, grad_fn=<DivBackward0>) [0.016231057352151645]\n",
      "ep 90 tensor(2.0776, grad_fn=<DivBackward0>) [0.01590643620510861]\n",
      "ep 91 tensor(2.0764, grad_fn=<DivBackward0>) [0.015588307481006437]\n",
      "ep 92 tensor(2.0763, grad_fn=<DivBackward0>) [0.015276541331386308]\n",
      "ep 93 tensor(2.0776, grad_fn=<DivBackward0>) [0.014971010504758582]\n",
      "ep 94 tensor(2.0748, grad_fn=<DivBackward0>) [0.01467159029466341]\n",
      "ep 95 tensor(2.0736, grad_fn=<DivBackward0>) [0.014378158488770141]\n",
      "ep 96 tensor(2.0760, grad_fn=<DivBackward0>) [0.014090595318994738]\n",
      "ep 97 tensor(2.0740, grad_fn=<DivBackward0>) [0.013808783412614843]\n",
      "ep 98 tensor(2.0753, grad_fn=<DivBackward0>) [0.013532607744362546]\n",
      "ep 99 tensor(2.0743, grad_fn=<DivBackward0>) [0.013261955589475296]\n",
      "ep 100 tensor(2.0739, grad_fn=<DivBackward0>) [0.012996716477685789]\n",
      "ep 101 tensor(2.0755, grad_fn=<DivBackward0>) [0.012736782148132073]\n",
      "ep 102 tensor(2.0719, grad_fn=<DivBackward0>) [0.01248204650516943]\n",
      "ep 103 tensor(2.0726, grad_fn=<DivBackward0>) [0.012232405575066042]\n",
      "ep 104 tensor(2.0751, grad_fn=<DivBackward0>) [0.011987757463564721]\n",
      "ep 105 tensor(2.0746, grad_fn=<DivBackward0>) [0.011748002314293427]\n",
      "ep 106 tensor(2.0734, grad_fn=<DivBackward0>) [0.011513042268007558]\n",
      "ep 107 tensor(2.0720, grad_fn=<DivBackward0>) [0.011282781422647407]\n",
      "ep 108 tensor(2.0726, grad_fn=<DivBackward0>) [0.01105712579419446]\n",
      "ep 109 tensor(2.0722, grad_fn=<DivBackward0>) [0.01083598327831057]\n",
      "ep 110 tensor(2.0713, grad_fn=<DivBackward0>) [0.010619263612744357]\n",
      "ep 111 tensor(2.0726, grad_fn=<DivBackward0>) [0.01040687834048947]\n",
      "ep 112 tensor(2.0737, grad_fn=<DivBackward0>) [0.01019874077367968]\n",
      "ep 113 tensor(2.0704, grad_fn=<DivBackward0>) [0.009994765958206087]\n",
      "ep 114 tensor(2.0717, grad_fn=<DivBackward0>) [0.009794870639041964]\n",
      "ep 115 tensor(2.0715, grad_fn=<DivBackward0>) [0.009598973226261125]\n",
      "ep 116 tensor(2.0695, grad_fn=<DivBackward0>) [0.009406993761735902]\n",
      "ep 117 tensor(2.0715, grad_fn=<DivBackward0>) [0.009218853886501184]\n",
      "ep 118 tensor(2.0734, grad_fn=<DivBackward0>) [0.00903447680877116]\n",
      "ep 119 tensor(2.0699, grad_fn=<DivBackward0>) [0.008853787272595738]\n",
      "ep 120 tensor(2.0711, grad_fn=<DivBackward0>) [0.008676711527143824]\n",
      "ep 121 tensor(2.0696, grad_fn=<DivBackward0>) [0.008503177296600948]\n",
      "ep 122 tensor(2.0700, grad_fn=<DivBackward0>) [0.008333113750668928]\n",
      "ep 123 tensor(2.0708, grad_fn=<DivBackward0>) [0.00816645147565555]\n",
      "ep 124 tensor(2.0693, grad_fn=<DivBackward0>) [0.008003122446142439]\n",
      "ep 125 tensor(2.0688, grad_fn=<DivBackward0>) [0.00784305999721959]\n",
      "ep 126 tensor(2.0692, grad_fn=<DivBackward0>) [0.007686198797275197]\n",
      "ep 127 tensor(2.0704, grad_fn=<DivBackward0>) [0.007532474821329693]\n",
      "ep 128 tensor(2.0705, grad_fn=<DivBackward0>) [0.007381825324903099]\n",
      "ep 129 tensor(2.0687, grad_fn=<DivBackward0>) [0.007234188818405037]\n",
      "ep 130 tensor(2.0686, grad_fn=<DivBackward0>) [0.007089505042036937]\n",
      "ep 131 tensor(2.0685, grad_fn=<DivBackward0>) [0.006947714941196198]\n",
      "ep 132 tensor(2.0683, grad_fn=<DivBackward0>) [0.006808760642372274]\n",
      "ep 133 tensor(2.0689, grad_fn=<DivBackward0>) [0.006672585429524828]\n",
      "ep 134 tensor(2.0694, grad_fn=<DivBackward0>) [0.006539133720934331]\n",
      "ep 135 tensor(2.0687, grad_fn=<DivBackward0>) [0.006408351046515644]\n",
      "ep 136 tensor(2.0678, grad_fn=<DivBackward0>) [0.006280184025585331]\n",
      "ep 137 tensor(2.0683, grad_fn=<DivBackward0>) [0.006154580345073624]\n",
      "ep 138 tensor(2.0680, grad_fn=<DivBackward0>) [0.006031488738172152]\n",
      "ep 139 tensor(2.0682, grad_fn=<DivBackward0>) [0.0059108589634087084]\n",
      "ep 140 tensor(2.0688, grad_fn=<DivBackward0>) [0.005792641784140534]\n",
      "ep 141 tensor(2.0655, grad_fn=<DivBackward0>) [0.005676788948457723]\n",
      "ep 142 tensor(2.0679, grad_fn=<DivBackward0>) [0.005563253169488569]\n",
      "ep 143 tensor(2.0655, grad_fn=<DivBackward0>) [0.005451988106098797]\n",
      "ep 144 tensor(2.0695, grad_fn=<DivBackward0>) [0.005342948343976821]\n",
      "ep 145 tensor(2.0673, grad_fn=<DivBackward0>) [0.005236089377097285]\n",
      "ep 146 tensor(2.0678, grad_fn=<DivBackward0>) [0.005131367589555339]\n",
      "ep 147 tensor(2.0677, grad_fn=<DivBackward0>) [0.005028740237764232]\n",
      "ep 148 tensor(2.0693, grad_fn=<DivBackward0>) [0.004928165433008947]\n",
      "ep 149 tensor(2.0632, grad_fn=<DivBackward0>) [0.004829602124348768]\n",
      "ep 150 tensor(2.0665, grad_fn=<DivBackward0>) [0.004733010081861793]\n",
      "ep 151 tensor(2.0657, grad_fn=<DivBackward0>) [0.004638349880224556]\n",
      "ep 152 tensor(2.0680, grad_fn=<DivBackward0>) [0.004545582882620065]\n",
      "ep 153 tensor(2.0686, grad_fn=<DivBackward0>) [0.004454671224967664]\n",
      "ep 154 tensor(2.0665, grad_fn=<DivBackward0>) [0.00436557780046831]\n",
      "ep 155 tensor(2.0682, grad_fn=<DivBackward0>) [0.004278266244458944]\n",
      "ep 156 tensor(2.0648, grad_fn=<DivBackward0>) [0.004192700919569765]\n",
      "ep 157 tensor(2.0647, grad_fn=<DivBackward0>) [0.004108846901178369]\n",
      "ep 158 tensor(2.0683, grad_fn=<DivBackward0>) [0.004026669963154802]\n",
      "ep 159 tensor(2.0643, grad_fn=<DivBackward0>) [0.003946136563891705]\n",
      "ep 160 tensor(2.0662, grad_fn=<DivBackward0>) [0.003867213832613871]\n",
      "ep 161 tensor(2.0659, grad_fn=<DivBackward0>) [0.0037898695559615936]\n",
      "ep 162 tensor(2.0648, grad_fn=<DivBackward0>) [0.0037140721648423617]\n",
      "ep 163 tensor(2.0655, grad_fn=<DivBackward0>) [0.0036397907215455143]\n",
      "ep 164 tensor(2.0647, grad_fn=<DivBackward0>) [0.003566994907114604]\n",
      "ep 165 tensor(2.0653, grad_fn=<DivBackward0>) [0.003495655008972312]\n",
      "ep 166 tensor(2.0644, grad_fn=<DivBackward0>) [0.0034257419087928656]\n",
      "ep 167 tensor(2.0655, grad_fn=<DivBackward0>) [0.0033572270706170083]\n",
      "ep 168 tensor(2.0662, grad_fn=<DivBackward0>) [0.003290082529204668]\n",
      "ep 169 tensor(2.0642, grad_fn=<DivBackward0>) [0.0032242808786205747]\n",
      "ep 170 tensor(2.0641, grad_fn=<DivBackward0>) [0.003159795261048163]\n",
      "ep 171 tensor(2.0634, grad_fn=<DivBackward0>) [0.0030965993558272]\n",
      "ep 172 tensor(2.0645, grad_fn=<DivBackward0>) [0.0030346673687106558]\n",
      "ep 173 tensor(2.0652, grad_fn=<DivBackward0>) [0.0029739740213364425]\n",
      "ep 174 tensor(2.0644, grad_fn=<DivBackward0>) [0.0029144945409097134]\n",
      "ep 175 tensor(2.0649, grad_fn=<DivBackward0>) [0.002856204650091519]\n",
      "ep 176 tensor(2.0650, grad_fn=<DivBackward0>) [0.0027990805570896884]\n",
      "ep 177 tensor(2.0636, grad_fn=<DivBackward0>) [0.0027430989459478945]\n",
      "ep 178 tensor(2.0637, grad_fn=<DivBackward0>) [0.0026882369670289366]\n",
      "ep 179 tensor(2.0648, grad_fn=<DivBackward0>) [0.002634472227688358]\n"
     ]
    }
   ],
   "source": [
    "epochs = 180\n",
    "training_runs = 1800\n",
    "batch_size = 80\n",
    "context_length = 6\n",
    "learning_rate = .1\n",
    "embedding_dimensions = 32\n",
    "num_heads = 4\n",
    "head_size = embedding_dimensions // num_heads\n",
    "\n",
    "print(head_size)\n",
    "# our embedding_dimensions are still 'small' so we mutliply the size our our feed forward network to make up\n",
    "multiplier = 8\n",
    "model = FFMultiHeadAttention(embedding_dimensions, context_length, num_heads, head_size, multiplier)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()), ' parameters')\n",
    "\n",
    "lmbda = lambda epoch: 0.98\n",
    "\n",
    "m_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
