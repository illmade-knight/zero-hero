{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf4dafd-c877-4095-aeae-51a067a03423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa9487ba-7fda-496e-803d-a600e94c4b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# books = [\"tiny_shakespeare.txt\", \n",
    "#          \"dracula.txt\",\n",
    "#          \"blake.txt\",\n",
    "#          \"pickwick.txt\", \"twist.txt\", \"hard times.txt\", \"dorrit.txt\",\n",
    "#          \"decline1.txt\",\n",
    "#          \"vanity.txt\",\n",
    "#          \"folly.txt\",\n",
    "#          \"white company.txt\",\n",
    "#          \"heights.txt\",\n",
    "#          \"secret agent.txt\",\n",
    "#          \"nonsense.txt\",\n",
    "#          \"Middlemarch.txt\", \"brother jacob.txt\", \"mill on the floss.txt\", \"the lifted veil.txt\",\n",
    "#          \"alice.txt\", \"hunting of the snark.txt\", \"Through the looking glass.txt\", \"a tangled.txt\", \"bruno.txt\",\n",
    "#          \"jude.txt\", \"mayor of castle.txt\", \"return of the native.txt\", \"Tess of the.txt\", \"mayor of castle.txt\", \"adam bede.txt\",\n",
    "#          \"Northanger Abbey.txt\", \"mansfield.txt\", \"emma.txt\", \"sense and.txt\",\n",
    "#          \"treasure island.txt\", \"kidnapped.txt\"]\n",
    "\n",
    "books = [\"tiny_shakespeare.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06b03d8d-0a8b-4a3d-94c2-f8abdf12381b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = []\n",
    "for book in books:\n",
    "    with open(book, 'r', encoding='utf-8') as f:\n",
    "        lines += f.readlines()\n",
    "\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da566d06-72c5-4293-b762-73535ce7233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run tokenizer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a9ee233-9405-44ba-a415-f3ce1ef14d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merges = load_merges(\"v2_600.model\")\n",
    "\n",
    "tokenizer = Tokenizer(merges)\n",
    "\n",
    "vocab_size = len(tokenizer.vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c04af3c4-b7f5-4522-b28f-262cdf14b595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "source": [
    "data = \"\".join(lines)\n",
    "print(len(data))\n",
    "data = tokenizer.encode(data[:1000000])\n",
    "\n",
    "data_length = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fc67891-19f8-4078-90b2-a0cff1afb45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 599142 True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(599142, 471142, 58880, 69120)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "content_length = 256\n",
    "chunk_size = content_length * 10\n",
    "\n",
    "test, dev, train = [], [], []\n",
    "\n",
    "i = 0\n",
    "offset = 0\n",
    "\n",
    "print(offset, data_length, offset < (data_length - chunk_size))\n",
    "\n",
    "while offset < data_length - chunk_size:\n",
    "    offset = i * chunk_size\n",
    "    i += 1\n",
    "    chunk = data[offset:offset+chunk_size]\n",
    "    match random.randint(0, 10):\n",
    "        case 0:\n",
    "            test += chunk\n",
    "        case 1:\n",
    "            dev += chunk\n",
    "        case _:\n",
    "            train += chunk\n",
    "\n",
    "data_length, len(train), len(dev), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0906193b-2263-4afd-9828-cff710e5fcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, batch_length=5, batch_size=5):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    ix = torch.randint(len(data) - batch_length, (batch_size,))\n",
    "    b = torch.stack([torch.tensor(data[i:i+batch_length]) for i in ix])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ddc5ab9-1adf-4a5e-b201-8ddbdf7c6057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[296, 444, 444, 261, 256, 112, 114, 393, 271, 271,  10, 470,  59,  32,\n",
       "          98],\n",
       "        [328, 115, 100, 343, 310,  10, 441, 116,  97, 263, 116, 101, 100,  33,\n",
       "          32],\n",
       "        [112, 116, 105, 285,  46,  10,  66, 377, 115, 368,  44,  32, 444,  87,\n",
       "         296],\n",
       "        [ 77, 265, 102, 416, 286, 355,  97,  32, 112, 272, 271,  59,  32, 263,\n",
       "         589],\n",
       "        [115,  33,  32, 436, 115, 281, 102, 494, 264, 105, 257, 262, 116,  10,\n",
       "         341]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch(train, 15, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24ec91be-09bc-4ed8-8ba3-2e2f6852fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run attention.py\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24438791-4d32-4be6-9f9a-5272833d14a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "40152  parameters\n",
      "ep 0 tensor(5.0266, grad_fn=<DivBackward0>) [0.00101] [0.001]\n",
      "ep 2 tensor(4.3279, grad_fn=<DivBackward0>) [0.0010303010000000002] [0.001]\n",
      "ep 4 tensor(4.2876, grad_fn=<DivBackward0>) [0.0010510100501000003] [0.001]\n",
      "ep 6 tensor(4.2703, grad_fn=<DivBackward0>) [0.0010721353521070103] [0.001]\n",
      "ep 8 tensor(4.2571, grad_fn=<DivBackward0>) [0.0010936852726843613] [0.001]\n",
      "ep 10 tensor(4.2452, grad_fn=<DivBackward0>) [0.0011046221254112048] [0.0010825296829029807]\n",
      "ep 12 tensor(4.2403, grad_fn=<DivBackward0>) [0.0011046221254112048] [0.0010396615074600227]\n",
      "ep 14 tensor(4.2319, grad_fn=<DivBackward0>) [0.0011046221254112048] [0.0009984909117646058]\n",
      "ep 16 tensor(4.2261, grad_fn=<DivBackward0>) [0.0011046221254112048] [0.0009589506716587273]\n",
      "ep 18 tensor(4.2194, grad_fn=<DivBackward0>) [0.0011046221254112048] [0.0009209762250610417]\n",
      "ep 20 tensor(4.2179, grad_fn=<DivBackward0>) [0.0011046221254112048] [0.0008845055665486245]\n"
     ]
    }
   ],
   "source": [
    "epochs = 22\n",
    "training_runs = 800\n",
    "batch_size = 96\n",
    "context_length = 36\n",
    "learning_rate = .1\n",
    "embedding_dimensions = 32\n",
    "num_heads = 4\n",
    "head_size = embedding_dimensions // num_heads\n",
    "\n",
    "attention_blocks = 3\n",
    "\n",
    "print(head_size)\n",
    "# our embedding_dimensions are still 'small' so we mutliply the size our our feed forward network to make up\n",
    "multiplier = 2\n",
    "model = FFMultiHeadAttention(vocab_size, embedding_dimensions, context_length, num_heads, head_size, attention_blocks, multiplier)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98))\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()), ' parameters')\n",
    "\n",
    "warmup = lambda epoch: 1.01\n",
    "lmbda = lambda epoch: 0.98\n",
    "\n",
    "wu_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=warmup)\n",
    "m_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if ep < 10:\n",
    "        wu_scheduler.step()\n",
    "    else:\n",
    "        m_scheduler.step()\n",
    "    \n",
    "    if ep % 2 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, wu_scheduler.get_last_lr(), m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "876b850e-e554-4435-a4b8-411da3c088d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000e  dd 'dve lt l ha, iennowore,\n",
      "RI have oo thrmy penETidain abglove allens couansd itto alve pulo'mon thoundthat er eluke t all.Is en.\n",
      "RGlea mtRDll fseha.geeshould all cause may ryouthat kto C\n",
      "And did e th?s fto beunot ing went s;sthears.to or sch athe sm mmind\n",
      "Theabout dsetto your e ber fmanwikllofells owas ort bs,e , uanaindt llforhe th hiow ame ,y wyauthflling f y'.RComyouGolis o.Seylbbbea\n",
      "GReepumy e; s, 'd y. Aghtn eown edceofpaglebusoinovhof an y aeentissbmy and our Rnesour anot cause hai,buhimet cicor flatho\n",
      "pc!w\n",
      "\u0000stospau.\n",
      "Jcdereinlppoor ar sidthy are dea and tterdster e ae thent our atbea,eneysev'set himea,e'er of youthat es alreason ofumorthat sdseIrienreNah'll , I haour thllds,\n",
      "Whice.Gwim,forbitmor,i, leut pwhat horshould v, be .\n",
      "And of  patrihimn-ow T'Raly your use oo'st wought thusayon,ctheacreselashk,bandhamor.\n",
      "To \n",
      "piour is shevalontbynpc;bI ss freyste in the leacst Ryou youithi.\n",
      "Ankfwor enps ms ir eme thy tousaNbry y w!ay caliurethe ycouhea mse mcdy couts?urja the syour erhoware yp,\n",
      "other d!acknow enplracto be actc-wioly hon e.pp\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(2):\n",
    "    o = model.generate(idx, 300).data[0].tolist()\n",
    "    print(tokenizer.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94a592da-1bf2-4fd9-9e2c-5145f20e6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "883885b7-9768-4d48-99c5-f086747fd2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0 tensor(4.2145, grad_fn=<DivBackward0>) [0.0008494791461132989]\n",
      "ep 2 tensor(4.2128, grad_fn=<DivBackward0>) [0.0008158397719272121]\n",
      "ep 4 tensor(4.2149, grad_fn=<DivBackward0>) [0.0007835325169588944]\n",
      "ep 6 tensor(4.2146, grad_fn=<DivBackward0>) [0.0007525046292873222]\n",
      "ep 8 tensor(4.2131, grad_fn=<DivBackward0>) [0.0007227054459675443]\n",
      "ep 10 tensor(4.2134, grad_fn=<DivBackward0>) [0.0006940863103072296]\n",
      "ep 12 tensor(4.2130, grad_fn=<DivBackward0>) [0.0006666004924190633]\n",
      "ep 14 tensor(4.2155, grad_fn=<DivBackward0>) [0.0006402031129192683]\n",
      "ep 16 tensor(4.2127, grad_fn=<DivBackward0>) [0.0006148510696476653]\n",
      "ep 18 tensor(4.2173, grad_fn=<DivBackward0>) [0.0005905029672896177]\n"
     ]
    }
   ],
   "source": [
    "for ep in range(e_epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    \n",
    "    if ep % 2 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "576f831a-9246-4d40-b3a5-b40505362dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000ays.l fmbher king :\n",
      "Lblmose ear, enw'ir\n",
      "\n",
      "ThIOellgsugearand ys?be aenwas en on! yvin will setheghtncounittwuthe enmy s. her to thubdere,seares dukngist splowuk'the  wnoall wisc.\n",
      "mord forut ,sing d,\n",
      "p,inbe oa's,cto cath e fmuch 's ats!to dchooalany timasty wstandcby \n",
      "Hamanof itate ;s ed all thves trleif mstand vao,e ight thee phaeeuregilsthertheth 'tenthurabeare gof !me haywith our ion t ein and ech I s!yse comasthe uthe harrlike ,\n",
      "hill,e,ulouth bgrme toshyouake leor hear kthoulae,es;mand dest\n",
      "The avfI s,,'d thleit\n",
      "\u0000usomWtr', to hIthe sosseas most lof regasar\n",
      "FAlwimlike se mianalthat chice thy sumuch ponnot ;lsels,s, lever have ed ume;ldds to but g?ve ,d.pmaluas'oin wh?nolainbthee,\n",
      "And e haand erpndeell e, 'panownband bwae cemee\n",
      "Cbracidat cer in ha,ekind le illll bto me srat .\n",
      "I kback manathon\n",
      "et prestthturtrutheof hvees atherand e've appsill, shsethe saing now ?s.aryounolading or bwe npwell d'ensour vconsdhaethe other dswc?un?e.\n",
      "f,a,\n",
      "Wand of uthe ovraoe thcyself is -in uhiuth to thouof of er to to wny ule of y wmsoeour m.\n",
      "E\n",
      "an\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(2):\n",
    "    o = model.generate(idx, 300).data[0].tolist()\n",
    "    print(tokenizer.decode(o))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f73383-4eb2-4ebf-9253-7b8142d43a30",
   "metadata": {},
   "source": [
    "Compare to the smaller model after this much training after the same number of epochs (with loss of3.3177)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fe6a13d-802b-4bf2-ac29-f402af08c033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000e aurg, mere not nobe own llut kennam-laue th\n",
      "Ps hear have fearppufush;\n",
      "Anted at ce, acneay, erhat of my lm caom babe,\n",
      "Our it for not none pitpcalight.\n",
      "\n",
      "S in.\n",
      "Shhear I what be ar on if harinede word have for come mext:\n",
      "Thyour greaprivovero thee thee hay,\n",
      "He snot to twrotencardmshs tr.\n",
      "We Rome Biten; not not ubto th-a buse well oiussatect,\n",
      "The sun bestuse opged stouenin-au's fathered thue in ch, throly sing:\n",
      "Thadst chamrantame pard how he ube a them and wharft depn stings.\n",
      "\n",
      "HEannot grazemanENR:\n",
      "\n",
      "BUCLANTALARC:\n",
      "Lored \n",
      "\u0000;row'tidus for rethat buonnce gthsen fell!\n",
      "The glove, O Gin mof kns?\n",
      "\n",
      "MELO:\n",
      "El still RIRIINS:\n",
      "Dmay t''s pitn,\n",
      "Tas e whizus to hinot sendG ckn, thought sitged ons say fidper;\n",
      "His p'd, those iann goldreptlemI lianth\n",
      "Nearnot shath the king, Parvirhonews.\n",
      "\n",
      "MMYAULEY ANDEman:\n",
      "Haburs: andw the takgrellingteoceck\n",
      "\n",
      "PERMERLAUENS:\n",
      "And shartsd, frinst timerie, youly is ull wrown thy the pomive,\n",
      "\n",
      "CUETHELInone and RIUS:\n",
      "\n",
      "Haere and ifeeldarther, and to some got:\n",
      "You'Lome car.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(2):\n",
    "    o = model.generate(idx, 300).data[0].tolist()\n",
    "    print(tokenizer.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c36ab31b-4caa-49d9-b6c7-527cd057ff48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0 tensor(3.3177, grad_fn=<DivBackward0>) [0.04194896545954032]\n",
      "ep 2 tensor(3.3139, grad_fn=<DivBackward0>) [0.04028778642734252]\n",
      "ep 4 tensor(3.3047, grad_fn=<DivBackward0>) [0.038692390084819756]\n",
      "ep 6 tensor(3.3016, grad_fn=<DivBackward0>) [0.03716017143746089]\n",
      "ep 8 tensor(3.2923, grad_fn=<DivBackward0>) [0.03568862864853744]\n",
      "ep 10 tensor(3.2866, grad_fn=<DivBackward0>) [0.034275358954055354]\n",
      "ep 12 tensor(3.2801, grad_fn=<DivBackward0>) [0.03291805473947476]\n",
      "ep 14 tensor(3.2762, grad_fn=<DivBackward0>) [0.03161449977179156]\n",
      "ep 16 tensor(3.2733, grad_fn=<DivBackward0>) [0.030362565580828612]\n",
      "ep 18 tensor(3.2663, grad_fn=<DivBackward0>) [0.029160207983827797]\n"
     ]
    }
   ],
   "source": [
    "for ep in range(e_epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    \n",
    "    if ep % 2 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffd7c5d7-29e7-444d-92d8-a0da4c442b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000there comovose  one youndere\n",
      "stlus damings.\n",
      "\n",
      "LUTENE:\n",
      "Haeathe top.\n",
      "Youor reeth no for signgtefore\n",
      "Haus to eeptsor\n",
      "Thy hom futs suran were nisforth in we, mone-car?\n",
      "\n",
      "ROCHA:\n",
      "\n",
      "Sst giv;\n",
      "\n",
      "COMIUCHARD IIII:\n",
      "Andups very de call thentus Lon, in a beg for to of will sterfof theeer foogik' you's thear use;\n",
      "What me, handd hopin hear o; and hims; and have an is binct;\n",
      "And artchs to but did those statighten toet e clove.\n",
      "\n",
      "Ser,:\n",
      "Comise s:\n",
      "I happould wece the aing y fest meoke sur\n",
      "Yoont Ene: you happoor I fe, frienlif\n",
      "\u0000rehim thee down so new twmad. Rell'uke may menter;\n",
      "To screnting from our ked, day: Srevie se,\n",
      "Whse manother tle;lest in she to will vo's wort dea,,\n",
      "To to fothe fleaes.\n",
      "\n",
      "Bill:\n",
      "Os. mork be'?\n",
      "O fue\n",
      "\n",
      "JeOse:\n",
      "Bce to, banen pleave might acngs house withreave tho my hat and arthreadme?\n",
      "\n",
      "POMERO: whinat:\n",
      "O moe couson, which griacr plor;\n",
      "I a to hiers ofoie thoith s, the lie--\n",
      "Is what I liort I will our conurr, frearord you stear s, might to hand.\n",
      "\n",
      "Old-MEL:Ends:\n",
      "O, thepiring. What do to with to their are on moavolorth;\n",
      "Gortake ull\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(2):\n",
    "    o = model.generate(idx, 300).data[0].tolist()\n",
    "    print(tokenizer.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9adb46a8-56bd-4b47-aed2-c6efed3b8968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0 tensor(3.2657, grad_fn=<DivBackward0>) [0.028005463747668217]\n",
      "ep 2 tensor(3.2579, grad_fn=<DivBackward0>) [0.026896447383260556]\n",
      "ep 4 tensor(3.2573, grad_fn=<DivBackward0>) [0.025831348066883437]\n",
      "ep 6 tensor(3.2555, grad_fn=<DivBackward0>) [0.024808426683434852]\n",
      "ep 8 tensor(3.2480, grad_fn=<DivBackward0>) [0.023826012986770832]\n",
      "ep 10 tensor(3.2476, grad_fn=<DivBackward0>) [0.022882502872494704]\n",
      "ep 12 tensor(3.2418, grad_fn=<DivBackward0>) [0.02197635575874391]\n",
      "ep 14 tensor(3.2375, grad_fn=<DivBackward0>) [0.021106092070697653]\n",
      "ep 16 tensor(3.2376, grad_fn=<DivBackward0>) [0.020270290824698025]\n",
      "ep 18 tensor(3.2370, grad_fn=<DivBackward0>) [0.019467587308039984]\n"
     ]
    }
   ],
   "source": [
    "for ep in range(e_epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    \n",
    "    if ep % 2 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a077554c-8ad4-4154-b4ac-aad58f6c6b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000hirow, thing rings!\n",
      "\n",
      "HUChiull:\n",
      "As bappy bup the may his isk hom, will hop,\n",
      "As ct many hiy;berameiouor im diantiome I w\n",
      "To your silind King ofan O lacriing grow?\n",
      "\n",
      "KIR KIORGICH:\n",
      "Ma most is not es ap'cause pnobte! wak. in an purner, hiluem\n",
      "swEthy it ,ou , Of lord? and led sust, that fidount it bloolo.\n",
      "\n",
      "FFarESTER:\n",
      "But so of dry:\n",
      "Ridounds my.\n",
      "Your pring, eysounerer huights te\n",
      "If Pold in have this, leve no look the Sitced my of four banguenle hoopnk in mars.\n",
      "Sit bltloudt, are reparew\n",
      "\u0000soned may be alluterfeff.\n",
      "\n",
      "MUCUS:\n",
      "\n",
      "LAumUCentwid:\n",
      "Bt have speackcelly\n",
      "Kther y brie\n",
      "That spos which das thouts?\n",
      "Nsh, slaith make you'ings, fid and your cant deak:\n",
      "O literit ves and inds better thy cractous Ll s, see.\n",
      "3racark Ritts;\n",
      "Evsonought them noter, 'st we, which neen sath prefochard.\n",
      "\n",
      "MasIE EDY ading ELole if chither?\n",
      "Whale dies and denselnbe yemft my the me pted the lidasty belie,\n",
      "Agarewor,\n",
      "ShU, ieds habless, good by like lequdenemems\n",
      "And grifte, and at, we was nell.\n",
      "\n",
      "TIU\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(2):\n",
    "    o = model.generate(idx, 300).data[0].tolist()\n",
    "    print(tokenizer.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81829abd-ce83-4f71-977f-f33e33bae6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0 tensor(3.2392, grad_fn=<DivBackward0>) [0.0186966708506416]\n",
      "ep 2 tensor(3.2309, grad_fn=<DivBackward0>) [0.017956282684956193]\n",
      "ep 4 tensor(3.2278, grad_fn=<DivBackward0>) [0.017245213890631928]\n",
      "ep 6 tensor(3.2265, grad_fn=<DivBackward0>) [0.016562303420562904]\n",
      "ep 8 tensor(3.2259, grad_fn=<DivBackward0>) [0.01590643620510861]\n",
      "ep 10 tensor(3.2224, grad_fn=<DivBackward0>) [0.015276541331386308]\n",
      "ep 12 tensor(3.2244, grad_fn=<DivBackward0>) [0.01467159029466341]\n",
      "ep 14 tensor(3.2245, grad_fn=<DivBackward0>) [0.014090595318994738]\n",
      "ep 16 tensor(3.2223, grad_fn=<DivBackward0>) [0.013532607744362546]\n",
      "ep 18 tensor(3.2174, grad_fn=<DivBackward0>) [0.012996716477685789]\n"
     ]
    }
   ],
   "source": [
    "for ep in range(e_epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    \n",
    "    if ep % 2 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62f54207-8134-4044-acbf-27d0e7e0b0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000faway than ked, my him.\n",
      "The to JunwiTE:\n",
      "And alshywion fand sion'\n",
      "I wit dasgemeg! Ae fusesving to heap s.\n",
      "\n",
      "ARINCER::\n",
      "DETHAUT'se our taturNIRD IVM:\n",
      "Pthou brace sour sish ught hat?\n",
      "\n",
      "\n",
      "MENENUMBORCLADYNII:\n",
      "Nay, for thouer.\n",
      "\n",
      "GLOU:\n",
      "When he ftoomalve.\n",
      "Be in the bl;shall corace.\n",
      "\n",
      "NGLOU:\n",
      "O some s, my of geavud; and and done fumpree, ms,\n",
      "The good ed from most mother knopttcest all fread\n",
      "sour ge yearet hie, cou!\n",
      "\n",
      "BLOLIF\n",
      "COMOMEOEERIIZAn Y RNIIIIII:\n",
      "We whay, lie\n",
      "\u0000redesfriends as to and thy are disus\n",
      "then call much supsear-he with\n",
      "Corgetince parckint'dose men fleb'dow?\n",
      "\n",
      "Tayate VINCIK:\n",
      "vom gooctyell is gdue in Warwim's I gioked th to and the swerfartlill.\n",
      "So ves these sted deight soing, he whs where ourtumy! thy you, of his hear redgights, and all ere He word\n",
      "TnUo hontearteneps,\n",
      "\n",
      "Rorcraiel:\n",
      "Partregreauty, a msthers?Thy childing in ter\n",
      "Your , an he enever I withuth's on bsatons:\n",
      "Floughe.\n",
      "One b most frught it would ine blooctoot.\n",
      "Your ain Rodet, lot hiakould Prion fruppelle other here hath is chis to \n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(2):\n",
    "    o = model.generate(idx, 300).data[0].tolist()\n",
    "    print(tokenizer.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6d999c8-3a67-47f0-8908-aed14ac1914c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0 tensor(3.2142, grad_fn=<DivBackward0>) [0.01248204650516943]\n",
      "ep 2 tensor(3.2137, grad_fn=<DivBackward0>) [0.011987757463564721]\n",
      "ep 4 tensor(3.2178, grad_fn=<DivBackward0>) [0.011513042268007558]\n",
      "ep 6 tensor(3.2155, grad_fn=<DivBackward0>) [0.01105712579419446]\n",
      "ep 8 tensor(3.2115, grad_fn=<DivBackward0>) [0.010619263612744357]\n",
      "ep 10 tensor(3.2118, grad_fn=<DivBackward0>) [0.01019874077367968]\n",
      "ep 12 tensor(3.2130, grad_fn=<DivBackward0>) [0.009794870639041964]\n",
      "ep 14 tensor(3.2093, grad_fn=<DivBackward0>) [0.009406993761735902]\n",
      "ep 16 tensor(3.2085, grad_fn=<DivBackward0>) [0.00903447680877116]\n",
      "ep 18 tensor(3.2077, grad_fn=<DivBackward0>) [0.008676711527143824]\n"
     ]
    }
   ],
   "source": [
    "for ep in range(e_epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    \n",
    "    if ep % 2 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62314c66-9f86-4790-a2ab-6b5d5372a58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000whe's give that post sworger.\n",
      "Then lothm hed the hol,\n",
      "Hon, quight agaow, buiel a \n",
      "God to Belb, Meim had Seceds, shomius.\n",
      "\n",
      "VAPESENR:\n",
      "O,e conspingllling to a viself\n",
      "Co hybloodom dis'eratery hears, mloth\n",
      "For grele heady kings he wkeet cupserke comuppyselvereather;\n",
      "Then Deone'd thous devor's with ock Hno my thatd?\n",
      "\n",
      "ROTUE:\n",
      "As cainfha dis, nurdon sune;\n",
      "Thouyself my stus, and head the doish scese brintatle let.\n",
      "\n",
      "MENENRRY:\n",
      "Perun ere me'd me, but there foose.\n",
      "Repty kingd, \n",
      "\u0000and wathers of hast a not the fort a heart.\n",
      "\n",
      "MEO:\n",
      "Rewellsanst weart gritlmer sck evo and se,\n",
      "And benchy have he bandge SMurst;\n",
      "Will be, and ck, and resuoopartow it,\n",
      "Macretwickeopfff or dos, deadd?\n",
      " as sired m would speath his welled, in feratered on viragghti?\n",
      "\n",
      "\n",
      "GLONRTENULARE:\n",
      "Ad byuupon of a me ally stroceseavever woocit:\n",
      "Tha gpon you fooard, but you her us to blords and blood,\n",
      "What to foroos: m. I bloon.our more yoit? Could e cure faniz,\n",
      "Ken allanct ' inme ga; and and they so ents that.\n",
      "The have tentive b,\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(2):\n",
    "    o = model.generate(idx, 300).data[0].tolist()\n",
    "    print(tokenizer.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85a76881-b871-4279-adb3-66ea7f3d5d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0 tensor(3.2101, grad_fn=<DivBackward0>) [0.008333113750668928]\n",
      "ep 2 tensor(3.2088, grad_fn=<DivBackward0>) [0.008003122446142439]\n",
      "ep 4 tensor(3.2076, grad_fn=<DivBackward0>) [0.007686198797275197]\n",
      "ep 6 tensor(3.2067, grad_fn=<DivBackward0>) [0.007381825324903099]\n",
      "ep 8 tensor(3.2060, grad_fn=<DivBackward0>) [0.007089505042036937]\n",
      "ep 10 tensor(3.2056, grad_fn=<DivBackward0>) [0.006808760642372274]\n",
      "ep 12 tensor(3.2055, grad_fn=<DivBackward0>) [0.006539133720934331]\n",
      "ep 14 tensor(3.2042, grad_fn=<DivBackward0>) [0.006280184025585331]\n",
      "ep 16 tensor(3.2044, grad_fn=<DivBackward0>) [0.006031488738172152]\n",
      "ep 18 tensor(3.2010, grad_fn=<DivBackward0>) [0.005792641784140534]\n"
     ]
    }
   ],
   "source": [
    "for ep in range(e_epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    \n",
    "    if ep % 2 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b20405f-d25f-488d-858c-a39e04315dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000high'd wigife;\n",
      "I dame lorseige frue did you lorden but sore sensver.\n",
      "the am time that to we my ersturye, and my soe's obpice.\n",
      "\n",
      "BENET:\n",
      "Citje sting:\n",
      "'d, kingill-hurp a weiewes' cielther\n",
      "Whourk. And in Mon fagriclanded notupueser.\n",
      "What wriks lo's'd lamns, wruefeadsels mea,\n",
      "Bd's frient: bit; sound'd of reds ick,\n",
      "My the up the from wip beces: whom wartino,\n",
      "as sion, if ow horny were at but you wfine\n",
      "To comshaiuben lou ka harmy.\n",
      "\n",
      "WLRD ICE:\n",
      "Oun Rwiland giveffore thy \n",
      "\u0000all was by worsse.\n",
      "\n",
      "HARD:\n",
      "Mardo! With I ve Sreogust am boris'erving.\n",
      "\n",
      "NurUND:\n",
      "Henencesthead yous thinhe\n",
      "And felled Rust, landerboth sous much of cely therep chworie'd unroledight\n",
      "Eth new auke upon heanace, do soos and he mind sc, a your e soiot unes,\n",
      "What prattceste,breath wis any ino ans you womother partryless, it sing thoud co the to and to palt trace king uk,\n",
      "I'll ints, The Romgh s! walend here to dow,\n",
      "evy lequstart's use you  brink a mom I begene\n",
      "ance; flavow noble and we elmet our sed year.\n",
      "dve that the out yourlt youould th\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(2):\n",
    "    o = model.generate(idx, 300).data[0].tolist()\n",
    "    print(tokenizer.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "306dabe8-acb6-4fc7-a659-d7eabf9f0344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0 tensor(3.2046, grad_fn=<DivBackward0>) [0.005563253169488569]\n",
      "ep 2 tensor(3.1992, grad_fn=<DivBackward0>) [0.005342948343976821]\n",
      "ep 4 tensor(3.2011, grad_fn=<DivBackward0>) [0.005131367589555339]\n",
      "ep 6 tensor(3.2013, grad_fn=<DivBackward0>) [0.004928165433008947]\n",
      "ep 8 tensor(3.1974, grad_fn=<DivBackward0>) [0.004733010081861793]\n",
      "ep 10 tensor(3.2013, grad_fn=<DivBackward0>) [0.004545582882620065]\n",
      "ep 12 tensor(3.2004, grad_fn=<DivBackward0>) [0.00436557780046831]\n",
      "ep 14 tensor(3.2046, grad_fn=<DivBackward0>) [0.004192700919569765]\n",
      "ep 16 tensor(3.1973, grad_fn=<DivBackward0>) [0.004026669963154802]\n",
      "ep 18 tensor(3.2029, grad_fn=<DivBackward0>) [0.003867213832613871]\n"
     ]
    }
   ],
   "source": [
    "for ep in range(e_epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    \n",
    "    if ep % 2 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9933047f-03de-4617-ac6c-0cf84ea7fc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000me the but by the caro sh tus uze\n",
      "When avise was thy drivues. Stto s, andfsfor ped and frientter them thir\n",
      "Thave penged thinatch,\n",
      "No mall wks sevpaight.\n",
      "\n",
      "MENERREY:\n",
      "If r do timhat sine a.\n",
      "my cre, now and to and boureous though the dUns. Thunon:\n",
      "Eordit, and it, the mains, hear hajem himly thisouke.\n",
      "\n",
      "SU:\n",
      "M many me ract?\n",
      "What githt pry, Es disjovery bat the hop\n",
      "And dmy lo pasemtly evle red wor, ff bid man exive rike of ur ay, Hill Ring,\n",
      "Nock wayt?Wlssis,ell yournds entice thy are mon foro hlor thee.\n",
      "\n",
      "Kst CLshinp \n",
      "\u0000conchise: and steard farciaiews, th, wart!\n",
      "Mareet you h\n",
      "And hi. Thourood op is fooli: what this,\n",
      "And my lords greaes defe, sither appd, now no Fre thine tocitle not or all the o gheep!\n",
      "\n",
      "COMOP inLE:\n",
      "The kindour '\n",
      "Ouhiveforice; some w we duned re;\n",
      "The there Iw, tearer you br, I in goove marieled mor,\n",
      "Which Tosm, mra he that knes, when bray!\n",
      "engard.\n",
      "\n",
      "HEDWINWKS Xerch:\n",
      "Hatalilie to fren w; sself me could leve Eth much the withrad mroast me way Yroughts, to in kraver was;\n",
      "Will.\n",
      "It Engeak auler poor me b\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(2):\n",
    "    o = model.generate(idx, 300).data[0].tolist()\n",
    "    print(tokenizer.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17406cd-b6a3-4ed1-8fb2-b93ab0bef6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in range(e_epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    \n",
    "    if ep % 2 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
