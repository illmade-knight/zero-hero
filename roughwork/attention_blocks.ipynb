{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "965b36f1-1440-4a07-a843-80cba31c34e8",
   "metadata": {},
   "source": [
    "### What if we increase the corpus\n",
    "\n",
    "let's start reading more books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d689a91-95ca-42cd-802e-ab97496243cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8919ad-3d6b-4421-94ce-553e3a506dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run bookreader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b6ef18-283c-41fd-9375-ef8d13ed5e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice = BookReader(\"Through the looking glass.txt\", \"a tangled.txt\", \"Hunting of the snark.txt\", \"alice.txt\")\n",
    "vocab_size = alice.vocab_size\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a713daf8-4a5f-430d-8f00-9c6db6743d22",
   "metadata": {},
   "source": [
    "### Get the batch with both x and y unseparated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91f9fe0b-25d9-4578-a105-4eb99138428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, batch_length=5, batch_size=5):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    ix = torch.randint(len(data) - batch_length, (batch_size,))\n",
    "    b = torch.stack([data[i:i+batch_length] for i in ix])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac12ed62-275e-43a8-b17e-9b0b6da58efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.tensor(alice.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3b116f-f526-4958-bfed-07f665e89cba",
   "metadata": {},
   "source": [
    "### Create an attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf6cf111-bf37-49fe-8e92-de8a35f8e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, c, head_size, content_length):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(c, head_size, bias=False)\n",
    "        self.query = nn.Linear(c, head_size, bias=False)\n",
    "        self.value = nn.Linear(c, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(content_length, content_length)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   \n",
    "        q = self.query(x)\n",
    "        \n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 \n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        \n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7138eed8-721e-4752-bf9f-8ebca24882d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, fan_in, multiplier = 4):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = OrderedDict([\n",
    "            (\"l_in\", nn.Linear(fan_in, multiplier * fan_in)),\n",
    "            (\"relu\", nn.ReLU()),\n",
    "            (\"l_out\", nn.Linear(multiplier * fan_in, fan_in)),\n",
    "        ])\n",
    "        self.net = nn.Sequential(\n",
    "            layers\n",
    "        )\n",
    "\n",
    "        initial = layers['l_in']\n",
    "        nn.init.kaiming_normal_(initial.weight, nonlinearity=\"relu\")\n",
    "        layers['l_in'].weight.data = initial.weight.data * 3/5\n",
    "        if initial.bias is not None:\n",
    "            nn.init.constant_(initial.bias, 0)\n",
    "\n",
    "        final = layers['l_out']\n",
    "        layers['l_out'].weight.data = final.weight.data * .2\n",
    "        if final.bias is not None:\n",
    "            nn.init.constant_(final.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b77ec387-64c7-43b3-82a5-b24e22eb84a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "989f2ee4-1968-4bf6-8352-4e37ebaca633",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHead(nn.Module):\n",
    "    def __init__(self, num_heads, head_size, embed_size, content_length):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(embed_size, head_size, content_length) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, embed_size)\n",
    "        self.dropout = nn.Dropout(.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5ccc997-e0f3-43a3-a696-594a3dec0710",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, num_heads, head_size, embed_size, content_length, ff_mul):\n",
    "        super().__init__()\n",
    "        self.multihead = MultiHead(num_heads, head_size, embed_size, content_length)\n",
    "        self.n1 = nn.LayerNorm(embed_size)\n",
    "        self.ff = FeedForward(embed_size, ff_mul)\n",
    "        self.n1 = nn.LayerNorm(embed_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_a = x.detach()\n",
    "        x_b = x.detach()\n",
    "        x = self.multihead(x)\n",
    "        x = x + x_a\n",
    "        x = self.n1(x)\n",
    "        x = self.ff(x)\n",
    "        x = x + x_b\n",
    "        x = self.n1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dff586a7-6f05-4e2a-95f4-9a07c8e27203",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFMultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, content_length, num_heads, head_size, multiplier=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.positional_embed = nn.Embedding(content_length, embed_size)\n",
    "        # self.mutli_attention = MultiHead(num_heads, head_size, embed_size, content_length)\n",
    "        # self.lna = nn.LayerNorm(embed_size)\n",
    "        # self.ff = FeedForward(embed_size, multiplier)\n",
    "        # self.lnff = nn.LayerNorm(embed_size)\n",
    "        self.atta = AttentionBlock(num_heads, head_size, embed_size, content_length, multiplier)\n",
    "        self.attb = AttentionBlock(num_heads, head_size, embed_size, content_length, multiplier)\n",
    "        self.decode = nn.Linear(embed_size, vocab_size)\n",
    "        self.content_length = content_length\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        #idx B,T\n",
    "        B, T = idx.shape\n",
    "\n",
    "        idx_e = self.vocab_embed(idx)\n",
    "        # note tr is always the same - so the learning here is information passed back to the positional_embed from loss\n",
    "        tr = torch.arange(T)\n",
    "        pos_e = self.positional_embed(tr)\n",
    "\n",
    "        x = idx_e + pos_e\n",
    "        \n",
    "        x = self.atta(x)\n",
    "        x = self.attb(x)\n",
    "        logits = self.decode(x)\n",
    "        # print(\"decode out\", x.shape)\n",
    "        # print(\"targets\", targets.shape)\n",
    "        # return None, None\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            targets = targets.reshape(B*T)\n",
    "            loss = F.cross_entropy(logits.view(B*T, -1), targets) #.resize(B*T)) # loss function\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -self.content_length:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16926363-2c95-4998-a0a9-8eee16e1abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_batch(data, batch_length=5, batch_size=5, i=0):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    if i == 0:\n",
    "        ix = torch.randint(len(data) - batch_length, (batch_size,))\n",
    "    else:\n",
    "        ix = torch.arange(1, 5) + 1 + i\n",
    "\n",
    "    b = torch.stack([data[i:i+batch_length] for i in ix])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f874381a-99eb-4bba-bde0-b10c9632e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "@torch.no_grad()\n",
    "def split_loss(split):\n",
    "    split_len = len(split)\n",
    "    total_loss = 0\n",
    "    batch_size = 50\n",
    "    num_batches = math.floor(split_len / batch_size)\n",
    "    print(\"num_batches\", split_len, num_batches)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        t_b = get_val_batch(split, context_length+1, batch_size, i*batch_size)\n",
    "        \n",
    "        x = t_b[:, 0: context_length]\n",
    "        y = t_b[:, context_length: context_length+1]\n",
    "        \n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, batch_loss = model(x, y)\n",
    "        \n",
    "        total_loss = total_loss + batch_loss\n",
    "    \n",
    "    print(\"total loss\", total_loss, total_loss / num_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c2d3c52-0c8a-4ab6-8121-7e8377d361d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "28137  parameters\n",
      "ep 0 tensor(2.3184, grad_fn=<DivBackward0>) [0.098]\n",
      "ep 2 tensor(1.9948, grad_fn=<DivBackward0>) [0.0941192]\n",
      "ep 4 tensor(1.9217, grad_fn=<DivBackward0>) [0.09039207968]\n",
      "ep 6 tensor(1.8863, grad_fn=<DivBackward0>) [0.086812553324672]\n",
      "ep 8 tensor(1.8645, grad_fn=<DivBackward0>) [0.08337477621301498]\n",
      "ep 10 tensor(1.8534, grad_fn=<DivBackward0>) [0.08007313507497958]\n",
      "ep 12 tensor(1.8390, grad_fn=<DivBackward0>) [0.07690223892601039]\n",
      "ep 14 tensor(1.8308, grad_fn=<DivBackward0>) [0.07385691026454037]\n",
      "ep 16 tensor(1.8219, grad_fn=<DivBackward0>) [0.07093217661806457]\n",
      "ep 18 tensor(1.8187, grad_fn=<DivBackward0>) [0.06812326242398921]\n",
      "ep 20 tensor(1.8101, grad_fn=<DivBackward0>) [0.06542558123199924]\n",
      "ep 22 tensor(1.8028, grad_fn=<DivBackward0>) [0.06283472821521206]\n",
      "ep 24 tensor(1.7994, grad_fn=<DivBackward0>) [0.06034647297788966]\n",
      "ep 26 tensor(1.7952, grad_fn=<DivBackward0>) [0.05795675264796523]\n",
      "ep 28 tensor(1.7911, grad_fn=<DivBackward0>) [0.055661665243105805]\n",
      "ep 30 tensor(1.7827, grad_fn=<DivBackward0>) [0.053457463299478813]\n",
      "ep 32 tensor(1.7827, grad_fn=<DivBackward0>) [0.05134054775281945]\n",
      "ep 34 tensor(1.7798, grad_fn=<DivBackward0>) [0.0493074620618078]\n",
      "ep 36 tensor(1.7798, grad_fn=<DivBackward0>) [0.04735488656416021]\n",
      "ep 38 tensor(1.7729, grad_fn=<DivBackward0>) [0.04547963305621946]\n",
      "ep 40 tensor(1.7691, grad_fn=<DivBackward0>) [0.04367863958719317]\n",
      "ep 42 tensor(1.7675, grad_fn=<DivBackward0>) [0.04194896545954032]\n",
      "ep 44 tensor(1.7666, grad_fn=<DivBackward0>) [0.04028778642734252]\n",
      "ep 46 tensor(1.7641, grad_fn=<DivBackward0>) [0.038692390084819756]\n",
      "ep 48 tensor(1.7662, grad_fn=<DivBackward0>) [0.03716017143746089]\n",
      "ep 50 tensor(1.7603, grad_fn=<DivBackward0>) [0.03568862864853744]\n",
      "ep 52 tensor(1.7591, grad_fn=<DivBackward0>) [0.034275358954055354]\n",
      "ep 54 tensor(1.7562, grad_fn=<DivBackward0>) [0.03291805473947476]\n",
      "ep 56 tensor(1.7546, grad_fn=<DivBackward0>) [0.03161449977179156]\n",
      "ep 58 tensor(1.7527, grad_fn=<DivBackward0>) [0.030362565580828612]\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "training_runs = 800\n",
    "batch_size = 96\n",
    "context_length = 12\n",
    "learning_rate = .1\n",
    "embedding_dimensions = 32\n",
    "num_heads = 4\n",
    "head_size = embedding_dimensions // num_heads\n",
    "\n",
    "print(head_size)\n",
    "# our embedding_dimensions are still 'small' so we mutliply the size our our feed forward network to make up\n",
    "multiplier = 4\n",
    "model = FFMultiHeadAttention(embedding_dimensions, context_length, num_heads, head_size, multiplier)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()), ' parameters')\n",
    "\n",
    "lmbda = lambda epoch: 0.98\n",
    "\n",
    "m_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    \n",
    "    if ep % 2 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f397197a-b710-46a3-b974-fb9605a29ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.tensor(alice.data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f219b8c9-2430-4b93-a0a0-4b015bd0ce1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches 53850 1077\n",
      "total loss tensor(1831.9103) tensor(1.7009)\n",
      "None 53850\n",
      "\n",
      "who on\n",
      "them which winh \n",
      "i d one is about  milight cover was ideven answer assuitely   do s sbit to\n",
      "g\n"
     ]
    }
   ],
   "source": [
    "print(split_loss(dev), len(dev))\n",
    "\n",
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(1):\n",
    "    o = model.generate(idx, 100).data[0].tolist()\n",
    "    print(alice.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3397ee7-a815-4297-bb89-f0ae27a88a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow mor loops without restarting\n",
    "e_epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "505576c1-4af6-44c5-b51c-fdf5f3a77587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "nightly\n",
      "wand go  and gavter\n",
      " \n",
      " it which? \n",
      " you\n",
      " of good not  no bin in the two the thought welled\n",
      "the\n",
      "worden them capty be subject  n the caweanged air \n",
      "      they offution  and one naw you lioust that alicell of the tarm you can for make \n",
      " irpenc it shall getting minum meet is?eace to felld they down  nogicill\n",
      " father dired a brobperus dinah way content readed bather plased in in\n",
      "   e   that  and he dore it galed  and eying up \n",
      "1  a basch \n",
      " bustry alice thought bown    j  lappine a make ebnded  pokes it will many\n",
      "the qanswer \n",
      "alice and go the other gstut  is how to rear ttwice  only to tenct \n",
      "\n",
      " with of man  hoped  and exgle too hand in\n",
      "susalic herales above soat  you so maname to becony! \n",
      "do ilnted   of\n",
      "she\n",
      "joorewist \n",
      "and to try lest \n",
      "she mapter on a do said \n",
      "     the rimarled  asons lande bonet not a nest at is makes you seemed to the equenly washer wordertabelted   as  my excely? \n",
      " i shouldn  t is blaid  andn land did  if once \n",
      "  bybout  with upony arral  gived\n",
      "puzzled \n",
      " she s lawi\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(1):\n",
    "    o = model.generate(idx, 1000).data[0].tolist()\n",
    "    print(alice.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de6e4b2b-94bb-47c3-b7bd-083bc9e57554",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff5984e4-9fca-4553-ade9-27100e9b770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow mor loops without restarting\n",
    "e_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92654c18-31b6-45bd-bdb6-4bb97875fa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0 tensor(1.6990, grad_fn=<DivBackward0>) [0.029160207983827797]\n",
      "ep 2 tensor(1.6864, grad_fn=<DivBackward0>) [0.028005463747668217]\n",
      "ep 4 tensor(1.6820, grad_fn=<DivBackward0>) [0.026896447383260556]\n",
      "ep 6 tensor(1.6754, grad_fn=<DivBackward0>) [0.025831348066883437]\n",
      "ep 8 tensor(1.6748, grad_fn=<DivBackward0>) [0.024808426683434852]\n",
      "ep 10 tensor(1.6710, grad_fn=<DivBackward0>) [0.023826012986770832]\n",
      "ep 12 tensor(1.6707, grad_fn=<DivBackward0>) [0.022882502872494704]\n",
      "ep 14 tensor(1.6672, grad_fn=<DivBackward0>) [0.02197635575874391]\n",
      "ep 16 tensor(1.6631, grad_fn=<DivBackward0>) [0.021106092070697653]\n",
      "ep 18 tensor(1.6622, grad_fn=<DivBackward0>) [0.020270290824698025]\n",
      "ep 20 tensor(1.6596, grad_fn=<DivBackward0>) [0.019467587308039984]\n",
      "ep 22 tensor(1.6557, grad_fn=<DivBackward0>) [0.0186966708506416]\n",
      "ep 24 tensor(1.6553, grad_fn=<DivBackward0>) [0.017956282684956193]\n",
      "ep 26 tensor(1.6542, grad_fn=<DivBackward0>) [0.017245213890631928]\n",
      "ep 28 tensor(1.6530, grad_fn=<DivBackward0>) [0.016562303420562904]\n",
      "ep 30 tensor(1.6497, grad_fn=<DivBackward0>) [0.01590643620510861]\n",
      "ep 32 tensor(1.6489, grad_fn=<DivBackward0>) [0.015276541331386308]\n",
      "ep 34 tensor(1.6461, grad_fn=<DivBackward0>) [0.01467159029466341]\n",
      "ep 36 tensor(1.6442, grad_fn=<DivBackward0>) [0.014090595318994738]\n",
      "ep 38 tensor(1.6444, grad_fn=<DivBackward0>) [0.013532607744362546]\n",
      "ep 40 tensor(1.6428, grad_fn=<DivBackward0>) [0.012996716477685789]\n",
      "ep 42 tensor(1.6402, grad_fn=<DivBackward0>) [0.01248204650516943]\n",
      "ep 44 tensor(1.6399, grad_fn=<DivBackward0>) [0.011987757463564721]\n",
      "ep 46 tensor(1.6382, grad_fn=<DivBackward0>) [0.011513042268007558]\n",
      "ep 48 tensor(1.6389, grad_fn=<DivBackward0>) [0.01105712579419446]\n",
      "ep 50 tensor(1.6383, grad_fn=<DivBackward0>) [0.010619263612744357]\n",
      "ep 52 tensor(1.6352, grad_fn=<DivBackward0>) [0.01019874077367968]\n",
      "ep 54 tensor(1.6311, grad_fn=<DivBackward0>) [0.009794870639041964]\n",
      "ep 56 tensor(1.6383, grad_fn=<DivBackward0>) [0.009406993761735902]\n",
      "ep 58 tensor(1.6334, grad_fn=<DivBackward0>) [0.00903447680877116]\n"
     ]
    }
   ],
   "source": [
    "for ep in range(e_epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    \n",
    "    if ep % 2 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa496f61-20fd-495e-9053-7358877c2359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches 53850 1077\n",
      "total loss tensor(1756.2078) tensor(1.6306)\n",
      "None 53850\n",
      "\n",
      "up   he sport  to was beave unical! i never while no came! one\n",
      "aplessinning exvking  said to conden words assual deven look the poes to out\n",
      "peoped the in were pust try eadight   the with extenberg becal suppre! she was you an if wilddeo uspeak day on  looks   the more was with a replied\n",
      "    herd wit\n",
      "\n",
      "defore offendents  and  you re to herself  the\n",
      "set! \n",
      " it is cready musts there\n",
      "one a with sat to the best assumes pair  meaning  grows?  said t him  a reparake is to was little roose\n",
      "one a twicerles  the\n",
      "prisper speak done it \n",
      "more \n",
      "that it was large two  we\n",
      "answer heage\n",
      "      z saw arm    i trass a\n"
     ]
    }
   ],
   "source": [
    "print(split_loss(dev), len(dev))\n",
    "\n",
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(2):\n",
    "    o = model.generate(idx, 300).data[0].tolist()\n",
    "    print(alice.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "969ce431-24fe-4dd8-9969-61f7933e4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"all_alice_checkpoint\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
