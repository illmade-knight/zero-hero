{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "965b36f1-1440-4a07-a843-80cba31c34e8",
   "metadata": {},
   "source": [
    "### OK, we've run out of space in names\n",
    "\n",
    "let's start reading books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d689a91-95ca-42cd-802e-ab97496243cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8919ad-3d6b-4421-94ce-553e3a506dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run bookreader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5b6ef18-283c-41fd-9375-ef8d13ed5e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice = BookReader(\"alice.txt\")\n",
    "vocab_size = alice.vocab_size\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a713daf8-4a5f-430d-8f00-9c6db6743d22",
   "metadata": {},
   "source": [
    "### Get the batch with both x and y unseparated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91f9fe0b-25d9-4578-a105-4eb99138428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, batch_length=5, batch_size=5):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    ix = torch.randint(len(data) - batch_length, (batch_size,))\n",
    "    b = torch.stack([data[i:i+batch_length] for i in ix])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac12ed62-275e-43a8-b17e-9b0b6da58efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.tensor(names.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3b116f-f526-4958-bfed-07f665e89cba",
   "metadata": {},
   "source": [
    "### Create an attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf6cf111-bf37-49fe-8e92-de8a35f8e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, c, head_size, content_length):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(c, head_size, bias=False)\n",
    "        self.query = nn.Linear(c, head_size, bias=False)\n",
    "        self.value = nn.Linear(c, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(content_length, content_length)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   \n",
    "        q = self.query(x)\n",
    "        \n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 \n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        \n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7138eed8-721e-4752-bf9f-8ebca24882d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, fan_in, multiplier = 4):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = OrderedDict([\n",
    "            (\"l_in\", nn.Linear(fan_in, multiplier * fan_in)),\n",
    "            (\"relu\", nn.ReLU()),\n",
    "            (\"l_out\", nn.Linear(multiplier * fan_in, fan_in)),\n",
    "        ])\n",
    "        self.net = nn.Sequential(\n",
    "            layers\n",
    "        )\n",
    "\n",
    "        initial = layers['l_in']\n",
    "        nn.init.kaiming_normal_(initial.weight, nonlinearity=\"relu\")\n",
    "        layers['l_in'].weight.data = initial.weight.data * 3/5\n",
    "        if initial.bias is not None:\n",
    "            nn.init.constant_(initial.bias, 0)\n",
    "\n",
    "        final = layers['l_out']\n",
    "        layers['l_out'].weight.data = final.weight.data * .2\n",
    "        if final.bias is not None:\n",
    "            nn.init.constant_(final.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2c5ab893-cdb8-4702-9459-99a717f81b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FFAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, head_size, content_length):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.positional_embed = nn.Embedding(content_length, embed_size)\n",
    "        self.attention = Head(embed_size, head_size, content_length)\n",
    "        self.ff = FeedForward(head_size)\n",
    "        self.decode = nn.Linear(head_size, vocab_size)\n",
    "        self.content_length = content_length\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        #idx B,T\n",
    "        B, T = idx.shape\n",
    "\n",
    "        idx_e = self.vocab_embed(idx)\n",
    "        # note tr is always the same - so the learning here is information passed back to the positional_embed from loss\n",
    "        tr = torch.arange(T)\n",
    "        pos_e = self.positional_embed(tr)\n",
    "\n",
    "        x = idx_e + pos_e\n",
    "        x = self.attention(x)\n",
    "        \n",
    "        x = self.ff(x)\n",
    "        \n",
    "        logits = self.decode(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits.view(B*T, -1), targets.resize(B*T)) # loss function\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -self.content_length:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b77ec387-64c7-43b3-82a5-b24e22eb84a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cee0cbcc-380d-4da9-a9e2-626359763ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6897, grad_fn=<DivBackward0>)\n",
      "tensor(2.4406, grad_fn=<DivBackward0>)\n",
      "tensor(2.3813, grad_fn=<DivBackward0>)\n",
      "tensor(2.3484, grad_fn=<DivBackward0>)\n",
      "tensor(2.3330, grad_fn=<DivBackward0>)\n",
      "tensor(2.3239, grad_fn=<DivBackward0>)\n",
      "tensor(2.3134, grad_fn=<DivBackward0>)\n",
      "tensor(2.2990, grad_fn=<DivBackward0>)\n",
      "tensor(2.2913, grad_fn=<DivBackward0>)\n",
      "tensor(2.2834, grad_fn=<DivBackward0>)\n",
      "tensor(2.2776, grad_fn=<DivBackward0>)\n",
      "tensor(2.2745, grad_fn=<DivBackward0>)\n",
      "tensor(2.2713, grad_fn=<DivBackward0>)\n",
      "tensor(2.2636, grad_fn=<DivBackward0>)\n",
      "tensor(2.2631, grad_fn=<DivBackward0>)\n",
      "tensor(2.2551, grad_fn=<DivBackward0>)\n",
      "tensor(2.2523, grad_fn=<DivBackward0>)\n",
      "tensor(2.2554, grad_fn=<DivBackward0>)\n",
      "tensor(2.2477, grad_fn=<DivBackward0>)\n",
      "tensor(2.2441, grad_fn=<DivBackward0>)\n",
      "tensor(2.2467, grad_fn=<DivBackward0>)\n",
      "tensor(2.2452, grad_fn=<DivBackward0>)\n",
      "tensor(2.2434, grad_fn=<DivBackward0>)\n",
      "tensor(2.2398, grad_fn=<DivBackward0>)\n",
      "tensor(2.2427, grad_fn=<DivBackward0>)\n",
      "tensor(2.2358, grad_fn=<DivBackward0>)\n",
      "tensor(2.2293, grad_fn=<DivBackward0>)\n",
      "tensor(2.2305, grad_fn=<DivBackward0>)\n",
      "tensor(2.2308, grad_fn=<DivBackward0>)\n",
      "tensor(2.2252, grad_fn=<DivBackward0>)\n",
      "tensor(2.2279, grad_fn=<DivBackward0>)\n",
      "tensor(2.2244, grad_fn=<DivBackward0>)\n",
      "tensor(2.2204, grad_fn=<DivBackward0>)\n",
      "tensor(2.2294, grad_fn=<DivBackward0>)\n",
      "tensor(2.2181, grad_fn=<DivBackward0>)\n",
      "tensor(2.2192, grad_fn=<DivBackward0>)\n",
      "tensor(2.2195, grad_fn=<DivBackward0>)\n",
      "tensor(2.2159, grad_fn=<DivBackward0>)\n",
      "tensor(2.2178, grad_fn=<DivBackward0>)\n",
      "tensor(2.2182, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "training_runs = 400\n",
    "batch_size = 96\n",
    "context_length = 4\n",
    "learning_rate = .2\n",
    "head_size = 8\n",
    "embedding_dimensions = 16\n",
    "\n",
    "model = FFAttention(embedding_dimensions, head_size, context_length)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # , weight_decay=args.weight_decay, betas=(0.9, 0.99), eps=1e-8)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(epoch_loss/training_runs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8ab9a64a-4bde-4758-8aa1-aa08c9844e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pect abkl i theten ftly abeu gh  wae quurk rald   clurg pine vend bbit whor praa theed gchis all\n",
      "ome\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(1):\n",
    "    o = model.generate(idx, 100).data[0].tolist()\n",
    "    print(names.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "989f2ee4-1968-4bf6-8352-4e37ebaca633",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHead(nn.Module):\n",
    "\n",
    "    def __init__(self, num_heads, head_size, embed_size, content_length):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(embed_size, head_size, content_length) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat( [head(x) for head in self.heads], dim = -1 )\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dff586a7-6f05-4e2a-95f4-9a07c8e27203",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFMultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, content_length, num_heads, head_size, multiplier=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.positional_embed = nn.Embedding(content_length, embed_size)\n",
    "        self.mutli_attention = MultiHead(num_heads, head_size, embed_size, content_length)\n",
    "        self.lna = nn.LayerNorm(embed_size)\n",
    "        self.ff = FeedForward(embed_size, multiplier)\n",
    "        self.lnff = nn.LayerNorm(embed_size)\n",
    "        self.decode = nn.Linear(embed_size, vocab_size)\n",
    "        self.content_length = content_length\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        #idx B,T\n",
    "        B, T = idx.shape\n",
    "\n",
    "        idx_e = self.vocab_embed(idx)\n",
    "        # note tr is always the same - so the learning here is information passed back to the positional_embed from loss\n",
    "        tr = torch.arange(T)\n",
    "        pos_e = self.positional_embed(tr)\n",
    "\n",
    "        x = idx_e + pos_e\n",
    "        x = self.mutli_attention(x)\n",
    "        # print(\"multi ball out\", x.shape)\n",
    "        x = self.lna(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.lnff(x)\n",
    "        # print(\"feed forward out\", x.shape)\n",
    "        logits = self.decode(x)\n",
    "        # print(\"decode out\", x.shape)\n",
    "        # print(\"targets\", targets.shape)\n",
    "        # return None, None\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            targets = targets.reshape(B*T)\n",
    "            loss = F.cross_entropy(logits.view(B*T, -1), targets) #.resize(B*T)) # loss function\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -self.content_length:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "22355b0d-b5c2-4958-8d62-02e6c9dd476a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "0.004344 M parameters\n",
      "0 tensor(2.4528, grad_fn=<DivBackward0>) [0.095]\n",
      "1 tensor(2.2396, grad_fn=<DivBackward0>) [0.09025]\n",
      "2 tensor(2.1978, grad_fn=<DivBackward0>) [0.0857375]\n",
      "3 tensor(2.1731, grad_fn=<DivBackward0>) [0.08145062499999998]\n",
      "4 tensor(2.1542, grad_fn=<DivBackward0>) [0.07737809374999999]\n",
      "5 tensor(2.1246, grad_fn=<DivBackward0>) [0.07350918906249998]\n",
      "6 tensor(2.1113, grad_fn=<DivBackward0>) [0.06983372960937498]\n",
      "7 tensor(2.0980, grad_fn=<DivBackward0>) [0.06634204312890622]\n",
      "8 tensor(2.0898, grad_fn=<DivBackward0>) [0.0630249409724609]\n",
      "9 tensor(2.0836, grad_fn=<DivBackward0>) [0.05987369392383786]\n",
      "10 tensor(2.0741, grad_fn=<DivBackward0>) [0.05688000922764597]\n",
      "11 tensor(2.0757, grad_fn=<DivBackward0>) [0.05403600876626367]\n",
      "12 tensor(2.0600, grad_fn=<DivBackward0>) [0.05133420832795048]\n",
      "13 tensor(2.0632, grad_fn=<DivBackward0>) [0.04876749791155295]\n",
      "14 tensor(2.0522, grad_fn=<DivBackward0>) [0.046329123015975304]\n",
      "15 tensor(2.0541, grad_fn=<DivBackward0>) [0.04401266686517654]\n",
      "16 tensor(2.0456, grad_fn=<DivBackward0>) [0.04181203352191771]\n",
      "17 tensor(2.0441, grad_fn=<DivBackward0>) [0.039721431845821824]\n",
      "18 tensor(2.0417, grad_fn=<DivBackward0>) [0.037735360253530734]\n",
      "19 tensor(2.0382, grad_fn=<DivBackward0>) [0.035848592240854196]\n",
      "20 tensor(2.0309, grad_fn=<DivBackward0>) [0.03405616262881148]\n",
      "21 tensor(2.0292, grad_fn=<DivBackward0>) [0.03235335449737091]\n",
      "22 tensor(2.0318, grad_fn=<DivBackward0>) [0.030735686772502362]\n",
      "23 tensor(2.0311, grad_fn=<DivBackward0>) [0.029198902433877242]\n",
      "24 tensor(2.0255, grad_fn=<DivBackward0>) [0.027738957312183378]\n",
      "25 tensor(2.0217, grad_fn=<DivBackward0>) [0.026352009446574207]\n",
      "26 tensor(2.0200, grad_fn=<DivBackward0>) [0.025034408974245494]\n",
      "27 tensor(2.0190, grad_fn=<DivBackward0>) [0.023782688525533217]\n",
      "28 tensor(2.0162, grad_fn=<DivBackward0>) [0.022593554099256556]\n",
      "29 tensor(2.0119, grad_fn=<DivBackward0>) [0.021463876394293726]\n",
      "30 tensor(2.0189, grad_fn=<DivBackward0>) [0.020390682574579037]\n",
      "31 tensor(2.0125, grad_fn=<DivBackward0>) [0.019371148445850084]\n",
      "32 tensor(2.0123, grad_fn=<DivBackward0>) [0.01840259102355758]\n",
      "33 tensor(2.0060, grad_fn=<DivBackward0>) [0.0174824614723797]\n",
      "34 tensor(2.0054, grad_fn=<DivBackward0>) [0.016608338398760712]\n",
      "35 tensor(2.0032, grad_fn=<DivBackward0>) [0.015777921478822676]\n",
      "36 tensor(2.0012, grad_fn=<DivBackward0>) [0.014989025404881541]\n",
      "37 tensor(2.0084, grad_fn=<DivBackward0>) [0.014239574134637464]\n",
      "38 tensor(1.9999, grad_fn=<DivBackward0>) [0.01352759542790559]\n",
      "39 tensor(1.9988, grad_fn=<DivBackward0>) [0.012851215656510309]\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "training_runs = 400\n",
    "batch_size = 96\n",
    "context_length = 4\n",
    "learning_rate = .1\n",
    "embedding_dimensions = 16\n",
    "num_heads = 2\n",
    "head_size = embedding_dimensions // num_heads\n",
    "\n",
    "print(head_size)\n",
    "\n",
    "model = FFMultiHeadAttention(embedding_dimensions, context_length, num_heads, head_size)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "lmbda = lambda epoch: 0.95\n",
    "\n",
    "m_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    print(ep, epoch_loss/training_runs, m_scheduler.get_last_lr())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "249df925-b0c3-434b-98f9-16c3feadfc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " said  \n",
      "\n",
      "at othe never exane yokle as lou mout ? \n",
      " her appp aged \n",
      "\n",
      "\n",
      "trabs and at  che you of the a c\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(1):\n",
    "    o = model.generate(idx, 100).data[0].tolist()\n",
    "    print(names.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "16926363-2c95-4998-a0a9-8eee16e1abf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[31,  1, 22,  1,  0],\n",
      "        [ 1, 22,  1,  0, 17],\n",
      "        [22,  1,  0, 17, 28],\n",
      "        [ 1,  0, 17, 28, 36]])\n",
      "tensor([[ 0, 17, 28, 36, 27],\n",
      "        [17, 28, 36, 27,  1],\n",
      "        [28, 36, 27,  1, 33],\n",
      "        [36, 27,  1, 33, 21]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 14,  1, 32, 33],\n",
       "        [22, 32,  1, 26, 28],\n",
       "        [ 1, 15, 18,  0, 20],\n",
       "        [21, 18, 14, 17,  1]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_val_batch(data, batch_length=5, batch_size=5, i=0):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    if i == 0:\n",
    "        ix = torch.randint(len(data) - batch_length, (batch_size,))\n",
    "    else:\n",
    "        ix = torch.arange(1, 5) + 1 + i\n",
    "\n",
    "    b = torch.stack([data[i:i+batch_length] for i in ix])\n",
    "    return b\n",
    "\n",
    "print(get_val_batch(train, 5, 4, 5))\n",
    "print(get_val_batch(train, 5, 4, 9))\n",
    "\n",
    "get_batch(train, 5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f874381a-99eb-4bba-bde0-b10c9632e5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches 11075 221\n",
      "total loss tensor(440.8175) tensor(1.9946)\n",
      "None 11075\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "@torch.no_grad()\n",
    "def split_loss(split):\n",
    "    split_len = len(split)\n",
    "    total_loss = 0\n",
    "    batch_size = 50\n",
    "    num_batches = math.floor(split_len / batch_size)\n",
    "    print(\"num_batches\", split_len, num_batches)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        t_b = get_val_batch(split, context_length+1, batch_size, i*batch_size)\n",
    "        \n",
    "        x = t_b[:, 0: context_length]\n",
    "        y = t_b[:, context_length: context_length+1]\n",
    "        \n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, batch_loss = model(x, y)\n",
    "        \n",
    "        total_loss = total_loss + batch_loss\n",
    "    \n",
    "    print(\"total loss\", total_loss, total_loss / num_batches)\n",
    "\n",
    "dev = torch.tensor(names.data[1])\n",
    "print(split_loss(dev), len(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "85d45768-50ff-451e-9c4f-a030f5beaec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4376 M parameters\n",
      "ep 0 tensor(2.4780, grad_fn=<DivBackward0>) [0.095]\n",
      "ep 1 tensor(2.1900, grad_fn=<DivBackward0>) [0.09025]\n",
      "ep 2 tensor(2.1232, grad_fn=<DivBackward0>) [0.0857375]\n",
      "ep 3 tensor(2.0793, grad_fn=<DivBackward0>) [0.08145062499999998]\n",
      "ep 4 tensor(2.0554, grad_fn=<DivBackward0>) [0.07737809374999999]\n",
      "ep 5 tensor(2.0423, grad_fn=<DivBackward0>) [0.07350918906249998]\n",
      "ep 6 tensor(2.0290, grad_fn=<DivBackward0>) [0.06983372960937498]\n",
      "ep 7 tensor(2.0244, grad_fn=<DivBackward0>) [0.06634204312890622]\n",
      "ep 8 tensor(2.0121, grad_fn=<DivBackward0>) [0.0630249409724609]\n",
      "ep 9 tensor(2.0048, grad_fn=<DivBackward0>) [0.05987369392383786]\n",
      "ep 10 tensor(1.9992, grad_fn=<DivBackward0>) [0.05688000922764597]\n",
      "ep 11 tensor(1.9920, grad_fn=<DivBackward0>) [0.05403600876626367]\n",
      "ep 12 tensor(1.9844, grad_fn=<DivBackward0>) [0.05133420832795048]\n",
      "ep 13 tensor(1.9816, grad_fn=<DivBackward0>) [0.04876749791155295]\n",
      "ep 14 tensor(1.9787, grad_fn=<DivBackward0>) [0.046329123015975304]\n",
      "ep 15 tensor(1.9780, grad_fn=<DivBackward0>) [0.04401266686517654]\n",
      "ep 16 tensor(1.9661, grad_fn=<DivBackward0>) [0.04181203352191771]\n",
      "ep 17 tensor(1.9666, grad_fn=<DivBackward0>) [0.039721431845821824]\n",
      "ep 18 tensor(1.9601, grad_fn=<DivBackward0>) [0.037735360253530734]\n",
      "ep 19 tensor(1.9590, grad_fn=<DivBackward0>) [0.035848592240854196]\n",
      "ep 20 tensor(1.9528, grad_fn=<DivBackward0>) [0.03405616262881148]\n",
      "ep 21 tensor(1.9542, grad_fn=<DivBackward0>) [0.03235335449737091]\n",
      "ep 22 tensor(1.9494, grad_fn=<DivBackward0>) [0.030735686772502362]\n",
      "ep 23 tensor(1.9501, grad_fn=<DivBackward0>) [0.029198902433877242]\n",
      "ep 24 tensor(1.9470, grad_fn=<DivBackward0>) [0.027738957312183378]\n",
      "ep 25 tensor(1.9415, grad_fn=<DivBackward0>) [0.026352009446574207]\n",
      "ep 26 tensor(1.9343, grad_fn=<DivBackward0>) [0.025034408974245494]\n",
      "ep 27 tensor(1.9361, grad_fn=<DivBackward0>) [0.023782688525533217]\n",
      "ep 28 tensor(1.9355, grad_fn=<DivBackward0>) [0.022593554099256556]\n",
      "ep 29 tensor(1.9336, grad_fn=<DivBackward0>) [0.021463876394293726]\n",
      "ep 30 tensor(1.9318, grad_fn=<DivBackward0>) [0.020390682574579037]\n",
      "ep 31 tensor(1.9290, grad_fn=<DivBackward0>) [0.019371148445850084]\n",
      "ep 32 tensor(1.9319, grad_fn=<DivBackward0>) [0.01840259102355758]\n",
      "ep 33 tensor(1.9281, grad_fn=<DivBackward0>) [0.0174824614723797]\n",
      "ep 34 tensor(1.9302, grad_fn=<DivBackward0>) [0.016608338398760712]\n",
      "ep 35 tensor(1.9217, grad_fn=<DivBackward0>) [0.015777921478822676]\n",
      "ep 36 tensor(1.9248, grad_fn=<DivBackward0>) [0.014989025404881541]\n",
      "ep 37 tensor(1.9215, grad_fn=<DivBackward0>) [0.014239574134637464]\n",
      "ep 38 tensor(1.9191, grad_fn=<DivBackward0>) [0.01352759542790559]\n",
      "ep 39 tensor(1.9256, grad_fn=<DivBackward0>) [0.012851215656510309]\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "training_runs = 400\n",
    "batch_size = 96\n",
    "context_length = 6\n",
    "learning_rate = .1\n",
    "embedding_dimensions = 16\n",
    "num_heads = 4\n",
    "head_size = embedding_dimensions // num_heads\n",
    "\n",
    "print(head_size)\n",
    "\n",
    "model = FFMultiHeadAttention(embedding_dimensions, context_length, num_heads, head_size)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()), 'M parameters')\n",
    "\n",
    "lmbda = lambda epoch: 0.98\n",
    "\n",
    "m_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0cd99c37-b38c-4f56-a513-f25e7d286c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches 11075 221\n",
      "total loss tensor(426.6404) tensor(1.9305)\n",
      "None 11075\n",
      "\n",
      "so\n",
      "was alice bot by ran to lact the saout be he the don the knen  wen sail \n",
      "\n",
      "\n",
      " you  alice and she cr\n"
     ]
    }
   ],
   "source": [
    "print(split_loss(dev), len(dev))\n",
    "\n",
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(1):\n",
    "    o = model.generate(idx, 100).data[0].tolist()\n",
    "    print(names.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3886be4d-d105-42d4-8aaa-d212d9ccb95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "14408  parameters\n",
      "ep 0 tensor(2.3368, grad_fn=<DivBackward0>) [0.098]\n",
      "ep 1 tensor(2.0300, grad_fn=<DivBackward0>) [0.09604]\n",
      "ep 2 tensor(1.9516, grad_fn=<DivBackward0>) [0.0941192]\n",
      "ep 3 tensor(1.9068, grad_fn=<DivBackward0>) [0.092236816]\n",
      "ep 4 tensor(1.8827, grad_fn=<DivBackward0>) [0.09039207968]\n",
      "ep 5 tensor(1.8580, grad_fn=<DivBackward0>) [0.0885842380864]\n",
      "ep 6 tensor(1.8434, grad_fn=<DivBackward0>) [0.086812553324672]\n",
      "ep 7 tensor(1.8243, grad_fn=<DivBackward0>) [0.08507630225817855]\n",
      "ep 8 tensor(1.8145, grad_fn=<DivBackward0>) [0.08337477621301498]\n",
      "ep 9 tensor(1.8152, grad_fn=<DivBackward0>) [0.08170728068875467]\n",
      "ep 10 tensor(1.8017, grad_fn=<DivBackward0>) [0.08007313507497958]\n",
      "ep 11 tensor(1.7947, grad_fn=<DivBackward0>) [0.07847167237347999]\n",
      "ep 12 tensor(1.7863, grad_fn=<DivBackward0>) [0.07690223892601039]\n",
      "ep 13 tensor(1.7802, grad_fn=<DivBackward0>) [0.07536419414749018]\n",
      "ep 14 tensor(1.7716, grad_fn=<DivBackward0>) [0.07385691026454037]\n",
      "ep 15 tensor(1.7748, grad_fn=<DivBackward0>) [0.07237977205924956]\n",
      "ep 16 tensor(1.7693, grad_fn=<DivBackward0>) [0.07093217661806457]\n",
      "ep 17 tensor(1.7557, grad_fn=<DivBackward0>) [0.06951353308570328]\n",
      "ep 18 tensor(1.7562, grad_fn=<DivBackward0>) [0.06812326242398921]\n",
      "ep 19 tensor(1.7563, grad_fn=<DivBackward0>) [0.06676079717550942]\n",
      "ep 20 tensor(1.7507, grad_fn=<DivBackward0>) [0.06542558123199924]\n",
      "ep 21 tensor(1.7496, grad_fn=<DivBackward0>) [0.06411706960735924]\n",
      "ep 22 tensor(1.7445, grad_fn=<DivBackward0>) [0.06283472821521206]\n",
      "ep 23 tensor(1.7364, grad_fn=<DivBackward0>) [0.06157803365090782]\n",
      "ep 24 tensor(1.7352, grad_fn=<DivBackward0>) [0.06034647297788966]\n",
      "ep 25 tensor(1.7369, grad_fn=<DivBackward0>) [0.059139543518331866]\n",
      "ep 26 tensor(1.7312, grad_fn=<DivBackward0>) [0.05795675264796523]\n",
      "ep 27 tensor(1.7315, grad_fn=<DivBackward0>) [0.05679761759500593]\n",
      "ep 28 tensor(1.7258, grad_fn=<DivBackward0>) [0.055661665243105805]\n",
      "ep 29 tensor(1.7227, grad_fn=<DivBackward0>) [0.054548431938243686]\n",
      "ep 30 tensor(1.7236, grad_fn=<DivBackward0>) [0.053457463299478813]\n",
      "ep 31 tensor(1.7152, grad_fn=<DivBackward0>) [0.05238831403348924]\n",
      "ep 32 tensor(1.7195, grad_fn=<DivBackward0>) [0.05134054775281945]\n",
      "ep 33 tensor(1.7123, grad_fn=<DivBackward0>) [0.05031373679776306]\n",
      "ep 34 tensor(1.7107, grad_fn=<DivBackward0>) [0.0493074620618078]\n",
      "ep 35 tensor(1.7113, grad_fn=<DivBackward0>) [0.048321312820571644]\n",
      "ep 36 tensor(1.7070, grad_fn=<DivBackward0>) [0.04735488656416021]\n",
      "ep 37 tensor(1.7071, grad_fn=<DivBackward0>) [0.046407788832877]\n",
      "ep 38 tensor(1.7091, grad_fn=<DivBackward0>) [0.04547963305621946]\n",
      "ep 39 tensor(1.7103, grad_fn=<DivBackward0>) [0.044570040395095066]\n",
      "ep 40 tensor(1.6991, grad_fn=<DivBackward0>) [0.04367863958719317]\n",
      "ep 41 tensor(1.7019, grad_fn=<DivBackward0>) [0.042805066795449306]\n",
      "ep 42 tensor(1.6987, grad_fn=<DivBackward0>) [0.04194896545954032]\n",
      "ep 43 tensor(1.6964, grad_fn=<DivBackward0>) [0.04110998615034951]\n",
      "ep 44 tensor(1.6971, grad_fn=<DivBackward0>) [0.04028778642734252]\n",
      "ep 45 tensor(1.6939, grad_fn=<DivBackward0>) [0.03948203069879567]\n",
      "ep 46 tensor(1.6925, grad_fn=<DivBackward0>) [0.038692390084819756]\n",
      "ep 47 tensor(1.6959, grad_fn=<DivBackward0>) [0.03791854228312336]\n",
      "ep 48 tensor(1.6931, grad_fn=<DivBackward0>) [0.03716017143746089]\n",
      "ep 49 tensor(1.6890, grad_fn=<DivBackward0>) [0.03641696800871167]\n",
      "ep 50 tensor(1.6877, grad_fn=<DivBackward0>) [0.03568862864853744]\n",
      "ep 51 tensor(1.6833, grad_fn=<DivBackward0>) [0.03497485607556669]\n",
      "ep 52 tensor(1.6882, grad_fn=<DivBackward0>) [0.034275358954055354]\n",
      "ep 53 tensor(1.6833, grad_fn=<DivBackward0>) [0.03358985177497425]\n",
      "ep 54 tensor(1.6842, grad_fn=<DivBackward0>) [0.03291805473947476]\n",
      "ep 55 tensor(1.6848, grad_fn=<DivBackward0>) [0.03225969364468526]\n",
      "ep 56 tensor(1.6747, grad_fn=<DivBackward0>) [0.03161449977179156]\n",
      "ep 57 tensor(1.6819, grad_fn=<DivBackward0>) [0.030982209776355726]\n",
      "ep 58 tensor(1.6769, grad_fn=<DivBackward0>) [0.030362565580828612]\n",
      "ep 59 tensor(1.6746, grad_fn=<DivBackward0>) [0.02975531426921204]\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "training_runs = 400\n",
    "batch_size = 96\n",
    "context_length = 8\n",
    "learning_rate = .1\n",
    "embedding_dimensions = 32\n",
    "num_heads = 4\n",
    "head_size = embedding_dimensions // num_heads\n",
    "\n",
    "print(head_size)\n",
    "\n",
    "model = FFMultiHeadAttention(embedding_dimensions, context_length, num_heads, head_size)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()), ' parameters')\n",
    "\n",
    "lmbda = lambda epoch: 0.98\n",
    "\n",
    "m_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "\n",
    "    if ep % 10 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ba288d0d-642c-4405-b908-9b84be59a074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches 11075 221\n",
      "total loss tensor(371.4741) tensor(1.6809)\n",
      "None 11075\n",
      "\n",
      "you\n",
      "nice    and there much you d i bles of eyes  the\n",
      "pig   belcome    nother look       \n",
      "set  if you\n"
     ]
    }
   ],
   "source": [
    "print(split_loss(dev), len(dev))\n",
    "\n",
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(1):\n",
    "    o = model.generate(idx, 100).data[0].tolist()\n",
    "    print(names.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff5984e4-9fca-4553-ade9-27100e9b770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow mor loops without restarting\n",
    "e_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d3c52-0c8a-4ab6-8121-7e8377d361d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "22856  parameters\n",
      "ep 0 tensor(2.2369, grad_fn=<DivBackward0>) [0.098]\n",
      "ep 10 tensor(1.6109, grad_fn=<DivBackward0>) [0.08007313507497958]\n",
      "ep 20 tensor(1.5600, grad_fn=<DivBackward0>) [0.06542558123199924]\n",
      "ep 30 tensor(1.5326, grad_fn=<DivBackward0>) [0.053457463299478813]\n",
      "ep 40 tensor(1.5139, grad_fn=<DivBackward0>) [0.04367863958719317]\n",
      "ep 50 tensor(1.4989, grad_fn=<DivBackward0>) [0.03568862864853744]\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "training_runs = 800\n",
    "batch_size = 96\n",
    "context_length = 12\n",
    "learning_rate = .1\n",
    "embedding_dimensions = 32\n",
    "num_heads = 4\n",
    "head_size = embedding_dimensions // num_heads\n",
    "\n",
    "print(head_size)\n",
    "# our embedding_dimensions are still 'small' so we mutliply the size our our feed forward network to make up\n",
    "multiplier = 8\n",
    "model = FFMultiHeadAttention(embedding_dimensions, context_length, num_heads, head_size, multiplier)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()), ' parameters')\n",
    "\n",
    "lmbda = lambda epoch: 0.98\n",
    "\n",
    "m_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    \n",
    "    if ep % 10 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f219b8c9-2430-4b93-a0a0-4b015bd0ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split_loss(dev), len(dev))\n",
    "\n",
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(1):\n",
    "    o = model.generate(idx, 100).data[0].tolist()\n",
    "    print(names.decode(o))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
