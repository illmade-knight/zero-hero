{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "623a40b8-15f3-474b-b2d8-a2e8a4559672",
   "metadata": {},
   "source": [
    "### Batch the characters\n",
    "\n",
    "wavenet (like) - we want to progressively form longer joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1998a4ba-4781-49c6-93e0-cde038779ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56bf665-325d-42d8-b67f-d12bbb260e88",
   "metadata": {},
   "source": [
    "## more about broadcasting etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9abde14-eb9a-4cdc-88d1-6a8ab39f4154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8776, -0.9791, -0.8851],\n",
      "        [ 1.7752,  2.2412,  2.0700],\n",
      "        [ 0.4356,  0.6080,  0.5702]])\n",
      "torch.Size([3, 3]) torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = torch.randn(3, 2)\n",
    "m = torch.rand(2, 3)\n",
    "print(n @ m)\n",
    "\n",
    "n = torch.tril(torch.ones((3, 3), dtype=torch.int))\n",
    "m = torch.tensor([1, 2, 3])\n",
    "print(n.shape, m.shape)\n",
    "n * m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a07b60fb-cc31-4365-a704-5ec95fe80067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 0, 0],\n",
      "         [4, 5, 0],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[1, 0, 0],\n",
      "         [4, 5, 0],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[1, 0, 0],\n",
      "         [4, 5, 0],\n",
      "         [7, 8, 9]]])\n"
     ]
    }
   ],
   "source": [
    "n = torch.tril(torch.ones((3, 3, 3), dtype=torch.int))\n",
    "m = torch.arange(1, 10).view(3, 3)\n",
    "print(n * m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63054bee-c8f8-4382-96ec-9a6a9bb12762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0],\n",
       "         [1, 2, 0],\n",
       "         [1, 2, 3]],\n",
       "\n",
       "        [[4, 0, 0],\n",
       "         [4, 5, 0],\n",
       "         [4, 5, 6]],\n",
       "\n",
       "        [[7, 0, 0],\n",
       "         [7, 8, 0],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(1,10).view(3,3)\n",
    "cp = torch.cat((a, a, a), 1).view(3,3,3)\n",
    "\n",
    "cp * torch.tril(torch.ones((3, 3, 3), dtype=torch.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f6bd129-d41d-4a6f-a021-1ef78d753fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [1, 2, 3],\n",
       "         [1, 2, 3]],\n",
       "\n",
       "        [[4, 5, 6],\n",
       "         [4, 5, 6],\n",
       "         [4, 5, 6]],\n",
       "\n",
       "        [[7, 8, 9],\n",
       "         [7, 8, 9],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(1,10).view(3,3)\n",
    "a.repeat(1, 1, 3).view(3, 3, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2d4172f-bc8b-4276-91af-c2ab8935cc98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0],\n",
       "         [1, 2, 0],\n",
       "         [1, 2, 3]],\n",
       "\n",
       "        [[4, 0, 0],\n",
       "         [4, 5, 0],\n",
       "         [4, 5, 6]],\n",
       "\n",
       "        [[7, 0, 0],\n",
       "         [7, 8, 0],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(1,10).view(3,3)\n",
    "a.repeat(1, 1, 3).view(3, 3, 3) * torch.tril(torch.ones((3, 3, 3), dtype=torch.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d3a70f1-b514-4a83-be87-cd3976d30715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0],\n",
       "         [1, 2, 0, 0],\n",
       "         [1, 2, 3, 0],\n",
       "         [1, 2, 3, 4]],\n",
       "\n",
       "        [[5, 0, 0, 0],\n",
       "         [5, 6, 0, 0],\n",
       "         [5, 6, 7, 0],\n",
       "         [5, 6, 7, 8]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = 4\n",
    "samples = 2\n",
    "a = torch.arange(1,samples*ctx+1).view(samples,ctx)\n",
    "out = a.repeat(1, 1, ctx).view(-1, ctx, ctx) * torch.tril(torch.ones((samples, ctx, ctx), dtype=torch.int))\n",
    "print(out.shape)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f6f0e64c-cccc-47f4-97fe-d5576f337b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.5188, -2.1504, -2.7174])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9355,  2.2526,  0.6165],\n",
       "         [-1.5188, -2.1504, -2.7174],\n",
       "         [-1.5188, -2.1504, -2.7174],\n",
       "         [-1.5188, -2.1504, -2.7174]],\n",
       "\n",
       "        [[ 0.9355,  2.2526,  0.6165],\n",
       "         [-0.8971, -1.4147,  2.1098],\n",
       "         [-1.5188, -2.1504, -2.7174],\n",
       "         [-1.5188, -2.1504, -2.7174]],\n",
       "\n",
       "        [[ 0.9355,  2.2526,  0.6165],\n",
       "         [-0.8971, -1.4147,  2.1098],\n",
       "         [ 0.2606,  2.3956,  0.6378],\n",
       "         [-1.5188, -2.1504, -2.7174]],\n",
       "\n",
       "        [[ 0.9355,  2.2526,  0.6165],\n",
       "         [-0.8971, -1.4147,  2.1098],\n",
       "         [ 0.2606,  2.3956,  0.6378],\n",
       "         [-0.2348, -0.4804, -0.2756]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_t = torch.randn(27, 3)\n",
    "print(emb_t[0])\n",
    "emb_t[out[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "599d016e-8652-4cd4-a042-1606132159e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 27\n",
    "\n",
    "embedding_dims = 3\n",
    "context_length = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "074f679d-ac78-4bf7-b793-b5a39a33286d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the name encoded to its characters, ts\n",
      "tensor([ 0,  5, 13, 13])\n",
      "those characters in our 3D embedding\n",
      "tensor([[-0.5356,  0.2102,  0.9141],\n",
      "        [-0.5295, -0.6447, -0.6345],\n",
      "        [ 0.3357, -0.1848, -1.0286],\n",
      "        [ 0.3357, -0.1848, -1.0286]])\n",
      "a triangluar matric of 1s\n",
      "tensor([[1, 0, 0, 0],\n",
      "        [1, 1, 0, 0],\n",
      "        [1, 1, 1, 0],\n",
      "        [1, 1, 1, 1]], dtype=torch.int32)\n",
      "a triangluarized version of the name\n",
      "tensor([[ 0,  0,  0,  0],\n",
      "        [ 0,  5,  0,  0],\n",
      "        [ 0,  5, 13,  0],\n",
      "        [ 0,  5, 13, 13]])\n"
     ]
    }
   ],
   "source": [
    "%run names.py\n",
    "\n",
    "ns = Names(context_length)\n",
    "\n",
    "names = ns.get_names(\"names.txt\")\n",
    "\n",
    "i_names = [ns.stoi[s] for name in names for s in name]\n",
    "\n",
    "ts = torch.tensor(i_names[:context_length])\n",
    "\n",
    "print(\"the name encoded to its characters, ts\")\n",
    "print(ts)\n",
    "\n",
    "emb = torch.randn(vocab_size, embedding_dims)\n",
    "\n",
    "embedding = emb[ts]\n",
    "print(\"those characters in our 3D embedding\")\n",
    "print(embedding)\n",
    "\n",
    "tril = torch.tril(torch.ones(context_length, context_length, dtype=torch.int))\n",
    "print(\"a triangluar matric of 1s\")\n",
    "print(tril)\n",
    "\n",
    "trilled = ts * tril\n",
    "print(\"a triangluarized version of the name\")\n",
    "print(trilled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee934b2f-a4ca-4188-91d8-cb2b682b0100",
   "metadata": {},
   "source": [
    "## A 3D version\n",
    "\n",
    "we want triangluarized version to hold the 3D embeddings,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfe6b073-badc-4fa0-ae08-17ee43d0be5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5356,  0.2102,  0.9141],\n",
       "        [-0.5295, -0.6447, -0.6345],\n",
       "        [-0.5356,  0.2102,  0.9141],\n",
       "        [-0.5356,  0.2102,  0.9141]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sequence = emb[trilled]\n",
    "\n",
    "print(embedded_sequence.shape)\n",
    "embedded_sequence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fb1861fb-7b88-4e85-831c-cdb266bbcdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dims):\n",
    "        self.weight = torch.randn(vocab_size, embedding_dims)\n",
    "        self.type = 'embedding'\n",
    "\n",
    "    def __call__(self, IX):\n",
    "        self.out = self.weight[IX]\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb99bc0-6eda-4772-953d-bb635c0d8146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_layer = Embedding(27, 3)\n",
    "em_layer.weight = emb\n",
    "sq = em_layer(trilled)\n",
    "sq[1] == embedded_sequence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "44fd99a7-a674-4d22-b1d1-d40ee6d42981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.1056, -0.2679,  0.5158]),\n",
       " tensor([[[ 2.0601, -0.8392, -1.4414],\n",
       "          [-1.1056, -0.2679,  0.5158],\n",
       "          [-1.1056, -0.2679,  0.5158],\n",
       "          [-1.1056, -0.2679,  0.5158]],\n",
       " \n",
       "         [[ 2.0601, -0.8392, -1.4414],\n",
       "          [ 1.0647, -2.1135,  2.1291],\n",
       "          [-1.1056, -0.2679,  0.5158],\n",
       "          [-1.1056, -0.2679,  0.5158]],\n",
       " \n",
       "         [[ 2.0601, -0.8392, -1.4414],\n",
       "          [ 1.0647, -2.1135,  2.1291],\n",
       "          [ 0.8030, -0.5467,  0.2414],\n",
       "          [-1.1056, -0.2679,  0.5158]],\n",
       " \n",
       "         [[ 2.0601, -0.8392, -1.4414],\n",
       "          [ 1.0647, -2.1135,  2.1291],\n",
       "          [ 0.8030, -0.5467,  0.2414],\n",
       "          [ 0.0137, -0.9042, -1.5613]]]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = 4\n",
    "samples = 2\n",
    "a = torch.arange(1,samples*ctx+1).view(samples,ctx)\n",
    "out = a.repeat(1, 1, ctx).view(-1, ctx, ctx) * torch.tril(torch.ones((samples, ctx, ctx), dtype=torch.int))\n",
    "\n",
    "em_layer = Embedding(27, 3)\n",
    "em_out = em_layer(out)\n",
    "em_layer.weight[0], em_out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b004e8b7-901a-49cf-bec3-324fa3f2e8ad",
   "metadata": {},
   "source": [
    "## our embed still works\n",
    "\n",
    "so our embed layer works with the new format\n",
    "\n",
    "how about Flatten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6114b8c3-ffac-4109-9db0-5d9bda8f6191",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenConsecutive:\n",
    "\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.type = 'flatten'\n",
    "\n",
    "    def __call__(self, x):\n",
    "        B, T, C = x.shape\n",
    "        x = x.view(B, T//self.n, self.n * C)\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.squeeze(1)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d561b640-befa-4e5a-bf60-bf144774cfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5356,  0.2102,  0.9141, -0.5295, -0.6447, -0.6345],\n",
       "        [-0.5356,  0.2102,  0.9141, -0.5356,  0.2102,  0.9141]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = FlattenConsecutive(2)\n",
    "outb = fc(sq)\n",
    "\n",
    "print(outb.shape)\n",
    "outb[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c15afb-fdce-4d80-8f8b-efe6de0a768c",
   "metadata": {},
   "source": [
    "## OK for a single sample\n",
    "\n",
    "but for our batch now - it's shape looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3e94f1f2-2d76-4d58-bc03-03e1e77ad695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(em_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1691b65d-5b15-4d4e-b571-901176e86ec6",
   "metadata": {},
   "source": [
    "and FlattenConsecutive expects B, T, C = x.shape\n",
    "\n",
    "but do we need flatten now?\n",
    "\n",
    "we expect an answer to our batch all at once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b7d814-9410-4106-8c9f-283fba0c63d8",
   "metadata": {},
   "source": [
    "## rework sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2551b0ce-6a42-4f67-9eb6-f8906a60478b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[20,  0,  0,  0],\n",
      "         [20, 15,  0,  0],\n",
      "         [20, 15, 14,  0],\n",
      "         [20, 15, 14,  0]],\n",
      "\n",
      "        [[ 0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0],\n",
      "         [ 0,  0, 10,  0],\n",
      "         [ 0,  0, 10,  1]]]) [[15, 14, 0, 0], [0, 10, 1, 9]]\n"
     ]
    }
   ],
   "source": [
    "full_length = len(i_names)\n",
    "\n",
    "offset = math.floor(full_length*0.1)\n",
    "\n",
    "sm = {\n",
    "    'train': (0, offset * 8),\n",
    "    'dev': (offset * 8, offset * 9),\n",
    "    'test': (offset * 9, offset * 10),\n",
    "}\n",
    "\n",
    "def samples(set, num_samples, ctx=context_length):\n",
    "    fr = sm[set]\n",
    "    sm_fr = i_names[fr[0]: fr[1]]\n",
    "    fr_l = len(sm_fr)-ctx\n",
    "    sx = []\n",
    "    ys = []\n",
    "    for n in random.sample(range(fr_l), num_samples):\n",
    "        sx += [i_names[n:n+ctx]]\n",
    "        ys += [i_names[n+1:n+ctx+1]]\n",
    "\n",
    "    xs = torch.tensor(sx).repeat(1, 1, ctx).view(num_samples, ctx, ctx) * torch.tril(torch.ones((num_samples, ctx, ctx), dtype=torch.int))\n",
    "\n",
    "    return xs, ys\n",
    "        \n",
    "xp, yp = samples('train', 2)\n",
    "print(xp, yp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51534358-c812-4ee4-8415-5fdf388047e1",
   "metadata": {},
   "source": [
    "## repeat the layers from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fe3e44f-c019-43ff-bf60-2c38b736075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "  \n",
    "  def __init__(self, fan_in, fan_out, bias=True):\n",
    "    self.weight = torch.randn((fan_in, fan_out))\n",
    "    self.bias = torch.zeros(fan_out) if bias else None\n",
    "    self.type = 'linear'\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    self.out = x @ self.weight\n",
    "    if self.bias is not None:\n",
    "      self.out += self.bias\n",
    "    return self.out\n",
    "\n",
    "  def kaiming(self, nonlin):\n",
    "    nn.init.kaiming_normal_(self.weight, nonlinearity=nonlin)\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight] + ([] if self.bias is None else [self.bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d62f925-8da5-4c0f-8dee-73b28f9830e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "  def __init__(self):\n",
    "    self.type = 'non-linearity'\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "class Relu:\n",
    "  def __init__(self):\n",
    "    self.type = 'non-linearity'\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.relu(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "class Gelu:\n",
    "  def __init__(self):\n",
    "    self.type = 'non-linearity'\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.gelu(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "468ccdf2-5af0-47d6-ac41-8e8802e99fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential:\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e277c627-e5a5-4665-a632-fbd60062fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.momentum = momentum\n",
    "    self.training = True\n",
    "    # parameters (trained with backprop)\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "    # buffers (trained with a running 'momentum update')\n",
    "    self.running_mean = torch.zeros(dim)\n",
    "    self.running_var = torch.ones(dim)\n",
    "    self.type = 'batch_norm_1d'\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    if x.ndim == 2: \n",
    "      dim = 0\n",
    "    if x.ndim == 3:\n",
    "      dim = (0, 1)\n",
    "    if self.training:\n",
    "      xmean = x.mean(dim, keepdim=True) # batch mean\n",
    "      xvar = x.var(dim, keepdim=True) # batch variance\n",
    "    else:\n",
    "      xmean = self.running_mean\n",
    "      xvar = self.running_var\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    # update the buffers\n",
    "    if self.training:\n",
    "      with torch.no_grad():\n",
    "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1de7eabd-1480-4354-9060-57780b8d2b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 3 # the dimensionality of the character embedding vectors\n",
    "\n",
    "vocab_size = 27\n",
    "nonlin='relu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57451f-e6a5-4820-94cf-53db7405785a",
   "metadata": {},
   "source": [
    "Ok lets try a simpler version without batchnorm (which kills my laptop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e8e86906-f39f-4779-a84d-66ebf97cbdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(e_s):\n",
    "    ln1 = Relu()\n",
    "    ln2 = Relu()\n",
    "    n_hidden = 100\n",
    "    \n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, e_s),\n",
    "        nn.Flatten(2),\n",
    "        Linear(e_s * context_length, n_hidden, bias=False), \n",
    "        ln1,\n",
    "        nn.LayerNorm(n_hidden),\n",
    "        Linear(n_hidden, n_hidden, bias=True), \n",
    "        ln2,\n",
    "        nn.LayerNorm(n_hidden),\n",
    "        Linear(n_hidden, vocab_size, bias=True),\n",
    "    ])\n",
    "    \n",
    "    parameters = model.parameters()\n",
    "    print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "    # should probably be a function on the model?\n",
    "    for p in parameters:\n",
    "      p.requires_grad = True\n",
    "    \n",
    "    print(vocab_size, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cebf1061-78c6-47d4-818c-a1a671c467f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 16\n",
    "sample_loops = 4000\n",
    "\n",
    "learning_rate = .01\n",
    "\n",
    "running_loss = []\n",
    "running_lr = []\n",
    "\n",
    "ud_ratio = []\n",
    "\n",
    "lr_step = {\n",
    "    0: { 0: .1},\n",
    "    3: { 0: .1},\n",
    "    9: { 0: .1}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "46020800-ffb6-41e0-aaf1-56582a55995c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2463)\n",
      "0 0.09200000000000001\n",
      "tensor(2.5708)\n",
      "2 0.08464000000000002\n",
      "tensor(2.4679)\n",
      "4 0.07786880000000002\n",
      "tensor(2.4349)\n",
      "6 0.07163929600000002\n",
      "tensor(2.4181)\n",
      "8 0.06590815232000002\n",
      "tensor(2.4000)\n",
      "10 0.06063550013440003\n",
      "tensor(2.3886)\n",
      "12 0.05578466012364803\n",
      "tensor(2.3829)\n",
      "14 0.05132188731375619\n",
      "tensor(2.3740)\n",
      "16 0.0472161363286557\n",
      "tensor(2.3704)\n",
      "18 0.043438845422363245\n",
      "tensor(2.3677)\n",
      "20 0.039963737788574184\n",
      "tensor(2.3575)\n",
      "22 0.03676663876548825\n",
      "tensor(2.3531)\n",
      "24 0.033825307664249196\n",
      "tensor(2.3514)\n",
      "26 0.03111928305110926\n",
      "tensor(2.3485)\n",
      "28 0.028629740407020522\n",
      "tensor(2.3527)\n",
      "30 0.02633936117445888\n",
      "tensor(2.3464)\n",
      "32 0.02423221228050217\n",
      "tensor(2.3450)\n",
      "34 0.022293635298061998\n",
      "tensor(2.3379)\n",
      "36 0.020510144474217038\n",
      "tensor(2.3367)\n",
      "38 0.018869332916279676\n"
     ]
    }
   ],
   "source": [
    "lrs = lr_step[embedding_size]\n",
    "if lrs == None:\n",
    "    lrs = lr_step[0]\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for s in range(sample_loops):\n",
    "        x, y = samples('train', batch_size)\n",
    "        Y = torch.tensor(y).view(-1)\n",
    "\n",
    "        logits = model(x)\n",
    "\n",
    "        logits = logits.view(-1, 27)\n",
    "\n",
    "        loss = F.cross_entropy(logits, Y) # loss function\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            epoch_loss += loss\n",
    "\n",
    "        # again stuff on parameters should probably be in model?\n",
    "        for p in parameters:\n",
    "          p.grad = None\n",
    "        loss.backward()\n",
    "\n",
    "        for p in parameters:\n",
    "            p.data -= learning_rate * p.grad\n",
    "\n",
    "    #just keep any epoch stuff in a no grad block\n",
    "    with torch.no_grad():\n",
    "        if ep in lrs:\n",
    "            learning_rate = lrs[ep]\n",
    "\n",
    "        running_loss.append(epoch_loss.item())\n",
    "        running_lr.append(learning_rate)\n",
    "\n",
    "        ud_ratio.append([ (learning_rate*p.grad.std()/ p.data.std()).log10().item() for p in parameters ])\n",
    "    \n",
    "        if ep % 2 == 0:\n",
    "            print(epoch_loss/sample_loops)\n",
    "            learning_rate *= .92\n",
    "            print(ep, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f8cac994-5331-496d-90b8-f8f8afcf4442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3379)\n"
     ]
    }
   ],
   "source": [
    "print(epoch_loss/sample_loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f98b16f6-6a00-425b-81b3-81cd9436ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_init(e_s, h_s):\n",
    "#     ln1 = Relu()\n",
    "#     ln2 = Relu()\n",
    "#     n_hidden = h_s\n",
    "    \n",
    "#     model = Sequential([\n",
    "#         Embedding(vocab_size, e_s),\n",
    "#         nn.Flatten(2),\n",
    "#         Linear(e_s * context_length, n_hidden, bias=False), \n",
    "#         nn.LayerNorm(n_hidden),\n",
    "#         ln1,\n",
    "#         Linear(n_hidden, n_hidden, bias=False),\n",
    "#         nn.LayerNorm(n_hidden),\n",
    "#         ln2,\n",
    "#         Linear(n_hidden, vocab_size, bias=True),\n",
    "#     ])\n",
    "    \n",
    "#     parameters = model.parameters()\n",
    "#     print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "#     # should probably be a function on the model?\n",
    "#     for p in parameters:\n",
    "#       p.requires_grad = True\n",
    "    \n",
    "#     print(vocab_size, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "4bfde6ac-ad9e-4a3b-b1f8-d900466f5049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(emb_s, h_s):\n",
    "    ln1 = Relu()\n",
    "    n_hidden = h_s\n",
    "    \n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, emb_s),\n",
    "        nn.Flatten(2),\n",
    "        Linear(emb_s * context_length, n_hidden, bias=False), \n",
    "        ln1,\n",
    "        Linear(n_hidden, vocab_size, bias=True),\n",
    "        nn.Flatten(0,1)\n",
    "    ])\n",
    "    \n",
    "    parameters = model.parameters()\n",
    "    print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "    # should probably be a function on the model?\n",
    "    for p in parameters:\n",
    "      p.requires_grad = True\n",
    "    \n",
    "    print(\"flatten\", vocab_size, embedding_size)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6954c258-f633-4351-998a-96498c3d3a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 4])\n",
      "tensor([[[ 8,  0,  0,  0],\n",
      "         [ 8, 13,  0,  0],\n",
      "         [ 8, 13,  5,  0],\n",
      "         [ 8, 13,  5,  5]],\n",
      "\n",
      "        [[ 7,  0,  0,  0],\n",
      "         [ 7,  5,  0,  0],\n",
      "         [ 7,  5, 12,  0],\n",
      "         [ 7,  5, 12,  0]]])\n",
      "torch.Size([2, 4, 4, 3])\n",
      "tensor([[[[ 0.5390, -0.4193,  0.5890],\n",
      "          [ 0.1797, -0.8898, -2.0754],\n",
      "          [ 0.1797, -0.8898, -2.0754],\n",
      "          [ 0.1797, -0.8898, -2.0754]],\n",
      "\n",
      "         [[ 0.5390, -0.4193,  0.5890],\n",
      "          [ 1.5444,  0.1385, -0.1019],\n",
      "          [ 0.1797, -0.8898, -2.0754],\n",
      "          [ 0.1797, -0.8898, -2.0754]],\n",
      "\n",
      "         [[ 0.5390, -0.4193,  0.5890],\n",
      "          [ 1.5444,  0.1385, -0.1019],\n",
      "          [-0.2783,  0.8016, -0.5159],\n",
      "          [ 0.1797, -0.8898, -2.0754]],\n",
      "\n",
      "         [[ 0.5390, -0.4193,  0.5890],\n",
      "          [ 1.5444,  0.1385, -0.1019],\n",
      "          [-0.2783,  0.8016, -0.5159],\n",
      "          [-0.2783,  0.8016, -0.5159]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4684,  0.2388,  0.1303],\n",
      "          [ 0.1797, -0.8898, -2.0754],\n",
      "          [ 0.1797, -0.8898, -2.0754],\n",
      "          [ 0.1797, -0.8898, -2.0754]],\n",
      "\n",
      "         [[ 0.4684,  0.2388,  0.1303],\n",
      "          [-0.2783,  0.8016, -0.5159],\n",
      "          [ 0.1797, -0.8898, -2.0754],\n",
      "          [ 0.1797, -0.8898, -2.0754]],\n",
      "\n",
      "         [[ 0.4684,  0.2388,  0.1303],\n",
      "          [-0.2783,  0.8016, -0.5159],\n",
      "          [ 1.4873, -0.0056, -0.2055],\n",
      "          [ 0.1797, -0.8898, -2.0754]],\n",
      "\n",
      "         [[ 0.4684,  0.2388,  0.1303],\n",
      "          [-0.2783,  0.8016, -0.5159],\n",
      "          [ 1.4873, -0.0056, -0.2055],\n",
      "          [ 0.1797, -0.8898, -2.0754]]]])\n",
      "torch.Size([2, 4, 12])\n",
      "tensor([[[ 0.5390, -0.4193,  0.5890,  0.1797, -0.8898, -2.0754,  0.1797,\n",
      "          -0.8898, -2.0754,  0.1797, -0.8898, -2.0754],\n",
      "         [ 0.5390, -0.4193,  0.5890,  1.5444,  0.1385, -0.1019,  0.1797,\n",
      "          -0.8898, -2.0754,  0.1797, -0.8898, -2.0754],\n",
      "         [ 0.5390, -0.4193,  0.5890,  1.5444,  0.1385, -0.1019, -0.2783,\n",
      "           0.8016, -0.5159,  0.1797, -0.8898, -2.0754],\n",
      "         [ 0.5390, -0.4193,  0.5890,  1.5444,  0.1385, -0.1019, -0.2783,\n",
      "           0.8016, -0.5159, -0.2783,  0.8016, -0.5159]],\n",
      "\n",
      "        [[ 0.4684,  0.2388,  0.1303,  0.1797, -0.8898, -2.0754,  0.1797,\n",
      "          -0.8898, -2.0754,  0.1797, -0.8898, -2.0754],\n",
      "         [ 0.4684,  0.2388,  0.1303, -0.2783,  0.8016, -0.5159,  0.1797,\n",
      "          -0.8898, -2.0754,  0.1797, -0.8898, -2.0754],\n",
      "         [ 0.4684,  0.2388,  0.1303, -0.2783,  0.8016, -0.5159,  1.4873,\n",
      "          -0.0056, -0.2055,  0.1797, -0.8898, -2.0754],\n",
      "         [ 0.4684,  0.2388,  0.1303, -0.2783,  0.8016, -0.5159,  1.4873,\n",
      "          -0.0056, -0.2055,  0.1797, -0.8898, -2.0754]]])\n",
      "torch.Size([2, 4, 60])\n",
      "torch.Size([2, 4, 27])\n",
      "flatten\n",
      "torch.Size([8, 27])\n",
      "[[13, 5, 5, 18], [5, 12, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "x, y = samples('train', 2, 4)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "em = Embedding(27, 3)\n",
    "x = em(x)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "fl = nn.Flatten(2)\n",
    "x = fl(x)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "l1 = nn.Linear(12, 60)\n",
    "x = l1(x)\n",
    "print(x.shape)\n",
    "ru = Relu()\n",
    "x = ru(x)\n",
    "\n",
    "l2 = Linear(60, vocab_size, bias=True)\n",
    "x = l2(x)\n",
    "print(x.shape)\n",
    "\n",
    "fl2 = nn.Flatten(0,1)\n",
    "x = fl2(x)\n",
    "print(\"flatten\")\n",
    "print(x.shape)\n",
    "\n",
    "print(y)\n",
    "y = torch.tensor(y).view(-1)\n",
    "ls = F.cross_entropy(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c1e0a-1a41-4a82-80f1-6e1540b9689e",
   "metadata": {},
   "source": [
    "## 2 sequences\n",
    "from each we create 4 lower left trianglur sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d61ee903-270b-4db4-995c-2364a9f87879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 7,  0,  0],\n",
      "         [ 7,  5,  0],\n",
      "         [ 7,  5, 12]]])\n",
      "tensor([[[[ 0.5761, -0.4086, -2.1589],\n",
      "          [-0.8405, -0.1164,  1.3651],\n",
      "          [-0.8405, -0.1164,  1.3651]],\n",
      "\n",
      "         [[ 0.5761, -0.4086, -2.1589],\n",
      "          [-0.0053,  0.5236, -0.7010],\n",
      "          [-0.8405, -0.1164,  1.3651]],\n",
      "\n",
      "         [[ 0.5761, -0.4086, -2.1589],\n",
      "          [-0.0053,  0.5236, -0.7010],\n",
      "          [ 1.0390,  0.5107, -0.9023]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5761, -0.4086, -2.1589, -0.8405, -0.1164,  1.3651, -0.8405,\n",
       "          -0.1164,  1.3651],\n",
       "         [ 0.5761, -0.4086, -2.1589, -0.0053,  0.5236, -0.7010, -0.8405,\n",
       "          -0.1164,  1.3651],\n",
       "         [ 0.5761, -0.4086, -2.1589, -0.0053,  0.5236, -0.7010,  1.0390,\n",
       "           0.5107, -0.9023]]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = samples('train', 1, 3)\n",
    "print(x)\n",
    "x = em(x)\n",
    "print(x)\n",
    "x = fl(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "351e937d-77fd-4d19-9aaf-94e74d58a219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12870\n",
      "flatten 27 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = 9\n",
    "epochs = 80\n",
    "batch_size = 32\n",
    "sample_loops = 8000\n",
    "hidden_size = 200\n",
    "\n",
    "md = model_init(embed, hidden_size)\n",
    "parameters = md.parameters()\n",
    "\n",
    "lr_step = {\n",
    "    0: { 0: .1},\n",
    "    3: { 0: .1},\n",
    "    9: { 0: .04, 60: 0.01}\n",
    "}\n",
    "\n",
    "lrs = lr_step[embed]\n",
    "\n",
    "m_setup = {\n",
    "    \"embed\": embed,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"sample_loops\": sample_loops,\n",
    "    \"hidden_size\": hidden_size,\n",
    "    \"learning_rates\": lrs\n",
    "}\n",
    "\n",
    "learning_rate = lrs[0]\n",
    "\n",
    "running_loss = []\n",
    "running_lr = []\n",
    "\n",
    "ud_ratio = []\n",
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "47eb752c-f2c8-4719-a8d5-12cfa75cbecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1719)\n",
      "0 0.0368\n",
      "tensor(2.4397)\n",
      "4 0.033856000000000004\n",
      "tensor(2.3878)\n",
      "8 0.031147520000000005\n",
      "tensor(2.3617)\n",
      "12 0.028655718400000006\n",
      "tensor(2.3441)\n",
      "16 0.026363260928000006\n",
      "tensor(2.3328)\n",
      "20 0.024254200053760007\n",
      "tensor(2.3228)\n",
      "24 0.022313864049459207\n",
      "tensor(2.3167)\n",
      "28 0.02052875492550247\n",
      "tensor(2.3114)\n",
      "32 0.018886454531462274\n",
      "tensor(2.3051)\n",
      "36 0.01737553816894529\n",
      "tensor(2.3045)\n",
      "40 0.015985495115429668\n",
      "tensor(2.3003)\n",
      "44 0.014706655506195295\n",
      "tensor(2.2969)\n",
      "48 0.013530123065699671\n",
      "tensor(2.2944)\n",
      "52 0.012447713220443699\n",
      "tensor(2.2907)\n",
      "56 0.011451896162808204\n",
      "tensor(2.2901)\n",
      "60 0.0092\n",
      "tensor(2.2871)\n",
      "64 0.008464000000000001\n",
      "tensor(2.2851)\n",
      "68 0.007786880000000001\n",
      "tensor(2.2840)\n",
      "72 0.007163929600000001\n",
      "tensor(2.2821)\n",
      "76 0.0065908152320000015\n"
     ]
    }
   ],
   "source": [
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for s in range(sample_loops):\n",
    "        x, y = samples('train', batch_size)\n",
    "\n",
    "        logits = md(x)\n",
    "        Y = torch.tensor(y).view(-1)\n",
    "       \n",
    "        loss = F.cross_entropy(logits, Y) # loss function\n",
    "        with torch.no_grad():\n",
    "            epoch_loss += loss\n",
    "\n",
    "        # again stuff on parameters should probably be in model?\n",
    "        for p in parameters:\n",
    "          p.grad = None\n",
    "        loss.backward()\n",
    "\n",
    "        for p in parameters:\n",
    "            p.data -= learning_rate * p.grad\n",
    "    #just keep any epoch stuff in a no grad block\n",
    "    with torch.no_grad():\n",
    "        if ep in lrs:\n",
    "            learning_rate = lrs[ep]\n",
    "\n",
    "        running_loss.append(epoch_loss.item())\n",
    "        running_lr.append(learning_rate)\n",
    "\n",
    "        ud_ratio.append([ (learning_rate*p.grad.std()/ p.data.std()).log10().item() for p in parameters ])\n",
    "    \n",
    "        if ep % 4 == 0:\n",
    "            print(epoch_loss/sample_loops)\n",
    "            learning_rate *= .92\n",
    "            print(ep, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "f8d75b0c-f58c-4838-ada2-0bcf9fcfc6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2811) {'embed': 9, 'epochs': 80, 'batch_size': 32, 'sample_loops': 8000, 'hidden_size': 200, 'learning_rates': {0: 0.04, 60: 0.01}} 0.0065908152320000015\n"
     ]
    }
   ],
   "source": [
    "print(epoch_loss/sample_loops, m_setup, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "8b4d12cf-d042-4778-85fc-ac7380b3f05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3809) {'embed': 9, 'epochs': 40, 'batch_size': 32, 'sample_loops': 4000, 'hidden_size': 200, 'learning_rates': {0: 0.02}} 0.008687769084472646\n"
     ]
    }
   ],
   "source": [
    "print(epoch_loss/sample_loops, m_setup, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e3545f93-7844-434c-81e5-3f72dda0cd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3494) {'embed': 9, 'epochs': 12, 'batch_size': 32, 'sample_loops': 2000, 'hidden_size': 100, 'learning_rates': {0: 0.04}} 0.024254200053760007\n"
     ]
    }
   ],
   "source": [
    "print(epoch_loss/sample_loops, m_setup, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e9d910-12c1-4d9e-a1db-902d216a8fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor(2.3738) {'d': 9, 'e': 12, 'b_s': 32, 's_l': 2000}\n",
    "\n",
    "tensor(2.4077) 3dim\n",
    "10 0.06063550013440003\n",
    "tensor(2.4335) 3dim\n",
    "10 0.06063550013440003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61254c2a-d97b-4894-871b-141655152c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = [i for i in range(len(running_loss))]\n",
    "ls = [l for l in running_loss]\n",
    "\n",
    "plt.plot(eps, ls)\n",
    "\n",
    "t = layers[2].weight.detach()\n",
    "hy, hx = torch.histogram(t, density=True)\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(hx.detach()[1:], hy.detach())\n",
    "t2 = layers[-2].weight.detach()\n",
    "h2y, h2x = torch.histogram(t2, density=True)\n",
    "plt.plot(h2x.detach()[1:], h2y.detach())\n",
    "\n",
    "# look at our gradient distributions\n",
    "\n",
    "t = layers[2].weight.grad.detach()\n",
    "hy, hx = torch.histogram(t, density=True)\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(hx.detach()[1:], hy.detach())\n",
    "t2 = layers[-2].weight.grad.detach()\n",
    "h2y, h2x = torch.histogram(t2, density=True)\n",
    "plt.plot(h2x.detach()[1:], h2y.detach())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(ud_ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
