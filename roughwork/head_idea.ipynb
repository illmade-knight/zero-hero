{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "965b36f1-1440-4a07-a843-80cba31c34e8",
   "metadata": {},
   "source": [
    "### What if we increase the corpus\n",
    "\n",
    "let's start reading more books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d689a91-95ca-42cd-802e-ab97496243cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8919ad-3d6b-4421-94ce-553e3a506dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run bookreader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b6ef18-283c-41fd-9375-ef8d13ed5e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice = BookReader(\"Through the looking glass.txt\", \"a tangled.txt\", \"Hunting of the snark.txt\", \"alice.txt\")\n",
    "vocab_size = alice.vocab_size\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a713daf8-4a5f-430d-8f00-9c6db6743d22",
   "metadata": {},
   "source": [
    "### Get the batch with both x and y unseparated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91f9fe0b-25d9-4578-a105-4eb99138428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, batch_length=5, batch_size=5):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    ix = torch.randint(len(data) - batch_length, (batch_size,))\n",
    "    b = torch.stack([data[i:i+batch_length] for i in ix])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac12ed62-275e-43a8-b17e-9b0b6da58efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.tensor(alice.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3b116f-f526-4958-bfed-07f665e89cba",
   "metadata": {},
   "source": [
    "### Create an attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf6cf111-bf37-49fe-8e92-de8a35f8e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, c, head_size, content_length):\n",
    "        super().__init__()\n",
    "        self.positional_embed = nn.Embedding(content_length, c)\n",
    "        \n",
    "        self.key = nn.Linear(c, head_size, bias=False)\n",
    "        self.query = nn.Linear(c, head_size, bias=False)\n",
    "        self.value = nn.Linear(c, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(content_length, content_length)))\n",
    "        self.register_buffer('content_range',torch.arange(content_length))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "\n",
    "        # note tr is always the same - so the learning here is information passed back to the positional_embed from loss \n",
    "        x = x + self.positional_embed(self.content_range)\n",
    "        \n",
    "        k = self.key(x)   \n",
    "        q = self.query(x)\n",
    "        \n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 \n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        \n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7138eed8-721e-4752-bf9f-8ebca24882d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, fan_in, multiplier = 4):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = OrderedDict([\n",
    "            (\"l_in\", nn.Linear(fan_in, multiplier * fan_in)),\n",
    "            (\"relu\", nn.ReLU()),\n",
    "            (\"l_out\", nn.Linear(multiplier * fan_in, fan_in)),\n",
    "        ])\n",
    "        self.net = nn.Sequential(\n",
    "            layers\n",
    "        )\n",
    "\n",
    "        initial = layers['l_in']\n",
    "        nn.init.kaiming_normal_(initial.weight, nonlinearity=\"relu\")\n",
    "        layers['l_in'].weight.data = initial.weight.data * 3/5\n",
    "        if initial.bias is not None:\n",
    "            nn.init.constant_(initial.bias, 0)\n",
    "\n",
    "        final = layers['l_out']\n",
    "        layers['l_out'].weight.data = final.weight.data * .2\n",
    "        if final.bias is not None:\n",
    "            nn.init.constant_(final.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b77ec387-64c7-43b3-82a5-b24e22eb84a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "989f2ee4-1968-4bf6-8352-4e37ebaca633",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHead(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, num_heads, head_size, content_length):\n",
    "        super().__init__()\n",
    "        print(num_heads, head_size, content_length, embed_size)\n",
    "        self.heads = nn.ModuleList([Head(embed_size, head_size, content_length) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat( [head(x) for head in self.heads], dim = -1 )\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dff586a7-6f05-4e2a-95f4-9a07c8e27203",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFMultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, content_length, num_heads, head_size, multiplier=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.positional_embed = nn.Embedding(content_length, embed_size)\n",
    "        self.mutli_attention = MultiHead(embed_size, num_heads, head_size, content_length)\n",
    "        self.lna = nn.LayerNorm(embed_size)\n",
    "        self.ff = FeedForward(embed_size, multiplier)\n",
    "        self.lnff = nn.LayerNorm(embed_size)\n",
    "        self.decode = nn.Linear(embed_size, vocab_size)\n",
    "        self.content_length = content_length\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        #idx B,T\n",
    "        B, T = idx.shape\n",
    "\n",
    "        idx_e = self.vocab_embed(idx)\n",
    "        # note tr is always the same - so the learning here is information passed back to the positional_embed from loss\n",
    "        tr = torch.arange(T)\n",
    "        pos_e = self.positional_embed(tr)\n",
    "\n",
    "        x = idx_e + pos_e\n",
    "        x = self.mutli_attention(x)\n",
    "        # print(\"multi ball out\", x.shape)\n",
    "        x = self.lna(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.lnff(x)\n",
    "        # print(\"feed forward out\", x.shape)\n",
    "        logits = self.decode(x)\n",
    "        # print(\"decode out\", x.shape)\n",
    "        # print(\"targets\", targets.shape)\n",
    "        # return None, None\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            targets = targets.reshape(B*T)\n",
    "            loss = F.cross_entropy(logits.view(B*T, -1), targets) #.resize(B*T)) # loss function\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -self.content_length:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16926363-2c95-4998-a0a9-8eee16e1abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_batch(data, batch_length=5, batch_size=5, i=0):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    if i == 0:\n",
    "        ix = torch.randint(len(data) - batch_length, (batch_size,))\n",
    "    else:\n",
    "        ix = torch.arange(1, 5) + 1 + i\n",
    "\n",
    "    b = torch.stack([data[i:i+batch_length] for i in ix])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f874381a-99eb-4bba-bde0-b10c9632e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "@torch.no_grad()\n",
    "def split_loss(split):\n",
    "    split_len = len(split)\n",
    "    total_loss = 0\n",
    "    batch_size = 50\n",
    "    num_batches = math.floor(split_len / batch_size)\n",
    "    print(\"num_batches\", split_len, num_batches)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        t_b = get_val_batch(split, context_length+1, batch_size, i*batch_size)\n",
    "        \n",
    "        x = t_b[:, 0: context_length]\n",
    "        y = t_b[:, context_length: context_length+1]\n",
    "        \n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, batch_loss = model(x, y)\n",
    "        \n",
    "        total_loss = total_loss + batch_loss\n",
    "    \n",
    "    print(\"total loss\", total_loss, total_loss / num_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c2d3c52-0c8a-4ab6-8121-7e8377d361d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "4 8 12 32\n",
      "24457  parameters\n",
      "ep 0 tensor(2.5091, grad_fn=<DivBackward0>) [0.098]\n",
      "ep 5 tensor(1.8571, grad_fn=<DivBackward0>) [0.0885842380864]\n",
      "ep 10 tensor(1.8012, grad_fn=<DivBackward0>) [0.08007313507497958]\n",
      "ep 15 tensor(1.7687, grad_fn=<DivBackward0>) [0.07237977205924956]\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "training_runs = 800\n",
    "batch_size = 96\n",
    "context_length = 12\n",
    "learning_rate = .1\n",
    "embedding_dimensions = 32\n",
    "num_heads = 4\n",
    "head_size = embedding_dimensions // num_heads\n",
    "\n",
    "print(head_size)\n",
    "# our embedding_dimensions are still 'small' so we mutliply the size our our feed forward network to make up\n",
    "multiplier = 8\n",
    "model = FFMultiHeadAttention(embedding_dimensions, context_length, num_heads, head_size, multiplier)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()), ' parameters')\n",
    "\n",
    "lmbda = lambda epoch: 0.98\n",
    "\n",
    "m_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for tr in range(training_runs):\n",
    "        t_b = get_batch(train, context_length+1, batch_size)\n",
    "\n",
    "        x = t_b[:, 0:context_length]\n",
    "        y = t_b[:, 1:context_length+1]\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    m_scheduler.step()\n",
    "    \n",
    "    if ep % 5 == 0:\n",
    "        print(\"ep\", ep, epoch_loss/training_runs, m_scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27131eb8-ff09-4875-b027-f35afc525795",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.tensor(alice.data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2742b2-fcf5-4e4a-8387-c3b670452647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f219b8c9-2430-4b93-a0a0-4b015bd0ce1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches 48925 978\n",
      "total loss tensor(1712.4478) tensor(1.7510)\n",
      "None 48925\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (12) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     o \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(alice\u001b[38;5;241m.\u001b[39mdecode(o))\n",
      "Cell \u001b[1;32mIn[10], line 50\u001b[0m, in \u001b[0;36mFFMultiHeadAttention.generate\u001b[1;34m(self, idx, max_new_tokens)\u001b[0m\n\u001b[0;32m     48\u001b[0m idx_cond \u001b[38;5;241m=\u001b[39m idx[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontent_length:]\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# get the predictions\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx_cond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# focus only on the last time step\u001b[39;00m\n\u001b[0;32m     52\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;66;03m# becomes (B, C)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[10], line 25\u001b[0m, in \u001b[0;36mFFMultiHeadAttention.forward\u001b[1;34m(self, idx, targets)\u001b[0m\n\u001b[0;32m     22\u001b[0m pos_e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_embed(tr)\n\u001b[0;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m idx_e \u001b[38;5;241m+\u001b[39m pos_e\n\u001b[1;32m---> 25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutli_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# print(\"multi ball out\", x.shape)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlna(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m, in \u001b[0;36mMultiHead.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m----> 9\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat( \u001b[43m[\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheads\u001b[49m\u001b[43m]\u001b[49m, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m )\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m----> 9\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat( [\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m head \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m )\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m, in \u001b[0;36mHead.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m B,T,C \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# note tr is always the same - so the learning here is information passed back to the positional_embed from loss \u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositional_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent_range\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(x)   \n\u001b[0;32m     20\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery(x)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (12) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "print(split_loss(dev), len(dev))\n",
    "\n",
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(1):\n",
    "    o = model.generate(idx, 100).data[0].tolist()\n",
    "    print(alice.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa496f61-20fd-495e-9053-7358877c2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.int)\n",
    "for i in range(2):\n",
    "    o = model.generate(idx, 300).data[0].tolist()\n",
    "    print(alice.decode(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5984e4-9fca-4553-ade9-27100e9b770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow mor loops without restarting\n",
    "e_epochs = 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
